<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="utf-8">

<meta name="generator" content="Hexo 4.2.0">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="naver-site-verification" content="9abfedc8a2f9ddcb2cd0a96e6a2772ddc7b87e51">

<link rel="canonical" href="https://katie0809.github.io/2020/02/23/ai-study7/">
<title>[딥러닝 스터디] Attention을 활용한 기계번역 - Dailycrush</title>


    <meta name="description" content="다음의 책을 공부하며 정리한 내용입니다.  https:&#x2F;&#x2F;wikidocs.net&#x2F;24996 : seq2seq 정리 https:&#x2F;&#x2F;wikidocs.net&#x2F;22893 : 어텐션 모델 정리 https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v&#x3D;c8y9ZAb9aks&amp;t&#x3D;1032s : seq2seq에서 attention까지(매우 좋음, 꼭 참고하세요) h">
<meta property="og:type" content="article">
<meta property="og:title" content="[딥러닝 스터디] Attention을 활용한 기계번역">
<meta property="og:url" content="https://katie0809.github.io/2020/02/23/ai-study7/index.html">
<meta property="og:site_name" content="Dailycrush">
<meta property="og:description" content="다음의 책을 공부하며 정리한 내용입니다.  https:&#x2F;&#x2F;wikidocs.net&#x2F;24996 : seq2seq 정리 https:&#x2F;&#x2F;wikidocs.net&#x2F;22893 : 어텐션 모델 정리 https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v&#x3D;c8y9ZAb9aks&amp;t&#x3D;1032s : seq2seq에서 attention까지(매우 좋음, 꼭 참고하세요) h">
<meta property="og:locale" content="ko_KR">
<meta property="og:image" content="https://katie0809.github.io/image/Elegant_Background-2.jpg">
<meta property="article:published_time" content="2020-02-23T07:54:46.000Z">
<meta property="article:modified_time" content="2020-05-08T06:45:29.076Z">
<meta property="article:author" content="Kyungim Lee">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="자연어처리">
<meta property="article:tag" content="딥러닝">
<meta property="article:tag" content="언어모델">
<meta property="article:tag" content="한국어 임베딩">
<meta property="article:tag" content="케라스">
<meta property="article:tag" content="Attention">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://katie0809.github.io/image/Elegant_Background-2.jpg">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/vs2015.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-158681991-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-158681991-1');
</script>

    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    
    


<link rel="stylesheet" href="/css/style.css">
<link rel="alternate" href="/rss2.xml" title="Dailycrush" type="application/rss+xml">
</head>
<body class="is-2-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo.svg" alt="[딥러닝 스터디] Attention을 활용한 기계번역" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item" href="/">Home</a>
                
                <a class="navbar-item" href="/archives">Archives</a>
                
                <a class="navbar-item" href="/categories">Categories</a>
                
                <a class="navbar-item" href="/tags">Tags</a>
                
                <a class="navbar-item" href="/downloads">Downloads</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    <a class="navbar-item" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/katie0809">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="목차" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
                <a class="navbar-item search" title="검색" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-8-widescreen has-order-2 column-main">
<div class="card">
    
    <div class="card-image">
        <span class="image is-7by1">
            <img class="thumbnail" src="/image/Elegant_Background-2.jpg" alt="[딥러닝 스터디] Attention을 활용한 기계번역">
        </span>
    </div>
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-02-23T07:54:46.000Z">2020-02-23</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/">개발자 공부</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/">인공지능</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    14분 소요 (약 2038 글자)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                [딥러닝 스터디] Attention을 활용한 기계번역
            
        </h1>
        <div class="content">
            <p>다음의 책을 공부하며 정리한 내용입니다.</p>
<ul>
<li><a href="https://wikidocs.net/24996" rel="external nofollow noopener noreferrer" target="_blank">https://wikidocs.net/24996</a> : seq2seq 정리</li>
<li><a href="https://wikidocs.net/22893" rel="external nofollow noopener noreferrer" target="_blank">https://wikidocs.net/22893</a> : 어텐션 모델 정리</li>
<li><a href="https://www.youtube.com/watch?v=c8y9ZAb9aks&amp;t=1032s" rel="external nofollow noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=c8y9ZAb9aks&amp;t=1032s</a> : seq2seq에서 attention까지(매우 좋음, 꼭 참고하세요)</li>
<li><a href="https://www.tensorflow.org/tutorials/text/nmt_with_attention" rel="external nofollow noopener noreferrer" target="_blank">https://www.tensorflow.org/tutorials/text/nmt_with_attention</a> : attention 실습</li>
</ul>
<h1 id="시퀀스-투-시퀀스-seq2seq"><a href="#시퀀스-투-시퀀스-seq2seq" class="headerlink" title="시퀀스-투-시퀀스(seq2seq)"></a>시퀀스-투-시퀀스(seq2seq)</h1><p>: 입력된 시퀀스로부터 다른 도메인의 시퀀스를 출력하는 모델.</p>
<p>이는 다음과 같은 분야에서 사용된다.</p>
<ul>
<li>챗봇: 입력시퀀스와 출력시퀀스를 각각 질문/대답으로 구성하면 챗봇을 만들 수 있다.</li>
<li>기계번역: 입력시퀀스와 출력시퀀스를 입력/번역문장으로 구성하면 번역기를 만들 수 있다.</li>
<li>Text Summerization, Speech to Text 등에 사용될 수 있다.</li>
</ul>
<a id="more"></a>

<p><img src="https://wikidocs.net/images/page/24996/%EC%9D%B8%EC%BD%94%EB%8D%94%EB%94%94%EC%BD%94%EB%8D%94%EB%AA%A8%EB%8D%B8.PNG" alt></p>
<p>seq2seq 모델은 기본적으로 위의 구조를 띄고 있다.</p>
<ul>
<li>인코더와 디코더는 두개의 RNN 아키텍처이다. 입력 문장을 처리하는 RNN셀을 인코더, 출력 문장(번역된 문장)을 처리하는 RNN셀을 디코더라고 하는 것.</li>
<li>중간의 컨텍스트 벡터는 인코더 마지막 시점의 히든 스테이트의 크기이다. 즉, 이전의 내용이 함축된 하나의 벡터이다.</li>
</ul>
<p>이때 디코더에서 단순히 매 단계마다 가장 가능성이 높은 단어 하나를 선택하는 방식은 생각보다 효율적이지 않다. 이때 적용하는 방법이 Beam search.</p>
<blockquote>
<p>Beam search : 매 스텝마다 가장 ㄴㄴ 높은 n개의 단어를 선택하여, 이 N개의 단어 각각에 대해 다음 스텝에서 등장할 수 있는 모든 단어들의 확률을 예측한다. 이러한 방식으로 <strong>매 스텝마다 n개의 후보군을 유지</strong>하여 최적의 시퀀스 후보를 뽑아낸다.</p>
</blockquote>
<hr>
<h1 id="Attention-model"><a href="#Attention-model" class="headerlink" title="Attention model"></a>Attention model</h1><p><img src="https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg" alt></p>
<ul>
<li><p>seq2seq 모델은 기본적으로 <code>인코더 -&gt; [컨텍스트 벡터] -&gt; 디코더</code> 의 구조를 갖는다.</p>
</li>
<li><p>이러한 모델의 문제는 아래와 같다</p>
<ul>
<li>컨텍스트 벡터는 결국 <code>하나의 벡터</code>에 불과하다. 인코더의 모든 정보를 하나의 고정된 크기의 벡터에 압축하다 보면 필연적으로 <strong><code>정보의 손실</code></strong>이 발생하게 된다.</li>
<li>RNN의 고질적인 Vanishing gradient 문제가 발생한다.</li>
</ul>
<p>: 이러한 문제는 결과적으로 <u>입력 시퀀스가 길어질수록 번역의 품질이 저하</u>되는 문제를 야기한다.</p>
</li>
</ul>
<h2 id="Attention-Overview"><a href="#Attention-Overview" class="headerlink" title="Attention Overview"></a>Attention Overview</h2><p>어텐션 모델의 기본 아이디어는 다음과 같다.</p>
<blockquote>
<p>디코더의 매 time step마다 인코더에서의 <code>전체 입력문장을 다시 한번 참고</code>한다.</p>
</blockquote>
<ul>
<li>이때 입력 문장의 전체 토큰을 동일한 비중으로 참고하는 것이 아니라, 해당 시점에서 예측해야할 단어와 <em>연관이 있는 입력토큰</em> 부분을 좀더 집중(<strong>attention</strong>)해서 참고한다. </li>
</ul>
<h2 id="Dot-product-attention"><a href="#Dot-product-attention" class="headerlink" title="Dot product attention"></a>Dot product attention</h2><p>어텐션은 다양한 종류가 있다. 그 중 가장 기본적인 닷 프로덕트 어텐션의 구조를 살펴보자.</p>
<p>먼저 기본적인 용어 정의, seq2seq모델과 어텐션 모델의 차이점을 알아보자.</p>
<ul>
<li><strong>1, 2, 3… n</strong> : 인코더의 시점</li>
<li><strong>h1, h2, h3… hn</strong> : 각 시점에서의 인코더의 은닉 상태(hidden state)</li>
<li><strong>t</strong> : 디코더의 현재시점</li>
<li><strong>st</strong> : 현재 시점에서의 디코더의 은닉 상태</li>
</ul>
<p>이전에 배웠던 seq2seq에서 디코더는 두개의 값(<u>이전시점의 은닉상태, 이전시점의 출력</u>)을 통해 현재시점의 은닉상태를 계산했다. 이때 어텐션 모델에서는 계산을 위해 필요한 값이 하나 더 추가된다. 바로 <strong><code>t시점의 어텐션 값 at</code></strong>이다.</p>
<p>따라서 <u>어텐션 모델은 (seq2seq + 어텐션 값 계산) 인 모델</u>이다. 즉, 어텐션 모델에서의 핵심은 이 <strong>어텐션 값을 어떻게 구하는가</strong>이며, 이 과정에서 어텐션 스코어값을 구하는 방법에 따라 닷 프로덕트 어텐션, 루옹 어텐션, 바다나우 어텐션 등으로 종류가 나뉘게 된다.</p>
<p>또한 모든 어텐션 값 at는(“값”이라는 명칭에서 예상할 수 있듯) 스칼라 값이다.</p>
<h3 id="Step-1-어텐션-스코어를-구한다"><a href="#Step-1-어텐션-스코어를-구한다" class="headerlink" title="Step 1. 어텐션 스코어를 구한다."></a>Step 1. 어텐션 스코어를 구한다.</h3><p><img src="https://wikidocs.net/images/page/22893/dotproductattention2_final.PNG" alt></p>
<p>어텐션 스코어는 다음을 의미한다.</p>
<blockquote>
<p><strong>Attention score</strong> : 인코더의 <strong>각 은닉상태 h1 - hn</strong>이 현재 시점의 디코더 은닉상태 <strong>st</strong>와 <code>얼마나 유사한지</code>의 정도</p>
</blockquote>
<p>닷 프로덕트 어텐션에서는 이 스코어 값을 구하기 위해 <u>st와 hi(i : 1~n)를 닷 프로덕트 한다</u>. 이때 둘다 열벡터이므로 디코더의 은닉상태 st값을 전치하여 내적한다.</p>
<p>따라서 dot product attention의 attention score 함수 수식은 다음과 같다.</p>
<blockquote>
<p>score(st, hi) = stT * hi</p>
</blockquote>
<p>따라서 디코더의 현재 시점 t에 대한 은닉상태 st와 인코더의 모든 시점에 대한 은닉상태의 어텐션 스코어의 모음(et)은 아래와 같다.</p>
<blockquote>
<p>et = [stT * h1, …, stT * hN]</p>
</blockquote>
<h3 id="Step-2-Softmax를-통해-Attention-Distribution-어텐션-분포-를-구한다"><a href="#Step-2-Softmax를-통해-Attention-Distribution-어텐션-분포-를-구한다" class="headerlink" title="Step 2. Softmax를 통해 Attention Distribution(어텐션 분포)를 구한다."></a>Step 2. Softmax를 통해 Attention Distribution(어텐션 분포)를 구한다.</h3><p><img src="https://wikidocs.net/images/page/22893/dotproductattention3_final.PNG" alt></p>
<p>구해낸 모든 어텐션 스코어의 모음, <u>et에 <strong>softmax</strong>를 적용해 확률 분포를 얻어낸다</u>. </p>
<p>이를 통해 얻어낸 분포를 <code>Attention Distribution</code>(어텐션 분포)라 하며, 각각의 값을 <code>Attention Weight</code>(어텐션 가중치)라고 한다.</p>
<p><strong>어텐션 분포와 어텐션 값</strong>은 <code>디코더의 현재시점 t에 대해 정의</code>된다.</p>
<blockquote>
<p>Attention Distribution : 어텐션 스코어의 모음에 softmax를 적용해 얻어낸 확률분포. 어텐션 가중치의 모음값</p>
<p>Attention Weight : 어텐션 분포의 각각의 값</p>
</blockquote>
<p>따라서 어텐션 분포를 αt의 식은 다음과 같다.</p>
<blockquote>
<p>αt = softmax(et)</p>
</blockquote>
<h3 id="Step-3-Attention-Weight과-인코더-은닉상태를-가중합하여-Attention-Value를-구한다"><a href="#Step-3-Attention-Weight과-인코더-은닉상태를-가중합하여-Attention-Value를-구한다" class="headerlink" title="Step 3. Attention Weight과 인코더 은닉상태를 가중합하여 Attention Value를 구한다."></a>Step 3. Attention Weight과 인코더 은닉상태를 가중합하여 Attention Value를 구한다.</h3><p><img src="https://wikidocs.net/images/page/22893/dotproductattention4_final.PNG" alt></p>
<p>구해낸 Attention Distribution의 각 <strong>Attention Weight</strong>들을 <strong>해당 시점의 인코더 은닉상태(h1 ~ hN)</strong>와 <code>가중합(Weighted sum)</code> 한다. </p>
<p><strong>결과로 나오는 벡터 a</strong>는 최종 어텐션 값, 즉 <u>Attention Value</u>가 되며 이는 인코더의 문맥을 내포하고 있다는 의미에서 <u>Context Vector</u>라고 부르기도 한다.</p>
<blockquote>
<p>a = ∑αti * hi (i : 1~N, ati : i번째 어텐션 분포의 값)</p>
</blockquote>
<h3 id="Step-4-어텐션-값과-현재-상태-대코더의-은닉상태-st를-연결한다-Concatenation"><a href="#Step-4-어텐션-값과-현재-상태-대코더의-은닉상태-st를-연결한다-Concatenation" class="headerlink" title="Step 4. 어텐션 값과 현재 상태 대코더의 은닉상태 st를 연결한다(Concatenation)."></a>Step 4. 어텐션 값과 현재 상태 대코더의 은닉상태 st를 연결한다(Concatenation).</h3><p><img src="https://wikidocs.net/images/page/22893/dotproductattention5_final_final.PNG" alt></p>
<p>최종적으로 구해낸 어텐션 값(컨텍스트 벡터) a를 현재 시점의 디코더 은닉상태 st와 결합한다. 이때 둘을 연결해 하나의 벡터로 만드는(concatenation) 작업을 수행한다.</p>
<p>해당 결합 작업을 통해 산출된 최종 벡터 vt는 t시점의 디코더 예측값 y_hat를 도출하기 위한 연산의 입력값으로 사용된다.</p>
<hr>
<h1 id="Bahdanau-Attention-바다나우-어텐션"><a href="#Bahdanau-Attention-바다나우-어텐션" class="headerlink" title="Bahdanau Attention(바다나우 어텐션)"></a>Bahdanau Attention(바다나우 어텐션)</h1><p>: 위에서 어텐션의 종류는 step 1의 어텐션 스코어를 구하는 방법에 따라 달라진다고 했다. </p>
<p>닷 프로덕트 어텐션은 인코더의 각 은닉상태 h1 ~ hN과 현재시점 디코더 은닉상태 st의 유사도인 어텐션 스코어를 내적으로 구하였기 때문에 닷 프로덕트 어텐션이라는 이름이 붙었다.</p>
<p>이때,</p>
<ul>
<li><p><code>현재시점 디코더의 은닉상태</code> : <strong>query</strong></p>
</li>
<li><p><code>이전 인코더의 모든 은닉상태</code> : <strong>key</strong>(=<strong>value</strong>)</p>
</li>
</ul>
<p>라고 한다면 닷 프로덕트 어텐션의 스코어 함수는 아래와 같을 것이다.</p>
<blockquote>
<p>score(query, key) = queryT * key</p>
</blockquote>
<p>이때 바다나우 어텐션은 아래와 같은 스코어 함수를 사용한다.</p>
<blockquote>
<p>score(query, key) = vT * tanh(W1 * key + W2 * query)</p>
<p>: vT는 transposed weight vector</p>
</blockquote>

        </div>
        
        <div class="level is-size-7 is-uppercase">
            <div class="level-start">
                <div class="level-item">
                    <span class="is-size-6 has-text-grey has-mr-7">#</span>
                    <a class="has-link-grey -link" href="/tags/Attention/" rel="tag">Attention</a>, <a class="has-link-grey -link" href="/tags/pytorch/" rel="tag">pytorch</a>, <a class="has-link-grey -link" href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/" rel="tag">딥러닝</a>, <a class="has-link-grey -link" href="/tags/%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8/" rel="tag">언어모델</a>, <a class="has-link-grey -link" href="/tags/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/" rel="tag">자연어처리</a>, <a class="has-link-grey -link" href="/tags/%EC%BC%80%EB%9D%BC%EC%8A%A4/" rel="tag">케라스</a>, <a class="has-link-grey -link" href="/tags/%ED%95%9C%EA%B5%AD%EC%96%B4-%EC%9E%84%EB%B2%A0%EB%94%A9/" rel="tag">한국어 임베딩</a>
                </div>
            </div>
        </div>
        
        
        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2020/02/23/nuxt-study1/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">Introduction to Nuxt.js</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2020/02/19/ai-study6/">
                <span class="level-item">[딥러닝 스터디] 케라스(Keras) 실습</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <h3 class="title is-5 has-text-weight-normal">댓글</h3>
        <script>(function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/ko/sdk.js#xfbml=1&version=v2.8";
    fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
<div class="fb-comments" data-width="100%" data-href="https://katie0809.github.io/2020/02/23/ai-study7/" data-num-posts="5"></div>
<link rel="stylesheet" href="/css/facebook.css">
    </div>
</div>
</div>
                
                




<div class="column is-4-tablet is-4-desktop is-4-widescreen  has-order-3 column-right is-sticky">
    
        

    <div class="card widget" id="toc">
        <div class="card-content">
            <div class="menu">
                <h3 class="menu-label">
                    목차
                </h3>
                <ul class="menu-list"><li>
        <a class="is-flex" href="#시퀀스-투-시퀀스-seq2seq">
        <span class="has-mr-6">1</span>
        <span>시퀀스-투-시퀀스(seq2seq)</span>
        </a></li><li>
        <a class="is-flex" href="#Attention-model">
        <span class="has-mr-6">2</span>
        <span>Attention model</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Attention-Overview">
        <span class="has-mr-6">2.1</span>
        <span>Attention Overview</span>
        </a></li><li>
        <a class="is-flex" href="#Dot-product-attention">
        <span class="has-mr-6">2.2</span>
        <span>Dot product attention</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Step-1-어텐션-스코어를-구한다">
        <span class="has-mr-6">2.2.1</span>
        <span>Step 1. 어텐션 스코어를 구한다.</span>
        </a></li><li>
        <a class="is-flex" href="#Step-2-Softmax를-통해-Attention-Distribution-어텐션-분포-를-구한다">
        <span class="has-mr-6">2.2.2</span>
        <span>Step 2. Softmax를 통해 Attention Distribution(어텐션 분포)를 구한다.</span>
        </a></li><li>
        <a class="is-flex" href="#Step-3-Attention-Weight과-인코더-은닉상태를-가중합하여-Attention-Value를-구한다">
        <span class="has-mr-6">2.2.3</span>
        <span>Step 3. Attention Weight과 인코더 은닉상태를 가중합하여 Attention Value를 구한다.</span>
        </a></li><li>
        <a class="is-flex" href="#Step-4-어텐션-값과-현재-상태-대코더의-은닉상태-st를-연결한다-Concatenation">
        <span class="has-mr-6">2.2.4</span>
        <span>Step 4. 어텐션 값과 현재 상태 대코더의 은닉상태 st를 연결한다(Concatenation).</span>
        </a></li></ul></li></ul></li><li>
        <a class="is-flex" href="#Bahdanau-Attention-바다나우-어텐션">
        <span class="has-mr-6">3</span>
        <span>Bahdanau Attention(바다나우 어텐션)</span>
        </a></li></ul>
            </div>
        </div>
    </div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/">
            <span class="level-start">
                <span class="level-item">개발자 공부</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">36</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/JSP/">
            <span class="level-start">
                <span class="level-item">JSP</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/Javascript/">
            <span class="level-start">
                <span class="level-item">Javascript</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">6</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/">
            <span class="level-start">
                <span class="level-item">인공지능</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">24</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8/">
            <span class="level-start">
                <span class="level-item">코딩테스트</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/%EA%B7%B8%EB%83%A5-%EA%B7%B8%EB%9F%B0-%EC%9D%BC%EC%83%81/">
            <span class="level-start">
                <span class="level-item">그냥 그런 일상</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/%EA%B7%B8%EB%83%A5-%EA%B7%B8%EB%9F%B0-%EC%9D%BC%EC%83%81/%EA%B7%B8%EB%A0%87%EA%B2%8C-%EB%B0%94%EB%B3%B4%EB%8A%94-%EC%95%84%EB%8B%98/">
            <span class="level-start">
                <span class="level-item">그렇게 바보는 아님</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%EA%B7%B8%EB%83%A5-%EA%B7%B8%EB%9F%B0-%EC%9D%BC%EC%83%81/%EB%81%84%EC%A0%81%EB%81%84%EC%A0%81/">
            <span class="level-start">
                <span class="level-item">끄적끄적</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li></ul></li>
            </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Tag Cloud
        </h3>
        <a href="/tags/Attention/" style="font-size: 12px;">Attention</a> <a href="/tags/ES2015/" style="font-size: 10px;">ES2015+</a> <a href="/tags/ES6/" style="font-size: 10px;">ES6</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/Keras/" style="font-size: 10px;">Keras</a> <a href="/tags/RNN/" style="font-size: 13px;">RNN</a> <a href="/tags/YAMLException/" style="font-size: 10px;">YAMLException</a> <a href="/tags/api-server/" style="font-size: 10px;">api_server</a> <a href="/tags/change-permission/" style="font-size: 10px;">change permission</a> <a href="/tags/codility/" style="font-size: 14px;">codility</a> <a href="/tags/coding-rule/" style="font-size: 11px;">coding rule</a> <a href="/tags/coding-test/" style="font-size: 14px;">coding test</a> <a href="/tags/dacon/" style="font-size: 10px;">dacon</a> <a href="/tags/developer/" style="font-size: 14px;">developer</a> <a href="/tags/express/" style="font-size: 10px;">express</a> <a href="/tags/folder-permission/" style="font-size: 10px;">folder permission</a> <a href="/tags/githubpage/" style="font-size: 10px;">githubpage</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/inflearn/" style="font-size: 10px;">inflearn</a> <a href="/tags/javascript/" style="font-size: 15px;">javascript</a> <a href="/tags/jsp/" style="font-size: 10px;">jsp</a> <a href="/tags/linear-regression/" style="font-size: 11px;">linear regression</a> <a href="/tags/logistic-regression/" style="font-size: 10px;">logistic regression</a> <a href="/tags/mac/" style="font-size: 10px;">mac</a> <a href="/tags/nodejs/" style="font-size: 10px;">nodejs</a> <a href="/tags/numpy/" style="font-size: 11px;">numpy</a> <a href="/tags/nuxtjs/" style="font-size: 11px;">nuxtjs</a> <a href="/tags/python/" style="font-size: 11px;">python</a> <a href="/tags/pytorch/" style="font-size: 19px;">pytorch</a> <a href="/tags/style-guide/" style="font-size: 11px;">style guide</a> <a href="/tags/tensorflow/" style="font-size: 18px;">tensorflow</a> <a href="/tags/tensorflow-2-0/" style="font-size: 10px;">tensorflow 2.0</a> <a href="/tags/tensorflow-developer-certification/" style="font-size: 16px;">tensorflow developer certification</a> <a href="/tags/torchtext/" style="font-size: 10px;">torchtext</a> <a href="/tags/vue/" style="font-size: 11px;">vue</a> <a href="/tags/vuejs/" style="font-size: 13px;">vuejs</a> <a href="/tags/vueschool-io/" style="font-size: 11px;">vueschool.io</a> <a href="/tags/%EA%B7%B8%EB%9E%98%ED%94%84-%EC%8B%9C%EA%B0%81%ED%99%94/" style="font-size: 10px;">그래프 시각화</a> <a href="/tags/%EB%8D%B0%EC%9D%B4%EC%BD%98/" style="font-size: 10px;">데이콘</a> <a href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/" style="font-size: 18px;">딥러닝</a> <a href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D%EA%B8%B0%EC%B4%88/" style="font-size: 16px;">딥러닝기초</a> <a href="/tags/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1-%ED%9A%8C%EA%B7%80/" style="font-size: 10px;">로지스틱 회귀</a> <a href="/tags/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80/" style="font-size: 11px;">선형회귀</a> <a href="/tags/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D/" style="font-size: 12px;">순환신경망</a> <a href="/tags/%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8/" style="font-size: 17px;">언어모델</a> <a href="/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/" style="font-size: 17px;">인공지능</a> <a href="/tags/%EC%9E%90%EA%B2%A9%EC%A6%9D/" style="font-size: 16px;">자격증</a> <a href="/tags/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%A0%84%EC%B2%98%EB%A6%AC/" style="font-size: 11px;">자연어 전처리</a> <a href="/tags/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/" style="font-size: 20px;">자연어처리</a> <a href="/tags/%EC%BC%80%EB%9D%BC%EC%8A%A4/" style="font-size: 12px;">케라스</a> <a href="/tags/%ED%95%9C%EA%B5%AD%EC%96%B4-%EC%9E%84%EB%B2%A0%EB%94%A9/" style="font-size: 15px;">한국어 임베딩</a>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo.svg" alt="[딥러닝 스터디] Attention을 활용한 기계번역" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2021 Kyungim Lee&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> & <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/katie0809">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("ko");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'https://katie0809.github.io',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" rel="external nofollow noopener noreferrer" target="_blank">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>










<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="입력 하세요...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '포스트',
                PAGES: '페이지',
                CATEGORIES: '카테고리',
                TAGS: '태그',
                UNTITLED: '(제목없음)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>