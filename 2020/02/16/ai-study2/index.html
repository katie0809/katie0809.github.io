<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="utf-8">

<meta name="generator" content="Hexo 4.2.0">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="naver-site-verification" content="9abfedc8a2f9ddcb2cd0a96e6a2772ddc7b87e51">

<link rel="canonical" href="https://katie0809.github.io/2020/02/16/ai-study2/">
<title>[딥러닝 스터디] 자연어의 계산과 이해 - Dailycrush</title>


    <meta name="description" content="다음의 책을 공부하며 정리한 내용입니다  한국어 임베딩 - 이기창 https:&#x2F;&#x2F;wikidocs.net&#x2F;21668 https:&#x2F;&#x2F;wikidocs.net&#x2F;21687 https:&#x2F;&#x2F;wikidocs.net&#x2F;21692  2장. 언어모델이란: 자연어의 의미를 임베딩에 어떻게 녹여낼 수 있는가? 그 비결은 자연어의 통계적 패턴 을 통째로 임베딩에 넣는 것이다.">
<meta property="og:type" content="article">
<meta property="og:title" content="[딥러닝 스터디] 자연어의 계산과 이해">
<meta property="og:url" content="https://katie0809.github.io/2020/02/16/ai-study2/index.html">
<meta property="og:site_name" content="Dailycrush">
<meta property="og:description" content="다음의 책을 공부하며 정리한 내용입니다  한국어 임베딩 - 이기창 https:&#x2F;&#x2F;wikidocs.net&#x2F;21668 https:&#x2F;&#x2F;wikidocs.net&#x2F;21687 https:&#x2F;&#x2F;wikidocs.net&#x2F;21692  2장. 언어모델이란: 자연어의 의미를 임베딩에 어떻게 녹여낼 수 있는가? 그 비결은 자연어의 통계적 패턴 을 통째로 임베딩에 넣는 것이다.">
<meta property="og:locale" content="ko_KR">
<meta property="og:image" content="https://katie0809.github.io/image/Elegant_Background-2.jpg">
<meta property="article:published_time" content="2020-02-16T07:42:21.000Z">
<meta property="article:modified_time" content="2020-02-19T01:15:41.472Z">
<meta property="article:author" content="Kyungim Lee">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="자연어처리">
<meta property="article:tag" content="딥러닝">
<meta property="article:tag" content="언어모델">
<meta property="article:tag" content="한국어 임베딩">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://katie0809.github.io/image/Elegant_Background-2.jpg">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/monokai-sublime.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-158681991-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-158681991-1');
</script>

    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    
    


<link rel="stylesheet" href="/css/style.css">
<link rel="alternate" href="/rss2.xml" title="Dailycrush" type="application/rss+xml">
</head>
<body class="is-2-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo.svg" alt="[딥러닝 스터디] 자연어의 계산과 이해" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item" href="/">Home</a>
                
                <a class="navbar-item" href="/archives">Archives</a>
                
                <a class="navbar-item" href="/categories">Categories</a>
                
                <a class="navbar-item" href="/tags">Tags</a>
                
                <a class="navbar-item" href="/downloads">Downloads</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    <a class="navbar-item" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/katie0809">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="목차" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
                <a class="navbar-item search" title="검색" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-8-widescreen has-order-2 column-main">
<div class="card">
    
    <div class="card-image">
        <span class="image is-7by1">
            <img class="thumbnail" src="/image/Elegant_Background-2.jpg" alt="[딥러닝 스터디] 자연어의 계산과 이해">
        </span>
    </div>
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-02-16T07:42:21.000Z">2020-02-16</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/">개발자 공부</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/">인공지능</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    23분 소요 (약 3517 글자)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                [딥러닝 스터디] 자연어의 계산과 이해
            
        </h1>
        <div class="content">
            <p>다음의 책을 공부하며 정리한 내용입니다</p>
<ul>
<li>한국어 임베딩 - 이기창</li>
<li><a href="https://wikidocs.net/21668" rel="external nofollow noopener noreferrer" target="_blank">https://wikidocs.net/21668</a></li>
<li><a href="https://wikidocs.net/21687" rel="external nofollow noopener noreferrer" target="_blank">https://wikidocs.net/21687</a></li>
<li><a href="https://wikidocs.net/21692" rel="external nofollow noopener noreferrer" target="_blank">https://wikidocs.net/21692</a></li>
</ul>
<h2 id="2장-언어모델이란"><a href="#2장-언어모델이란" class="headerlink" title="2장. 언어모델이란"></a>2장. 언어모델이란</h2><p>: 자연어의 의미를 임베딩에 어떻게 녹여낼 수 있는가? 그 비결은 <code>자연어의 통계적 패턴</code> 을 통째로 임베딩에 넣는 것이다.</p>
<a id="more"></a>

<p>임베딩을 만드는 세가지 철학</p>
<table>
<thead>
<tr>
<th>구분</th>
<th>bag of words 가정</th>
<th>언어 모델</th>
<th>분포 가정</th>
</tr>
</thead>
<tbody><tr>
<td>내용</td>
<td>어떤 단어가 (많이) 쓰였는가</td>
<td>단어가 어떤 순서로 쓰였는가</td>
<td>어떤 단어가 같이 쓰였는가</td>
</tr>
<tr>
<td>대표 통계량</td>
<td>TF-IDF</td>
<td>-</td>
<td>PMI</td>
</tr>
<tr>
<td>대표 모델</td>
<td>Deep Averaging Network</td>
<td>ELMo, GPT</td>
<td>Word2Vec</td>
</tr>
</tbody></table>
<p>자연어의 의미는 해당 언어 사용자들이 실제 사용하는 일상 언어에서 드러난다. 따라서 실제 사람이 사용하는 자연어의 통계적 패턴정보를 임베딩에 넣는다면 임베딩에 자연어의 의미를 함축해 넣을 수 있다.</p>
<p>임베딩을 만들때 쓰는 통계정보는 크게 3가지가 있다.</p>
<p>첫째, 문장에 어떤 단어가 <code>(많이) 쓰였</code>는가</p>
<p>둘째, 단어가 어떤 <code>순서</code>로 등장하는가</p>
<p>셋째, 어떤 단어가 <code>같이</code> 나타났는가</p>
<hr>
<h3 id="2-1-어떤-단어가-많이-쓰였는가"><a href="#2-1-어떤-단어가-많이-쓰였는가" class="headerlink" title="2-1. 어떤 단어가 많이 쓰였는가"></a>2-1. 어떤 단어가 많이 쓰였는가</h3><ol>
<li><p>Bag of words 가정</p>
<ul>
<li>단어의 <em>등장 순서에 관계없이</em> 문서 내 <em>단어의 등장 빈도</em> 를 임베딩으로 쓰는 기법</li>
<li>저자가 생각한 <code>주제</code> 가 <code>분서에서의 단어 사용</code> 에 녹아들어있다는 가정을 바탕으로 한다.</li>
<li>정보 검색 분야에서 많이 사용한다. 사용자 질의를 백오브워즈 임베딩으로 변환 후 코사인 유사도가 가장 높은 문서를 사용자에게 노출한다.</li>
</ul>
</li>
<li><p>TF - IDF</p>
<ul>
<li>문서에 단순히 <strong>많이 나타나는</strong> 단어만으로 주제를 판단하기 어려울 수 있다.(예: 한국어 문서에는 조사 ‘을/를’이 많이 등장하지만 이를 통해 주제 파악은 어려움.)</li>
<li>이를 보안하기 위해 나타난 기법이 TF-IDF(Term Frequency-Inverse Document Frequency)</li>
<li><code>TF</code> : 어떤 단어가 특정 문서에 얼마나 쓰였는지의 빈도</li>
<li><code>DF</code> : 특정 단어가 나타난 문서의 수 </li>
<li><code>IDF</code> : log( 전체 문서의 수 / 특정 단어의 DF ) <ul>
<li>값이 클수록 특이한 단어임을 의미</li>
<li>단어가 <em>문서의 주제와 연관있을 정도</em>(주제 예측능력) 와 관련있다.</li>
</ul>
</li>
<li>단어의 주제 예측능력이 클수록 TF-IDF 값이 커진다.</li>
</ul>
</li>
<li><p>Deep Averaging Network</p>
<ul>
<li>백오브워즈 가정의 신경망 버전</li>
</ul>
</li>
</ol>
<hr>
<h3 id="2-2-단어가-어떤-순서로-쓰였는가"><a href="#2-2-단어가-어떤-순서로-쓰였는가" class="headerlink" title="2-2. 단어가 어떤 순서로 쓰였는가"></a>2-2. 단어가 어떤 순서로 쓰였는가</h3><p><img src="https://wikidocs.net/images/page/21668/%EB%94%A5_%EB%9F%AC%EB%8B%9D%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C.PNG" alt></p>
<ol start="0">
<li>언어 모델이란?<ul>
<li>언어 모델이란 딥러닝과 관계없이 이전부터 있었던 개념으로, 언어를 모델링하고자 <code>단어 시퀀스</code> 에 <code>확률을 부여</code> 하는 모델이다. </li>
<li>단어의 등장 순서를 무시하는 백오브 워즈와 달리 <code>시퀀스 정보를 명시적으로 학습</code> 한다. <u>따라서 백오브 워즈의 대척점</u>에 언어모델이 있다고 할 수 있다.</li>
<li>언어모델을 만드는 방법으로는 크게 1)통계를 이용한 방법과 2)신경망을 이용한 방법이 있다. </li>
</ul>
</li>
</ol>
<blockquote>
<p>잘 학습된 언어모델은 <u>어떤 문장이 더 자연스러운지</u>, 또한 주어진 단어 시퀀스 <u>다음에는 무엇이 오는게 자연스러운지</u>를 알수있다.</p>
</blockquote>
<p>이와 유사한 맥락에서 일각에서는 언어 모델을 <strong>문법(grammar)</strong> 이라 비유하기도 한다. 단어간의 조합이 얼마나 적절한지, 특정 문장이 얼마나 자연스러운지를 알려주는 언어모델의 역할이 마치 문법의 기능과 유사하기 때문이다.</p>
<p>단어가 n개 주어진 상황이라면 <code>언어모델은 n개 단어가 동시에 나타날 확률</code> , 즉 P(w1, w2… wn)을 반환한다.(단어 시퀀스에의 확률 할당)</p>
<p>이는 다음과 같이 사용할 수 있다. </p>
<h4 id="a-기계-번역-Machine-Translation"><a href="#a-기계-번역-Machine-Translation" class="headerlink" title="a. 기계 번역(Machine Translation):"></a><strong>a. 기계 번역(Machine Translation):</strong></h4><blockquote>
<p>P(나는 버스를 탔다) &gt; P(나는 버스를 태운다)</p>
</blockquote>
<p>: 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단합니다. </p>
<h4 id="b-오타-교정-Spell-Correction"><a href="#b-오타-교정-Spell-Correction" class="headerlink" title="b. 오타 교정(Spell Correction)"></a><strong>b. 오타 교정(Spell Correction)</strong></h4><p>선생님이 교실로 부리나케</p>
<blockquote>
<p>P(달려갔다) &gt; P(잘려갔다)</p>
</blockquote>
<p>: 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단합니다. </p>
<h4 id="c-음성-인식-Speech-Recognition"><a href="#c-음성-인식-Speech-Recognition" class="headerlink" title="c. 음성 인식(Speech Recognition)"></a><strong>c. 음성 인식(Speech Recognition)</strong></h4><blockquote>
<p>P(나는 메롱을 먹는다) &lt; P(나는 메론을 먹는다)</p>
</blockquote>
<p>: 언어 모델은 두 문장을 비교하여 우측의 문장의 확률이 더 높다고 판단합니다.</p>
<p>언어 모델은 위와 같이 확률을 통해 <strong>보다 적절한 문장을 판단한다.</strong></p>
<hr>
<h3 id="정리"><a href="#정리" class="headerlink" title="정리"></a>정리</h3><ul>
<li><p>언어를 모델링하고자 단어 시퀀스에 확률을 부여하는 모델로, 잘 학습된 언어모델은 어떤 시퀀스가 자연스러운지를 판단해낸다.</p>
</li>
<li><p>인간이 쓰는 자연어는 레이블이 없는 비지도 학습. 이를 지도학습과 같이 학습하도록 여러 방법을 사용</p>
</li>
<li><p>문제1) 비지도학습인 자연어를 어떻게 학습할 것인가?</p>
<p>: 이전 단어들이 주어졌을 때 다음 단어를 예측하도록 한다.</p>
</li>
<li><p>문제2) 각 단어시퀀스에 확률은 어떻게 할당할 것인가?</p>
<p>: 카운트 기반 접근방식 사용한다.</p>
</li>
</ul>
<hr>
<h3 id="언어모델의-종류"><a href="#언어모델의-종류" class="headerlink" title="언어모델의 종류"></a>언어모델의 종류</h3><ol>
<li><p>통계 기반 언어 모델(SLM: Statistical Language Model)</p>
<ul>
<li>통계 기반 언어모델은 말뭉치에서 해당 <code>단어 시퀀스가 얼마나 자주 등장하는지</code> 의 빈도를 세어서 학습한다.</li>
<li>문장은 문맥이라는 관계 내에서 단어들이 관계를 갖고 완성해낸 시퀀스이다. 따라서 특정 문장의 확률은 각 단어들의 <code>이전 단어가 주어졌을때 다음 단어로 등장할 확률의 곱</code> 으로 계산된다.</li>
</ul>
</li>
</ol>
<p>   즉, “나는 사과를 먹었다” 라는 문장의 확률은 다음과 같이 표현할 수 있다. (문장의 확률을 구하기 위해 다음 단어에 대한 예측 확률을 모두 곱한다.)</p>
<p>   <code>P(나는 사과를 먹었다) = P(나는) * P(사과를|나는) * P(먹었다|나는, 사과를)</code></p>
<blockquote>
<p>조건부 확률은 두개의 확률 P(A), P(B)에 대해 다음의 관계를 갖는다.</p>
<p>P(B|A)=P(A,B)/P(A)</p>
<p>P(A,B)=P(A)P(B|A)</p>
<p>더 많은 확률에 대해 일반화하면 다음과 같이 표현할 수 있다.</p>
<p>P(x1,x2,x3…xn)=P(x1)P(x2|x1)P(x3|x1,x2)…P(xn|x1…xn−1)</p>
<p>이를 조건부 확률의 연쇄법칙(chain rule) 이라고 한다.</p>
</blockquote>
<ul>
<li><p>이때 특정 시퀀스로부터 다음 단어가 나올 확률은 <strong>카운트에 기반해 계산</strong>할 수 있다.</p>
<p><img src="/image/screenshot3.png" alt></p>
</li>
</ul>
<ol start="2">
<li><p>N-gram 언어모델</p>
<ul>
<li><p>n-gram 언어모델은 통계 기반 언어모델의 일종으로 전통적 SLM과 같이 카운트에 기반한 통계적 접근을 사용한다. </p>
<p>: 이전의 <u>n-1개의 단어</u>를 보고 <strong>n번째 단어를 예측</strong>하는 방식</p>
</li>
<li><p>전통적 SLM과 달리 이전에 등장한 모든 단어가 아닌 <code>일부 단어만 고려</code> 하는 방법을 사용한다.</p>
</li>
<li><p>즉, n-gram에서 n은 n개의 단어, 혹은 n-gram에 기반한 언어모델을 의미한다. 말뭉치(corpus) 내 단어들을 <strong>n개씩 묶어서</strong> 그 빈도를 학습했다는 의미이다. </p>
</li>
</ul>
</li>
</ol>
<p>   <strong>한국어 언어 모델 예시</strong></p>
<table>
<thead>
<tr>
<th>문장</th>
<th>확률</th>
</tr>
</thead>
<tbody><tr>
<td>진이는 이 책을 세 번 읽었다</td>
<td>0.47</td>
</tr>
<tr>
<td>이 책이 진이한테 세 번 읽혔다</td>
<td>0.23</td>
</tr>
<tr>
<td>세 번이 진이한테 이 책을 읽혔다</td>
<td>0.07</td>
</tr>
</tbody></table>
<p>   : 자연스러운 한국어 문장에 높은 확률값을 부여한다.</p>
<table>
<thead>
<tr>
<th>표현</th>
<th>빈도</th>
</tr>
</thead>
<tbody><tr>
<td>영원히</td>
<td>104</td>
</tr>
<tr>
<td>기억될</td>
<td>29</td>
</tr>
<tr>
<td>최고의</td>
<td>3503</td>
</tr>
<tr>
<td>명작이다</td>
<td>298</td>
</tr>
<tr>
<td>영원히 기억될</td>
<td>7</td>
</tr>
<tr>
<td>기억될 최고의</td>
<td>1</td>
</tr>
<tr>
<td>최고의 명작이다</td>
<td>23</td>
</tr>
<tr>
<td>기억될 최고의 명작이다</td>
<td>17</td>
</tr>
<tr>
<td>영원히 기억될 최고의 명작이다</td>
<td>0</td>
</tr>
</tbody></table>
<ul>
<li>전통적 SLM에서는 문법적으로 전혀 문제가 없는 ‘영원히 기억될 최고의 명작이다’ 라는 문장에 0의 확률을 부여하게 된다. =&gt; 이 말뭉치에 한번도 나타난 적 없기 때문.</li>
<li>n-gram모델을 통해 이 문제를 일부 해결할 수 있다.</li>
<li><code>직전 n-1개 단어의 등장확률</code> 로 <strong>전체 단어 시퀀스 등장 확률</strong> 을 <strong><code>근사</code></strong> 하는 것이다!</li>
</ul>
<p>   ‘<strong>영원히 기억될 최고의</strong>‘ 시퀀스 뒤에 <code>명작이다</code> 라는 단어가 올 확률을 trigram으로 근사해보면 얼마일까?</p>
<p>   P(명작이다 | 영원히, 기억될, 최고의) <del>(유사)</del> P(명작이다 | 기억될, 최고의)</p>
<p>   = Freq(기억될, 최고의, 명작이다) / Freq(명작이다)</p>
<p>   = 17 / 298</p>
<ul>
<li>위와 같이 단어를 슬라이딩 해가면서 수식을 풀어 생각한다면 전체 문장 ‘영원히 기억될 최고의 작품이다’를 trigram으로 계산하기 위한 수식은 다음과 같다.</li>
<li><code>영원히 기억될</code> 이 등장할 확률 * <code>영원히 기억될</code> 뒤에 <code>최고의</code> 가 등장할 확률 * <code>기억될 최고의</code> 뒤에 <code>명작이다</code> 가 등장할 확률</li>
</ul>
<p>   [ 카운트 기반 접근방식의 <strong>본질적 한계</strong> ]</p>
<ul>
<li><p><strong><code>희소문제</code></strong> : Sparcity Problem</p>
<ul>
<li><p>여전히 희소문제는 존재한다. 코퍼스 내에 단어시퀀스가 없을(카운트하지 못할) 확률은 여전히 존재.</p>
</li>
<li><p>n의 선택은 trade-off : n의 크기를 키우면 예측의 정확도는 높아지지만, 코퍼스에서 해당 n개의 시퀀스를 카운트할 확률은 낮아짐(희소문제 증가), 모델사이즈 커짐. </p>
<p>반대로 n을 작게 선택하면 훈련 코퍼스에서 카운트는 잘 되겠지만 근사의 정확도는 현실의 확률분포와 멀어짐.</p>
<p>=&gt; <u>n은 최대 5</u>를 넘어서는 안된다고 권장됨.</p>
</li>
<li><p>NNLM(Neural Net Language Model)을 통해 <code>언어 모델 또한 단어의 유사도를 학습</code> 할 수 있도록 설계.</p>
<ul>
<li>훈련 코퍼스에 없는 단어 시퀀스도 예측을 통해 유사한 단어 시퀀스를 참고하여 확률을 계산해낸다.</li>
<li>워드 임베딩의 아이디어이기도 한다.</li>
<li>단어를 continuous한 밀집벡터의 형태로 표현하여 희소문제를 해결(?)</li>
</ul>
</li>
</ul>
</li>
<li><p><a href="https://wikidocs.net/22147" rel="external nofollow noopener noreferrer" target="_blank"><strong><code>long-term dependency</code></strong></a> : 정해진 개수의 전 토큰만을 보기 때문에 볼 수 있는 시퀀스의 범위가 한정됨.</p>
<ul>
<li>이는 모델의 정확도와 연관</li>
</ul>
<blockquote>
<p><u>An adorable little</u> boy is spreading (   ?   )</p>
</blockquote>
<p>위와 같은 문장이 있을 때 정답은 insults, smile 둘 중 하나라고 해보자. 문맥상 “<u>작고 사랑스러운</u> 아이가 (미소)를 퍼뜨렸다” 가 적절함을 알 수 있다.</p>
<p>하지만 만약 <u>작고 사랑스러운</u> 이라는 밑줄 친 부분을 예측에 고려하지 않는다면 엉뚱한 답 insults를 고를 수 있다.</p>
</li>
</ul>
<ol start="3">
<li><p>신경망 기반 언어모델</p>
<ul>
<li>카운트 기반 접근은 그 방식상 본질적인 한계를 갖는다. </li>
<li>이를 극복하기 위해 다양한 방법 시도되었지만(백오프, 스무딩) 본질적인 n-gram 언어모델(고정된 개수의 단어만을 입력으로 받아야한다)에 대한 취약점은 해결하지 못함.</li>
</ul>
</li>
</ol>
<p><strong>RNNLM</strong>(Recurrent Neural Network Language Model)</p>
<p><img src="https://wikidocs.net/images/page/46496/rnnlm1_final_final.PNG" alt></p>
<p>예문 <em>what will the fat cat sit on</em> 의 RNNLM 학습/사용 과정을 보자.</p>
<p>1) 훈련이 끝난 모델을 사용할 경우 </p>
<ul>
<li>RNNLM은 예측 과정에서 <strong>이전 시점의 출력을 현재 시점의 입력</strong>으로 한다. </li>
<li>RNNLM은 what을 입력받으면, will을 예`하고 이 will은 다음 시점의 입력이 되어 the를 예측한다. 이것이 반복되어 <u>네번째 시점의 cat</u>은 앞서 나온 <strong>what, will, the, fat이라는 시퀀스로 인해 결정된 단어</strong>가 된다.</li>
</ul>
<p>2) 모델을 훈련시키는 경우</p>
<ul>
<li>위의 샘플에 대해 <code>what will the fat cat sit 시퀀스를 모델의 입력</code>으로 넣으면, <strong>will the fat cat sit on를 예측하도록 훈련</strong>한다.</li>
<li>이때 <em>will, the, fat, cat, sit, on</em>은 <u>각 시점의 레이블(<strong><code>yt</code></strong>)</u>가 된다.</li>
<li>이러한 RNN 훈련 기법을 <strong>교사 강요(teacher forcing)</strong> 라고 한다.</li>
</ul>
<blockquote>
<p>교사 강요(teacher forcing) : 테스트(실제 모델 사용) 과정에서 t 시점의 출력이 t+1 시점의 입력으로 사용되는 RNN 모델을 훈련시킬 때 사용하는 <strong>훈련 기법</strong>입니다. </p>
<p>훈련할 때 교사 강요를 사용할 경우, 모델이 <u>t 시점에서 예측한 값</u>을 <strong>t+1 시점에 입력으로 사용하지 않고</strong>, t 시점의 레이블. 즉, <strong><code>실제 알고있는 정답</code></strong>을 t+1 시점의 입력으로 사용합니다.</p>
</blockquote>
<p><strong>RNNLM의 학습 구조</strong></p>
<p><img src="https://wikidocs.net/images/page/46496/rnnlm2_final_final.PNG" alt></p>
<p><img src="https://wikidocs.net/images/page/46496/rnnlm4_final.PNG" alt></p>
<ul>
<li>임베딩층 : et=lookup(xt)</li>
<li>은닉층 : ht=tanh(Wxet+Whht−1+b)</li>
<li>출력층 : yt^=softmax(Wyht+b)</li>
<li>사용되는 손실함수 : cross-entropy</li>
<li>학습 과정에서 학습되는 가중치 행렬 : E(임베딩 행렬), Wx, Wh, Wy</li>
</ul>
<hr>
<h3 id="2-3-어떤-단어가-같이-쓰였는가"><a href="#2-3-어떤-단어가-같이-쓰였는가" class="headerlink" title="2-3. 어떤 단어가 같이 쓰였는가"></a>2-3. 어떤 단어가 같이 쓰였는가</h3><h4 id="분포가정"><a href="#분포가정" class="headerlink" title="분포가정"></a>분포가정</h4><p>: 자연어 처리에서 <strong>분포</strong>란 특정 범위(=<strong>윈도우</strong>)내에 <code>동시에 등장하는 단어 또는 문맥의 집합</code> 을 가리킨다.</p>
<blockquote>
<p>어떤 단어 쌍이 비슷한 문맥 환경에서 자주 등장한다면 그 의미 또한 유사할 것이라는게 분포가정의 전제이다.</p>
</blockquote>
<p>즉, 자연어를 사용하는 화자들이 특정 단어를 <code>실제 어떻게 사용하는지 관찰</code> 함으로서 <strong>단어의 의미를 밝힐</strong> 수 있다는 의미.</p>

        </div>
        
        <div class="level is-size-7 is-uppercase">
            <div class="level-start">
                <div class="level-item">
                    <span class="is-size-6 has-text-grey has-mr-7">#</span>
                    <a class="has-link-grey -link" href="/tags/pytorch/" rel="tag">pytorch</a>, <a class="has-link-grey -link" href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/" rel="tag">딥러닝</a>, <a class="has-link-grey -link" href="/tags/%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8/" rel="tag">언어모델</a>, <a class="has-link-grey -link" href="/tags/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/" rel="tag">자연어처리</a>, <a class="has-link-grey -link" href="/tags/%ED%95%9C%EA%B5%AD%EC%96%B4-%EC%9E%84%EB%B2%A0%EB%94%A9/" rel="tag">한국어 임베딩</a>
                </div>
            </div>
        </div>
        
        
        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2020/02/16/yaml-exception/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">YAMLException: can not read a block mapping entry, Hexo</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2020/02/14/ai-study1/">
                <span class="level-item">[딥러닝 스터디] 임베딩이란</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <h3 class="title is-5 has-text-weight-normal">댓글</h3>
        <script>(function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/ko/sdk.js#xfbml=1&version=v2.8";
    fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
<div class="fb-comments" data-width="100%" data-href="https://katie0809.github.io/2020/02/16/ai-study2/" data-num-posts="5"></div>
<link rel="stylesheet" href="/css/facebook.css">
    </div>
</div>
</div>
                
                




<div class="column is-4-tablet is-4-desktop is-4-widescreen  has-order-3 column-right is-sticky">
    
        

    <div class="card widget" id="toc">
        <div class="card-content">
            <div class="menu">
                <h3 class="menu-label">
                    목차
                </h3>
                <ul class="menu-list"><li>
        <a class="is-flex" href="#2장-언어모델이란">
        <span class="has-mr-6">1</span>
        <span>2장. 언어모델이란</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#2-1-어떤-단어가-많이-쓰였는가">
        <span class="has-mr-6">1.1</span>
        <span>2-1. 어떤 단어가 많이 쓰였는가</span>
        </a></li><li>
        <a class="is-flex" href="#2-2-단어가-어떤-순서로-쓰였는가">
        <span class="has-mr-6">1.2</span>
        <span>2-2. 단어가 어떤 순서로 쓰였는가</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#a-기계-번역-Machine-Translation">
        <span class="has-mr-6">1.2.1</span>
        <span>a. 기계 번역(Machine Translation):</span>
        </a></li><li>
        <a class="is-flex" href="#b-오타-교정-Spell-Correction">
        <span class="has-mr-6">1.2.2</span>
        <span>b. 오타 교정(Spell Correction)</span>
        </a></li><li>
        <a class="is-flex" href="#c-음성-인식-Speech-Recognition">
        <span class="has-mr-6">1.2.3</span>
        <span>c. 음성 인식(Speech Recognition)</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#정리">
        <span class="has-mr-6">1.3</span>
        <span>정리</span>
        </a></li><li>
        <a class="is-flex" href="#언어모델의-종류">
        <span class="has-mr-6">1.4</span>
        <span>언어모델의 종류</span>
        </a></li><li>
        <a class="is-flex" href="#2-3-어떤-단어가-같이-쓰였는가">
        <span class="has-mr-6">1.5</span>
        <span>2-3. 어떤 단어가 같이 쓰였는가</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#분포가정">
        <span class="has-mr-6">1.5.1</span>
        <span>분포가정</span>
        </a></li></ul></li></ul></li></ul>
            </div>
        </div>
    </div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/">
            <span class="level-start">
                <span class="level-item">개발자 공부</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">14</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/JSP/">
            <span class="level-start">
                <span class="level-item">JSP</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/Javascript/">
            <span class="level-start">
                <span class="level-item">Javascript</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/">
            <span class="level-start">
                <span class="level-item">인공지능</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">11</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/%EA%B7%B8%EB%83%A5-%EA%B7%B8%EB%9F%B0-%EC%9D%BC%EC%83%81/">
            <span class="level-start">
                <span class="level-item">그냥 그런 일상</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/%EA%B7%B8%EB%83%A5-%EA%B7%B8%EB%9F%B0-%EC%9D%BC%EC%83%81/%EA%B7%B8%EB%A0%87%EA%B2%8C-%EB%B0%94%EB%B3%B4%EB%8A%94-%EC%95%84%EB%8B%98/">
            <span class="level-start">
                <span class="level-item">그렇게 바보는 아님</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/%EA%B7%B8%EB%83%A5-%EA%B7%B8%EB%9F%B0-%EC%9D%BC%EC%83%81/%EB%81%84%EC%A0%81%EB%81%84%EC%A0%81/">
            <span class="level-start">
                <span class="level-item">끄적끄적</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li></ul></li>
            </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Tag Cloud
        </h3>
        <a href="/tags/Attention/" style="font-size: 10px;">Attention</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/Keras/" style="font-size: 10px;">Keras</a> <a href="/tags/RNN/" style="font-size: 15px;">RNN</a> <a href="/tags/YAMLException/" style="font-size: 10px;">YAMLException</a> <a href="/tags/change-permission/" style="font-size: 10px;">change permission</a> <a href="/tags/folder-permission/" style="font-size: 10px;">folder permission</a> <a href="/tags/githubpage/" style="font-size: 10px;">githubpage</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/inflearn/" style="font-size: 10px;">inflearn</a> <a href="/tags/javascript/" style="font-size: 11.67px;">javascript</a> <a href="/tags/jsp/" style="font-size: 10px;">jsp</a> <a href="/tags/linear-regression/" style="font-size: 11.67px;">linear regression</a> <a href="/tags/logistic-regression/" style="font-size: 10px;">logistic regression</a> <a href="/tags/mac/" style="font-size: 10px;">mac</a> <a href="/tags/nuxtjs/" style="font-size: 11.67px;">nuxtjs</a> <a href="/tags/pytorch/" style="font-size: 20px;">pytorch</a> <a href="/tags/tensorflow/" style="font-size: 10px;">tensorflow</a> <a href="/tags/torchtext/" style="font-size: 10px;">torchtext</a> <a href="/tags/vue/" style="font-size: 11.67px;">vue</a> <a href="/tags/vuejs/" style="font-size: 11.67px;">vuejs</a> <a href="/tags/vueschool-io/" style="font-size: 11.67px;">vueschool.io</a> <a href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/" style="font-size: 18.33px;">딥러닝</a> <a href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D%EA%B8%B0%EC%B4%88/" style="font-size: 15px;">딥러닝기초</a> <a href="/tags/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1-%ED%9A%8C%EA%B7%80/" style="font-size: 10px;">로지스틱 회귀</a> <a href="/tags/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80/" style="font-size: 11.67px;">선형회귀</a> <a href="/tags/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D/" style="font-size: 13.33px;">순환신경망</a> <a href="/tags/%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8/" style="font-size: 16.67px;">언어모델</a> <a href="/tags/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%A0%84%EC%B2%98%EB%A6%AC/" style="font-size: 11.67px;">자연어 전처리</a> <a href="/tags/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/" style="font-size: 18.33px;">자연어처리</a> <a href="/tags/%EC%BC%80%EB%9D%BC%EC%8A%A4/" style="font-size: 10px;">케라스</a> <a href="/tags/%ED%95%9C%EA%B5%AD%EC%96%B4-%EC%9E%84%EB%B2%A0%EB%94%A9/" style="font-size: 15px;">한국어 임베딩</a>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo.svg" alt="[딥러닝 스터디] 자연어의 계산과 이해" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2020 Kyungim Lee&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> & <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/katie0809">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("ko");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'https://katie0809.github.io',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" rel="external nofollow noopener noreferrer" target="_blank">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>










<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="입력 하세요...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '포스트',
                PAGES: '페이지',
                CATEGORIES: '카테고리',
                TAGS: '태그',
                UNTITLED: '(제목없음)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>