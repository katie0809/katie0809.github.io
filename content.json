{"pages":[{"title":"Downloads","text":"인공지능자료 자연어처리 발표 참고자료 자연어처리 발표자료 자연어처리 발표자료2 자연어처리 발표자료3","link":"/downloads/index.html"}],"posts":[{"title":"[딥러닝 기초] 선형회귀 모델의 개선","text":"다음의 책을 공부하며 정리한 내용입니다 https://wikidocs.net/book/2788 nn.Module 을 사용한 선형회귀 모델의 개선: 파이토치에서 일부 모델(ex. 선형회귀모델)들은 이미 nn.Module의 형태로 편리하게 쓸 수 있도록 구현되어있다. 즉, 우리가 기존에 구현했던 선형회귀 수식 y_hat = (w * x_train) + b y_hat = x_train.matmul(w) + b 이는 아래와 같이 변경할 수 있다. model = nn.Linear(1, 1) model = nn.Linear(3, 1) : 이때 nn.Linear()은 선형회귀 모델을 의미하며 왼쪽부터 순서대로 input dimension, output dimension이다. input_dim : 가중치 w의 개수 output_dim : 가중치 w의 길이 nn.Linear 모델 사용해보기 nn.Linear( )에는 가중치w와 편향b가 저장되어있다. 이는 model.parameters( )로 불러올 수 있다. 12345678# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.import torchimport torch.nn as nnmodel = nn.Linear(1,1)# 출력되는 첫번째값이 w, 두번째값이 b. 랜덤 초기화되어있는 상태이다.print(list(model.parameters())) 1234[결과][Parameter containing:tensor([[0.5153]], requires_grad=True), Parameter containing:tensor([-0.4414], requires_grad=True)] 기존 선형회귀 코드의 개선: 기존 선형회귀 코드를 다음과 같이 개선할 수 있다. 개선 1123# 최종코드import torchtorch.manual_seed(1) torch.nn 까지 import 1234# 최종코드import torchimport torch.nntorch.manual_seed(1) 개선 2123456789101112131415for epoch in range(1000): # 새 학습값 y_hat = (w * x_train) + b # MSE함수통한 비용 계산 cost = torch.mean((y_train - y_hat) ** 2) # optimizer로 w,b 학습시킴으로서 y_hat 개선 # gradient를 0으로 초기화 optimizer.zero_grad() # 비용 함수를 미분하여 gradient 계산 cost.backward() # W와 b를 업데이트 optimizer.step() nn.Linear( )로 선언한 model로 y_hat 계산 F.mse_loss(prediction, y_train) 파이토치에서 제공하는 평균제곱함수로 cost 계산 1234567891011121314151617181920212223242526model = nn.Linear(1, 1) for epoch in range(1000): # 새 학습값 y_hat = model(x_train) # MSE함수통한 비용 계산 cost = F.mse_loss(y_hat, y_train) # optimizer로 w,b 학습시킴으로서 y_hat 개선 # gradient를 0으로 초기화 optimizer.zero_grad() # 비용 함수를 미분하여 gradient 계산 cost.backward() # W와 b를 업데이트 optimizer.step() # 임의의 입력 4를 선언new_var = torch.FloatTensor([[4.0]]) # 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장pred_y = model(new_var) # forward 연산# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된 것print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y) 12[결과]훈련 후 입력이 4일 때의 예측값 : tensor([[7.9989]], grad_fn=&lt;AddmmBackward&gt;) 위의 코드로 학습한 모델 model은 x_train, y_train에 대해 학습된 값 w,b 를 저장하고 있다. 학습된 모델 model을 활용해 새로운 값 x_new 에 대한 예측값 y_pred를 얻을 수 있다.","link":"/2020/02/17/ai-start3/"},{"title":"[딥러닝 기초] Linear Regression","text":"다음의 책을 공부하며 정리한 내용입니다 https://wikidocs.net/book/2788 선형회귀란: 선형 회귀란 학습 데이터와 가장 잘 맞는 하나의 직선을 찾는 일. 하나의 직선은 W와 b로 정의할 수 있다. 선형 회귀의 목표: 가장 잘 맞는 직선을 정의하는 W와 b의 값을 찾는 것. 파이토치에서의 선형회귀 선형 회귀 모델: nn.Linear() 평균 제곱오차: nn.functional.mse_loss() torch.manual_seed() : 현재의 코드를 재실행해도 다음에도 같은 결과가 나오도록 랜덤 시드(random seed)를 준다. 선형회귀 훈련을 위한 기본적인 코드의 뼈대는 아래와 같다 123456789101112131415161718192021222324252627# 1.훈련데이터의 선언# x_train의 벡터가 y_train이 되도록 하는 w와 b를 찾는다import torchx_train = torch.FloatTensor([[1], [2], [3]])y_train = torch.FloatTensor([[2], [4], [6]])# 2.가중치 W와 편향 b를 0으로 초기화# requires_grad: 학습을 통해 값이 변경되는 변수임을 명시.W = torch.zeros(1, requires_grad=True)b = torch.zeros(1, requires_grad=True)# 3.직선의 방정식(=선형회귀)에 해당되는 가설을 선언한다.# 가설 = 시스템이 학습한 w,b로 예측한 y_hat값hypothesis = x_train * W + b# print(hypothesis)# 4.사용할 비용함수 선언(MSE)cost = torch.mean((hypothesis - y_train) ** 2) # 5.W와 b를 SGD(경사하강법: Stochastic Gradient Descent)로 훈련시킨다# lr: learning rateoptimizer = torch.optim.SGD([W, b], lr=0.01) 이를 바탕으로 실제 동작하는 선형회귀 모델을 제작해 학습을 진행해보면 아래와 같다. 12345678910111213141516171819202122232425262728293031323334353637383940# 최종코드import torchtorch.manual_seed(1)# 훈련데이터 선언x_train = torch.FloatTensor([[1], [2], [3]])y_train = torch.FloatTensor([[2], [4], [6]])# 학습데이터 w,b 선언. 둘다 값이 1인 임의의 스칼라 텐서w = torch.zeros(1, requires_grad=True)b = torch.zeros(1, requires_grad=True)# SGD방식을 사용한 최적화 선언optimizer = torch.optim.SGD([w, b], lr=0.01)# 학습 횟수는 1000+1회tot_epoch = 1000for cur_epoch in range(tot_epoch + 1): # 새 학습값 y_hat = (w * x_train) + b # MSE함수통한 비용 계산 cost = torch.mean((y_train - y_hat) ** 2) # optimizer로 w,b 학습시킴으로서 y_hat 개선 # gradient를 0으로 초기화 optimizer.zero_grad() # 비용 함수를 미분하여 gradient 계산 cost.backward() # W와 b를 업데이트 optimizer.step() # 100번마다 로그 출력 if cur_epoch % 100 == 0: print('Epoch {:4d}/{} w: {:.3f}, b: {:.3f} Cost: {:.6f}'.format( cur_epoch, tot_epoch, w.item(), b.item(), cost.item() )) 123456789101112[결과]Epoch 0/1000 w: 0.187, b: 0.080 Cost: 18.666666Epoch 100/1000 w: 1.746, b: 0.578 Cost: 0.048171Epoch 200/1000 w: 1.800, b: 0.454 Cost: 0.029767Epoch 300/1000 w: 1.843, b: 0.357 Cost: 0.018394Epoch 400/1000 w: 1.876, b: 0.281 Cost: 0.011366Epoch 500/1000 w: 1.903, b: 0.221 Cost: 0.007024Epoch 600/1000 w: 1.924, b: 0.174 Cost: 0.004340Epoch 700/1000 w: 1.940, b: 0.136 Cost: 0.002682Epoch 800/1000 w: 1.953, b: 0.107 Cost: 0.001657Epoch 900/1000 w: 1.963, b: 0.084 Cost: 0.001024Epoch 1000/1000 w: 1.971, b: 0.066 Cost: 0.000633 위의 코드와 결과는 다음을 의미한다. x가 [1, 2, 3]일때 y가 [2,4,6]이 되는 w와 b는 2, 0이다. 학습을 통해 최종적으로 찾은 결과 w,b는 1.971, 0.066이므로 어느정도 답을 찾아냈다고 볼 수 있다. 다중선형회귀: 기존의 선형회귀가 y = wx + b의 w,b를 찾는 모델이었다면, 다중선형회귀는 y = w1x1 + w2x2 + w3x3 + b의 w1, w2, w3, b를 찾는 모델이다. 선형회귀 훈련을 위한 기본적인 코드의 뼈대는 아래와 같다. 123456789101112131415161718# N개의 x_train 벡터와 가중치 w는 행렬로 표현할 수 있다.# 5 * 3 학습벡터 =&gt; 길이 5의 x_train벡터 3개x_train = torch.FloatTensor([[73, 80, 75], [93, 88, 93], [89, 91, 90], [96, 98, 100], [73, 66, 70]]) # y_train벡터의 길이 = x_train벡터의 길이(5)y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])# 가중치 w의 개수 = x_train벡터의 개수(3) ** 길이는 1 **w = torch.zeros((3, 1) ,requires_grad=True)b = torch.zeros(1, requires_grad=True)# x_train과 y_train벡터가 각각 행렬이므로# 가설은 파이토치 행렬곱을 활용해 정의해준다. hypothesis = x_train.matmul(w) + b 이를 바탕으로 실제 동작하는 다중선형회귀 모델을 제작해 학습을 진행해보면 아래와 같다. 123456789101112131415161718192021222324252627282930313233# 학습을 위한 코드는 기존과 동일하다.import torchtorch.manual_seed(1)x_train = torch.FloatTensor([[73, 80, 75], [93, 88, 93], [89, 91, 90], [96, 98, 100], [73, 66, 70]]) y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])# 모델 초기화w = torch.zeros((3, 1) ,requires_grad=True)b = torch.zeros(1, requires_grad=True)# SGD방식을 사용한 최적화 선언optimizer = torch.optim.SGD([w, b], lr=1e-5)tot_epoch = 1000for cur_epoch in range(tot_epoch + 1): y_hat = x_train.matmul(w) + b cost = torch.mean((y_train - y_hat) ** 2) optimizer.zero_grad() cost.backward() optimizer.step() # 100번마다 로그 출력 if cur_epoch % 100 == 0: print('Epoch {:4d}/{} Cost: {:.6f}'.format( cur_epoch, tot_epoch, cost.item() )) 123456789101112[결과]Epoch 0/1000 Cost: 29661.800781Epoch 100/1000 Cost: 1.563628Epoch 200/1000 Cost: 1.497595Epoch 300/1000 Cost: 1.435044Epoch 400/1000 Cost: 1.375726Epoch 500/1000 Cost: 1.319507Epoch 600/1000 Cost: 1.266222Epoch 700/1000 Cost: 1.215703Epoch 800/1000 Cost: 1.167810Epoch 900/1000 Cost: 1.122429Epoch 1000/1000 Cost: 1.079390","link":"/2020/02/17/ai-start2/"},{"title":"[딥러닝 기초] Pytorch 기본연산","text":"다음의 책을 공부하며 정리한 내용입니다 https://wikidocs.net/book/2788 Pytorch 기본 연산: pytorch를 활용한 신경망 구성을 위해 필수적인 딥러닝 기본 연산단위를 알아보자. 벡터 행벡터 : 세로벡터 -&gt; tor.FloatTensor([0,1,2,3]) 열벡터 : 가로벡터 -&gt; tor.FloatTensor([0],[1],[2],[3]]) Tensor 딥러닝의 가장 기본적인 연산단위 : 벡터, 행렬, 텐서 0차원 : 스칼라 1차원 : 벡터 2차원 : 행렬 3차원 이상 : 텐서 2D Tensor : 행렬 2차원 텐서는 말그대로 ‘행렬‘이다. 따라서 2차원 텐서 t는 다음과 같이 나타낼 수 있다. |t| = (배치 사이즈, 차원) 행렬의 행의 개수 = 배치사이즈 행렬의 열의 개수 = 차원(dimension) 123456789101112131415t = tor.FloatTensor([0,1,2,3])print(t)print(t.dim(), t.size()) # rank(차원), 원소개수# 인덱스로 접근 가능하다print(t[1])# 정수 텐서lt = tor.LongTensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12] ])print(lt)print(lt[2], lt[2].size()) 12345678tensor([0., 1., 2., 3.])1 torch.Size([4])tensor(1.)tensor([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]])tensor([7, 8, 9]) torch.Size([3]) 3D Tensor 이미지/영상처리 분야에서는 보다 복잡한 텐서를 다룬다. 이미지는 가로/세로가 존재하며, 따라서 여러장의 이미지는 자연스레 (가로, 세로, 배치 크기) 가 됨을 연상할 수 있다. 3D Tensor in NLPNatural Language Processing(자연어처리)에서는 보통 (문장길이, 차원, 배치 크기) 라는 3차원 텐서를 사용한다.","link":"/2020/02/17/ai-start1/"},{"title":"[딥러닝 기초] 그래프 시각화","text":"데이터의 학습과정을 확인하고 분석하기 위해서는 이를 그래프로 시각화하는 과정이 필수적이다. matplotlib.pyplot 라이브러리를 활용해 그래프 시각화 테크닉을 익혀보자. 패키지 로딩1234import numpy as npimport matplotlib.pyplot as plt%matplotlib inline // jupyter notebook에서만 사용가능. 그래프를 새 창이 아닌 현재 실행중인 창에서 띄워준다. 점선 기본 그래프 그리기 : plt.plot(data): numpy array의 각 값들을 선으로 이은 기본 그래프 그린다. 123data = np.random.rand(50)plt.plot(data)plt.show() 여러 그래프 그리기 pyplot.subplot(행 개수, 열 개수, 그래프 그릴위치 index) 123plt.subplot(1, 2, 1) // 1 * 2의 판을 만든다. 그 중 첫번째 위치에 그래프를 그린다. plt.plot(data) // subplot으로 그래프 그릴 위치 정해주고 그래프 그리는 함수로 데이터 그려준다.plt.show() plot대신 사용가능한 함수 : hist() 히스토그램, scatter() 분산데이터 그래프 옵션 색상/마커 등 조절가능 : b, g, r, c, y, k, w / 원, 선, 별표 등 가능 1plt.plot(data, 'y') pyplot.figure(figsize=(10, 5)) : 그래프 가로세로 길이 조절가능하다 pyplot.legend() : 그래프 선 이름을 보여준다. pyplot.xlabel('name'), pyplot.ylabel('name') : x/y축 레이블을 보여준다. pyplot.savefig('saved_graph.svg') : 그래프 저장하기","link":"/2020/12/05/ai-start6/"},{"title":"[딥러닝 기초] ","text":"딥러닝을 하기 위한 텐서플로 기초 사용법입니다. 파이썬 numpy array를 활용해 기본적인 텐서를 생성하고, 생성된 텐서의 정보를 확인해보자. Tensor의 생성파이썬 numpy를 통해 생성한 배열/튜플/리스트는 텐서플로의 tf.constant() 함수를 통해 텐서로 변환할 수 있다. 12arr = np.array([1, 2, 3])tf.constant(arr) Tensor 정보 확인 tensor.shape : tensor의 shape 확인 tensor.dtype : tensor의 데이터 타입 확인 텐서 생성시에 데이터 타입을 정의해줄 수 있다. 1tensor = tf.constant([1, 2, 3], dtype=tf.float32) tf.cast() : data type 변환 numpy array는 numpy.astype()을 사용해 데이터 타입 변환한다. 1tf.cast(tensor, dtype=tf.uint8) tensor.numpy(), np.array(tensor), type(tensor.numpy()) : 텐서에서 numpy불러오기 난수 생성하기 numpy.random.rand(), tf.random.normal() : normal distribution의 난수 생성 tf.random.uniform() : uniform distribution의 난수 생성","link":"/2020/12/09/ai-start7/"},{"title":"[딥러닝 기초] Logistic Regression","text":"다음의 책을 공부하며 정리한 내용입니다 https://wikidocs.net/book/2788 로지스틱 회귀란: 로지스틱 회귀는 이진분류(Binary Classification) 문제의 해결에 사용되는 대표적인 알고리즘. 이름은 ‘회귀‘이지만 ‘분류‘에 쓰인다 이진분류의 모델 점수(x) 결과(y) 45 불합격 50 불합격 55 불합격 60 합격 65 합격 70 합격 위와 같은 데이터가 있다고 하자. 조건은 아래와 같다. 합격 커트라인은 알려져있지 않다 임의의 점수 x의 합격여부를 예측하고 싶다. 이 경우 주어진 데이터에 대해 합격(1), 불합격(0)으로 그래프를 그리면 아래와 같이 표현할 수 있다. 위의 간단한 예시를 통해 이진분류의 문제를 풀기위한 x, y의 관계는 S 형태의 그래프로 나타내야 함을 알 수 있다. 따라서 다음과 같은 결론을 얻을 수 있다. 로지스틱 회귀의 가설은 선형 회귀 때의 H(x)=Wx+b가 아니다. 위처럼 S자 모양의 그래프를 만들 수 있는 어떤 특정 함수 f를 추가적으로 사용하여 H(x)=f(Wx+b)의 가설을 사용한다. 어떤 함수 f는 이미 널리 알려져있다. =&gt; 시그모이드 함수 즉, 로지스틱 회귀의 가설이자 이진분류 문제를 풀기위한 함수 f는 Sigmoid function이다 Sigmoid 수식 H(x)=sigmoid(Wx+b)=1+e−(Wx+b)=σ(Wx+b) 가중치(w)의 변화에 따른 Sigmoid 함수 red: w값이 0.5 ~ blue: w값이 2 편향(b)의 변화에 따른 Sigmoid 함수 red: b값이 0.5 ~ blue: b값이 2 Sigmoid 함수의 특성 시그모이드 함수는 입력값이 한없이 커지면 1에 수렴하고, 입력값이 한없이 작아지면 0에 수렴한다. 시그모이드 함수의 출력은 0~1 위의 특성을 이용하여 분류 작업에 사용. 임계값 x(0 =&lt; x =&lt; 1)를 넘으면 1, 넘지 못하면 0으로 분류 결론 로지스틱 회귀의 가설/모델은 H(x)=sigmoid(Wx+b) 이다. 로지스틱 회귀 실습12345678910111213141516171819202122232425262728293031323334# 최종코드import torchimport torch.nn.functional as Ftorch.manual_seed(1)x_train = torch.FloatTensor([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]])y_train = torch.FloatTensor([[0], [0], [0], [1], [1], [1]])w = torch.zeros([2, 1], requires_grad=True)b = torch.zeros([1], requires_grad=True)# hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(w) + b)))hypothesis = torch.sigmoid(x_train.matmul(w) + b)optimizer = torch.optim.SGD([w, b], lr=1)tot_epoch = 1000for cur_epoch in range(tot_epoch + 1): y_hat = torch.sigmoid(x_train.matmul(w) + b) cost = F.binary_cross_entropy(y_hat, y_train) optimizer.zero_grad() cost.backward() optimizer.step() # 100번마다 로그 출력 if cur_epoch % 100 == 0: print('Epoch {:4d}/{} Cost: {:.6f}'.format(cur_epoch, tot_epoch, cost.item())) # 제대로 학습됐는지 확인print(w)print(b) 123456789101112131415[결과]Epoch 0/1000 Cost: 0.693147Epoch 100/1000 Cost: 0.134722Epoch 200/1000 Cost: 0.080643Epoch 300/1000 Cost: 0.057900Epoch 400/1000 Cost: 0.045300Epoch 500/1000 Cost: 0.037261Epoch 600/1000 Cost: 0.031672Epoch 700/1000 Cost: 0.027556Epoch 800/1000 Cost: 0.024394Epoch 900/1000 Cost: 0.021888Epoch 1000/1000 Cost: 0.019852tensor([[3.2530], [1.5179]], requires_grad=True)tensor([-14.4819], requires_grad=True)","link":"/2020/02/17/ai-start4/"},{"title":"[딥러닝 기초] Tensor의 이해와 Numpy기초","text":"딥러닝의 Tensor =&gt; numpy array로 주로 표현한다. Tensor의 기본에 대해 이해하고 python numpy의 기본 도구들을 익히자 Tensor의 이해0차원(scalar)12345import numpy as nparr = np.array(5)arr.shapearr.ndim 12Out: ()Out: 0 스칼라로 들어간 넘파이 배열. shape가 아무것도 없는 것으로 나온다. 1차원(vector)12arr = np.array([5])arr.shape 1Out: (1,) numpy에서 1차원 텐서의 shape을 표현할때 (1)이 아닌 (1, ) 과 같이 표현한다. 이건 shape이기 때문에 1이라는 값이 들어갔다는게 아니다. 1차원에 1개의 값이 들어갔다는 의미. 마찬가지로 예를들어 (3, ) 은 1차원에 3개의 값이 들어갔다는 의미이다. 2차원(matrix)12arr = np.array([[1,2,3], [1,2,3]])arr.shape 1Out: (2, 3) 다차원12arr = np.array([[[1],[2],[3]], [[1],[2],[3]], [[1],[2],[3]]])arr.shape 1Out: (3, 3, 1) Numpy기초0과 1로 채워진 numpy array만들기 np.zeros() : 0으로 채워진 numpy array 만들기 np.ones() : 1으로 채워진 numpy array 만들기 1234zeros = np.zeros([2, 3])ones = np.ones([3, 2])zerosones 1234567Out:array([[0., 0., 0.], [0., 0., 0.]]) array([[1., 1.], [1., 1.], [1., 1.]]) 특정 범위의 숫자로 채워진 numpy array만들기 np.arrange(M, N) : M부터 N-1까지의 수로 채워진 numpy array를 만들어준다 12arr = np.arrange(4, 7)arr 12Out:array([4, 5, 6]) (응용) reshape와 섞어서 쓰기12arr = np.arrange(4, 8).reshape(2, 2)arr 123Out:array([4, 5], [6, 7]) (응용) array의 index로 접근하기1234nums = [1, 2, 3, [1, 2, 3, 4]]arr[1]arr[1, 0]nums[4] 1234Out:array([6, 7])6[1, 2, 3, 4] (응용) index로 slicing하기123arr = np.arrange(9).reshape(3, 3)arr[1:]arr[1:, 1:] 1234array([3, 4, 5], [6, 7, 8])array([4, 5], [7, 8]) (응용) Boolean indexing12data = np.random().radn(2, 2) // 랜덤한 숫자로 2*2 배열 생성data &lt;= 0 // 0보다 작은 숫자 이렇게 boolean으로 바로 찾을수도 있다. 123Out:array([ True, False], [False, False]) Broadcast 연산하려는 행렬의 shape, 값 등을 조정하기 위한 테크닉 알 필요가 있다. 1234arr = np.arrange(9).reshape(3, 3)arr + 3 // 모든 값에 3씩 더해준다arr + np.array([1, 2, 3]) // 각 행마다 [1, 2, 3]을 더해준다arr * 3 // 모든 값에 3을 곱해준다 기타 np.argmax(arr) : 가장 값이 큰 value의 인덱스를 반환한다. argmin()도 있다. np.unique(arr) : array안에 있는 unique한 값들을 numpy array형태로 반환해준다. np.dtype() : array의 data type(dtype)을 반환해준다. 기본적으로 그냥 [1, 2, 3] 뭐 이렇게 넣으면 알아서 ‘int64’ 타입으로 들어간다. 배열 생성시에 데이터 타입을 지정해줄 수도 있다 : (예시) np.array([[1., 2, 3], [1, 2, 3]], dtype=np.uint8) np.astype(‘data type’) : 값의 data type을 원하는 타입으로 변환해준다. np.ndim() : 차원 수를 return np.size() : size 확인 np.reshape() : resize()와는 다르게 사이즈는 유지하면서 모양/차원만 바꿔준다. -1 활용.차원 바꿔주고싶은데 해당 차원에 몇개 들어가야할지 정확히 모를때 그냥 -1쓰면 알아서 계산해서 바꿔준다. 일종의 물음표라고 생각하면 된다.1234arr = np.array([[1, 2, 3], [1, 2, 3]])arr.reshape([6]).shape // (6, ) =&gt; 1차원 array로 바뀜arr.reshape([-1]).shape // (6, ) =&gt; 1차원으로 바꿔주는데 몇개인지 모를때 그냥 알아서 1차원으로 바꿔줌arr.reshape([-1, 2]).shape // (3, 2) =&gt; (?, 2)로 바꿔달라는 말과 동일하며, 알아서 맞춰서 (3, 2)의 배열로 변환해준다. 사이즈 변동이 없는 선에서 차원을 늘릴 수 있다. 12arr = np.array([[1, 2, 3], [1, 2, 3]]) // (2, 3)arr.reshape(2, 3, 1, 1) // (2, 3, 1, 1) np.random.rand(M, N, …) : (M, N, …) 차원의 배열을 랜덤한 숫자로 채워 생성한다. np.ravel() : 차원을 1차원으로 바꿔서 펼쳐준다. Layer의 flatten을 위한 기능이라고 생각하면 된다. 값을 유지하며 차원을 늘리자 : np.expand_dims(): reshape으로도 차원을 늘릴 수는 있지만 동일한 형태 유지하면서 차원만 늘리려면 안에 들어있는 값 개수를 알아야 한다. 개수를 모를때 차원을 늘리기 위해 사용할 수 있는 함수가 expand_dims() 1234arr.expand_dims( arr, // 차원을 늘릴 numpy array 0 // 0: 차원을 뒤에 붙임, -1: 차원을 앞에 붙임)","link":"/2020/12/05/ai-start5/"},{"title":"[딥러닝 스터디] 임베딩이란","text":"다음의 책을 공부하며 정리한 내용입니다 한국어 임베딩 - 이기창 1장. 임베딩이란: 임베딩이란 자연어를 벡터로 바꾼 결과 혹은 그 일련의 과정 전체를 의미하는 용어이다. 임베딩에는.. 말뭉치(corpus)의 의미, 문법 정보가 응축되어있다. 벡터이기 때문에 사칙연산이 가능하다 단어/문서 관련도를 계산할 수 있다. 대규모 말뭉치(corpus)를 미리 학습한 임베딩을 다른 문제를 푸는 데에 재사용 할 수 있다(전이학습) 임베딩 품질이 좋으면 단순한 모델로도 원하는 성능을 낼 수 있다. 따라서 자연어 처리 모델의 구성과 서비스에 있어 가장 중요한 구성요소 중 하나는 임베딩이라고 꼽을 수 있다. 임베딩 소스코드 내려받기 : 다양한 논문 저자들이 공개한 실제 임베딩 코드를 통해 자신만의 임베딩을 구축할 수 있다. 1-1. 임베딩이란 임베딩이란 사람이 쓰는 자연어 를 기계가 이해할 수 있는 숫자의 나열인 벡터 로 바꾼 결과/일련의 과정 을 의미한다. 이는 단어나 문장 각각을 벡터로 변환해 벡터공간으로 끼워넣는다 는 의미에서 임베딩이란 이름이 붙게 되었다. 가장 간단한 임베딩은 단어의 빈도를 벡터로 사용하는 것이다. 근대 소설 작품 몇 편에 나오는 단어 기차 , 막걸리 , 선술집 의 예시를 통해 알아보자. 구분 메밀꽃 필 무렵 운수좋은 날 사랑손님과 어머니 삼포가는 길 기차 0 2 10 7 막걸리 0 1 0 0 선술집 0 1 1 0 기차의 임베딩은 [0,2,10,7], 막걸리의 임베딩은 [0,1,0,0], 선술집의 임베딩은 [0,1,1,0]이다. 이를 바탕으로 우리는 기차(blue)-막걸리(red)간 의미차이가 선술집(orange)-막걸리(red)간 의미 차이보다 크다는 것을 알 수 있다. 1-2. 임베딩의 역할임베딩의 역할은 위에서 언급한 것과 같이 크게 3가지로 분류할 수 있다. 단어/문장 간 관련도 계산 : 임베딩된 단어(벡터)는 단어 간 유사도를 계산할 수 있다.(코사인 유사도) 의미적/문법적 정보 함축 : 임베딩은 벡터 인 만큼 사칙연산이 가능하다. 따라서 임베딩된 단어는 사칙 연산을 통해 단어간의 의미적/문법적 관계를 도출해낼 수 있다. 예를 들어 품질이 좋은 임베딩은 다음의 관계를 도출해낼 수 있다. 아들 - 딸 + 소녀 = 소년 전이 학습 : 임베딩은 자주 다른 딥러닝 모델의 입력값으로 쓰인다. 이를 전이학습이라고 한다. 1-3. 임베딩 기법의 역사와 종류임베딩 기법의 발전흐름과 종류는 다음과 같이 정리할 수 있다. 1) 통계기반에서 뉴럴 네트워크 기반으로 초기 임베딩 기법은 말뭉치의 통계량을 직접적으로 활용 최근에는 신경망 기반의 임베딩 기법이 사용된다 : 다음/이전/중간 단어의 예측을 해내는 과정에서 학습 2) 단어 수준에서 문장 수준으로 2017년 이전의 임베딩 기법은 대게 단어수준 모델이었다 : NPLM, Word2Vec, GloVe, FastText, Swivel 등 이는 동음이의어를 분간하기 어렵다는 문제가 있다 : 사람의 눈 과 하늘에서 내리는 눈 은 엄연히 다르지만 임베딩 벡터는 하나. 2018년 이후 문장수준 임베딩 기법들이 주목받았다 : BERT, GPT, ELMo 문장수준 임베딩 기법은 개별 단어가 아닌 단어 시퀀스 전체의 문맥적 의미를 함축한다. 따라서 단어임베딩보다 학습 효과가 좋다. 다의어 ‘bank’를 문맥에 따라 시각화한 모습. 의미가 다른 단어를 분리해 이해할 수 있다. 3) Pre-train/Fine-tuning 모델로 90년대 자연어 처리 모델 : 사람이 직접 모델의 입력값을 선정. 2000년대 이후 : 데이터를 통째로 모델에 넣고 입출력 사이의 관계 를 사람의 개입없이 모델 스스로 이해해내도록 유도한다. 이러한 기법을 엔드 투 엔드 모델 이라고 한다. 대표적으로 시퀀스 투 시퀀스 모델이 있다. 2018년 이후 : 엔드투 엔드 방식에서 벗어나 pretrain/fine tuning 방식으로 발전해나가고 있다. 대규모 말뭉치로 임베딩을 만든다(프리트레인) : 이 말뭉치에는 단어의 의미/문법적 맥락이 포함되어있다. 임베딩을 입력으로 하는 새로운 딥러닝 모델을 만들고, 풀고자 하는 문제에 맞춰 임베딩을 포함한 모델 전체를 업데이트 한다.(파인 튜닝, 전이 학습) : ELMo, GPT, BERT 등이 해당 [용어 이해하기] 다운스트림 태스크 : 풀고자 하는 구체적 자연어처리 문제들. 품사판별, 개채명 인식, 의미역 분석 등이 있다. 업스트림 태스크 : 다운스트림 태스크에 앞서 해결해야할 과제. 단어/문장 임베딩을 프리트레인하는 과정이 이에 해당. 4) 임베딩의 종류와 성능 : 임베딩 기법은 크게 3가지로 나뉜다. 행렬분해 기반 방법 말뭉치 정보가 들어있는 기존의 행렬을 두 개 이상의 작은 행렬로 쪼개는 임베딩 기법 GloVe, Sweivel등이 이에 해당 예측 기반 방법 어떤 단어 주변에 특정 단어가 나타날지 예측하거나, 이전/다음/중간의 단어가 무엇일지 맞추는 과정에서 학습하는 임베딩 기법 신경망 기반 임베딩 기법이 이러한 예측 기반 방법에 속한다 : Word2Vec, FastText, BERT, ELMo, GPT 등이 이에 해당 토픽 기반 방법 주어진 문서에 잠재된 주제를 추론하는 방식 의 임베딩 기법 잠재 디리클레 할당이 대표적 기법이다.","link":"/2020/02/14/ai-study1/"},{"title":"[딥러닝 스터디] 순환신경망(RNN)","text":"다음의 책을 공부하며 정리한 내용입니다. https://wikidocs.net/22886 순환신경망(RNN : Recurrent Neural Network): RNN은 입력과 출력을 시퀀스 단위로 처리하는 시퀀스 모델이다. 이때의 입력은 처리하고자 하는 문장, 즉 단어 시퀀스이며, 출력은 처리된 문장 단어 시퀀스이다. RNN의 가장 큰 특징은 은닉층의 노드에서 나온 결과값이 출력층 과 은닉층 노드의 다음 계산을 위한 입력으로, 둘 모두로 보내진다는 점이다. xt : 입력층의 입력 벡터 yt : 출력층의 출력 벡터 cell : 은닉층에서 결과를 두 방향으로 내보내는(출력층 &amp; 다음연산) 노드. 메모리 셀 혹은 RNN셀이라고 표현한다. 이때 메모리 셀이 두 방향으로 내보내는 결과를 은닉상태(hidden state) 라고 한다. 피드포워드 신경망에서는 기본적으로 뉴런이라는 단위를 사용했지만, RNN에서는 입력층/출력층 -&gt; 입력벡터/출력벡터 은닉층 -&gt; 은닉상태 의 표현을 일반적으로 사용한다. 피드포워드 신경망과 같이 뉴런 단위로 RNN을 시각화할 경우 아래와 같이 표현할 수 있다. 입력벡터 차원(입력층의 뉴런 수) : 4 은닉상태 크기(은닉층의 뉴런 수) : 2 출력벡터 차원(출력층의 뉴런 수) : 2 시점(timestep) : 2 RNN의 활용: RNN은 입력과 출력의 길이가 고정되어 있지 않다. 즉, 설계에 따라 다양한 용도로 신경망을 사용할 수 있다. 일대다 모델 하나의 이미지 입력에 대해서 사진의 제목을 출력하는 이미지 캡셔닝(Image Captioning) 작업에 사용할 수 있다. 사진의 제목은 단어들의 나열이므로 시퀀스 출력이다. 다대일 모델 단어 시퀀스에 대해서 하나의 출력(many-to-one)을 하는 모델. 입력 문서가 긍정적인지 부정적인지를 판별하는 감성 분류(sentiment classification), 또는 메일이 정상 메일인지 스팸 메일인지 판별하는 스팸 메일 분류(spam detection)에 사용할 수 있다. 위 그림은 RNN으로 스팸 메일을 분류할 때의 아키텍처를 보여줍니다. 다대다 모델 다 대 다(many-to-many)의 모델의 경우에는 입력 문장으로 부터 대답 문장을 출력하는 챗봇과 입력 문장으로부터 번역된 문장을 출력하는 번역기, 개체명 인식이나 품사 태깅과 같은 작업이 속한다. 위 그림은 개체명 인식을 수행할 때의 RNN 아키텍처를 보여줍니다. RNN의 수식 ht : 현재시점 t에서의 은닉 상태값 wx : 입력층의 입력값에 대한 가중치 wt : 이전시점 t-1의 은닉상태값 ht-1 에 대한 가중치 wh 따라서 ht를 계산하는 수식은 다음과 같다. ht = activation_func((wh * ht-1) + (wx * xt) + b) 이때 활성화 함수는 일반적으로 tanh함수를 사용한다. ReLU를 사용하기도 한다. 출력층 값 yt는 아래와 같이 계산한다. yt = activation_func((wy * ht) + b) 이때 비선형 활성화 함수 중 하나를 activation func으로 사용한다. (실습) 파이썬으로 RNN 구현하기1234567891011121314151617181920import torchimport torch.nn as nn# 입력과 은닉상태의 크기를 정의한다.input_size = 5hidden_size = 8# 입력텐서(=입력벡터)를 정의한다. # (배치크기 * 시점의 수 * 입력크기)를 인자로 받는다.input_vec = torch.Tensor(1, 10, input_size)# nn.RNN()으로 RNN셀을 정의한다.# (입력크기 * 은닉상태 크기)를 인자로 받는다. batch_first=True는 입력텐서의 첫번째 차원이 배치크기임을 알려준다.cell = nn.RNN(input_size, hidden_size, batch_first=True)# 입력텐서를 RNN셀에 넣어 출력값의 크기를 확인해본다.# (모든 시점의 은닉상태들, 마지막 시점의 은닉상태)를 반환한다.outputs, final_output = cell(input_vec)print(outputs.shape)print(final_output.shape) 123[결과]torch.Size([1, 10, 8])torch.Size([1, 1, 8]) 다양한 순환신경망 깊은 순환신경망(Deep Recurrent Neural Network) : RNN역시 다수의 은닉층을 가질 수 있다. 2개 이상의 은닉층을 가진 RNN을 Deep RNN이라고 한다. 깊은 순환 신경망은 nn.RNN()의 인자로 num_layers 파라미터를 추가해줌으로서 구현할 수 있다. 12# (입력텐서 크기, 은닉층 크기, 은닉층 개수)cell = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True) 이때 마지막 시점의 은닉상태는 다음과 같이 바뀐다. 1234print(final_output.shape) # (층의 개수, 배치 크기, 은닉 상태의 크기)&gt;&gt; torch.Size([2, 1, 8]) 양방향 순환신경망(Bidirectional Recurrent Neural Network) : 양방향 순환신경망은 특정 시점 t에서 출력값 ht를 예측할 때 이전시점의 데이터 ht-1뿐만 아니라 이후시점의 데이터로도 예측할 수 있다는 아이디어에서 출발한다. (예제) 12345Exercise is very effective at [ ] belly fat. 1) reducing2) increasing3) multiplying 정답 reducing을 찾기 위해서는 이전에 나온 단어와 이후에 나온 단어 모두를 참고\\해야 결정할 수 있다. 즉, 양방향 RNN은 이전 시점의 데이터뿐만 아니라, 이후 시점의 데이터도 힌트로 활용하기 위해서 고안된 모델이다. 양방향 순환 신경망은 하나의 출력값 ht를 예측하기 위해 두개의 메모리 셀을 사용 한다. 첫번째 메모리 셀은 앞 시점의 은닉상태를 전달받아 계산한다. 두번째 메모리 셀은 뒤 시점의 은닉상태를 전달받아 계산한다. 양방향 RNN도 다수의 은닉층을 가질 수 있다. nn.RNN()의 인자로 bidirectional값을 True로 전달하여 구현할 수 있다. 12# (입력텐서 크기, 은닉층 크기, 은닉층 개수, 양방향 여부)cell = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True, bidirectional=True) 이때 마지막 시점의 은닉상태는 다음과 같이 바뀐다. 1234print(final_output.shape) # (층의 개수 * 2, 배치 크기, 은닉 상태의 크기)&gt;&gt; torch.Size([4, 1, 8])","link":"/2020/02/17/ai-study3/"},{"title":"[딥러닝 스터디] 자연어의 계산과 이해","text":"다음의 책을 공부하며 정리한 내용입니다 한국어 임베딩 - 이기창 https://wikidocs.net/21668 https://wikidocs.net/21687 https://wikidocs.net/21692 2장. 언어모델이란: 자연어의 의미를 임베딩에 어떻게 녹여낼 수 있는가? 그 비결은 자연어의 통계적 패턴 을 통째로 임베딩에 넣는 것이다. 임베딩을 만드는 세가지 철학 구분 bag of words 가정 언어 모델 분포 가정 내용 어떤 단어가 (많이) 쓰였는가 단어가 어떤 순서로 쓰였는가 어떤 단어가 같이 쓰였는가 대표 통계량 TF-IDF - PMI 대표 모델 Deep Averaging Network ELMo, GPT Word2Vec 자연어의 의미는 해당 언어 사용자들이 실제 사용하는 일상 언어에서 드러난다. 따라서 실제 사람이 사용하는 자연어의 통계적 패턴정보를 임베딩에 넣는다면 임베딩에 자연어의 의미를 함축해 넣을 수 있다. 임베딩을 만들때 쓰는 통계정보는 크게 3가지가 있다. 첫째, 문장에 어떤 단어가 (많이) 쓰였는가 둘째, 단어가 어떤 순서로 등장하는가 셋째, 어떤 단어가 같이 나타났는가 2-1. 어떤 단어가 많이 쓰였는가 Bag of words 가정 단어의 등장 순서에 관계없이 문서 내 단어의 등장 빈도 를 임베딩으로 쓰는 기법 저자가 생각한 주제 가 분서에서의 단어 사용 에 녹아들어있다는 가정을 바탕으로 한다. 정보 검색 분야에서 많이 사용한다. 사용자 질의를 백오브워즈 임베딩으로 변환 후 코사인 유사도가 가장 높은 문서를 사용자에게 노출한다. TF - IDF 문서에 단순히 많이 나타나는 단어만으로 주제를 판단하기 어려울 수 있다.(예: 한국어 문서에는 조사 ‘을/를’이 많이 등장하지만 이를 통해 주제 파악은 어려움.) 이를 보안하기 위해 나타난 기법이 TF-IDF(Term Frequency-Inverse Document Frequency) TF : 어떤 단어가 특정 문서에 얼마나 쓰였는지의 빈도 DF : 특정 단어가 나타난 문서의 수 IDF : log( 전체 문서의 수 / 특정 단어의 DF ) 값이 클수록 특이한 단어임을 의미 단어가 문서의 주제와 연관있을 정도(주제 예측능력) 와 관련있다. 단어의 주제 예측능력이 클수록 TF-IDF 값이 커진다. Deep Averaging Network 백오브워즈 가정의 신경망 버전 2-2. 단어가 어떤 순서로 쓰였는가 언어 모델이란? 언어 모델이란 딥러닝과 관계없이 이전부터 있었던 개념으로, 언어를 모델링하고자 단어 시퀀스 에 확률을 부여 하는 모델이다. 단어의 등장 순서를 무시하는 백오브 워즈와 달리 시퀀스 정보를 명시적으로 학습 한다. 따라서 백오브 워즈의 대척점에 언어모델이 있다고 할 수 있다. 언어모델을 만드는 방법으로는 크게 1)통계를 이용한 방법과 2)신경망을 이용한 방법이 있다. 잘 학습된 언어모델은 어떤 문장이 더 자연스러운지, 또한 주어진 단어 시퀀스 다음에는 무엇이 오는게 자연스러운지를 알수있다. 이와 유사한 맥락에서 일각에서는 언어 모델을 문법(grammar) 이라 비유하기도 한다. 단어간의 조합이 얼마나 적절한지, 특정 문장이 얼마나 자연스러운지를 알려주는 언어모델의 역할이 마치 문법의 기능과 유사하기 때문이다. 단어가 n개 주어진 상황이라면 언어모델은 n개 단어가 동시에 나타날 확률 , 즉 P(w1, w2… wn)을 반환한다.(단어 시퀀스에의 확률 할당) 이는 다음과 같이 사용할 수 있다. a. 기계 번역(Machine Translation): P(나는 버스를 탔다) &gt; P(나는 버스를 태운다) : 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단합니다. b. 오타 교정(Spell Correction)선생님이 교실로 부리나케 P(달려갔다) &gt; P(잘려갔다) : 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단합니다. c. 음성 인식(Speech Recognition) P(나는 메롱을 먹는다) &lt; P(나는 메론을 먹는다) : 언어 모델은 두 문장을 비교하여 우측의 문장의 확률이 더 높다고 판단합니다. 언어 모델은 위와 같이 확률을 통해 보다 적절한 문장을 판단한다. 정리 언어를 모델링하고자 단어 시퀀스에 확률을 부여하는 모델로, 잘 학습된 언어모델은 어떤 시퀀스가 자연스러운지를 판단해낸다. 인간이 쓰는 자연어는 레이블이 없는 비지도 학습. 이를 지도학습과 같이 학습하도록 여러 방법을 사용 문제1) 비지도학습인 자연어를 어떻게 학습할 것인가? : 이전 단어들이 주어졌을 때 다음 단어를 예측하도록 한다. 문제2) 각 단어시퀀스에 확률은 어떻게 할당할 것인가? : 카운트 기반 접근방식 사용한다. 언어모델의 종류 통계 기반 언어 모델(SLM: Statistical Language Model) 통계 기반 언어모델은 말뭉치에서 해당 단어 시퀀스가 얼마나 자주 등장하는지 의 빈도를 세어서 학습한다. 문장은 문맥이라는 관계 내에서 단어들이 관계를 갖고 완성해낸 시퀀스이다. 따라서 특정 문장의 확률은 각 단어들의 이전 단어가 주어졌을때 다음 단어로 등장할 확률의 곱 으로 계산된다. 즉, “나는 사과를 먹었다” 라는 문장의 확률은 다음과 같이 표현할 수 있다. (문장의 확률을 구하기 위해 다음 단어에 대한 예측 확률을 모두 곱한다.) P(나는 사과를 먹었다) = P(나는) * P(사과를|나는) * P(먹었다|나는, 사과를) 조건부 확률은 두개의 확률 P(A), P(B)에 대해 다음의 관계를 갖는다. P(B|A)=P(A,B)/P(A) P(A,B)=P(A)P(B|A) 더 많은 확률에 대해 일반화하면 다음과 같이 표현할 수 있다. P(x1,x2,x3…xn)=P(x1)P(x2|x1)P(x3|x1,x2)…P(xn|x1…xn−1) 이를 조건부 확률의 연쇄법칙(chain rule) 이라고 한다. 이때 특정 시퀀스로부터 다음 단어가 나올 확률은 카운트에 기반해 계산할 수 있다. N-gram 언어모델 n-gram 언어모델은 통계 기반 언어모델의 일종으로 전통적 SLM과 같이 카운트에 기반한 통계적 접근을 사용한다. : 이전의 n-1개의 단어를 보고 n번째 단어를 예측하는 방식 전통적 SLM과 달리 이전에 등장한 모든 단어가 아닌 일부 단어만 고려 하는 방법을 사용한다. 즉, n-gram에서 n은 n개의 단어, 혹은 n-gram에 기반한 언어모델을 의미한다. 말뭉치(corpus) 내 단어들을 n개씩 묶어서 그 빈도를 학습했다는 의미이다. 한국어 언어 모델 예시 문장 확률 진이는 이 책을 세 번 읽었다 0.47 이 책이 진이한테 세 번 읽혔다 0.23 세 번이 진이한테 이 책을 읽혔다 0.07 : 자연스러운 한국어 문장에 높은 확률값을 부여한다. 표현 빈도 영원히 104 기억될 29 최고의 3503 명작이다 298 영원히 기억될 7 기억될 최고의 1 최고의 명작이다 23 기억될 최고의 명작이다 17 영원히 기억될 최고의 명작이다 0 전통적 SLM에서는 문법적으로 전혀 문제가 없는 ‘영원히 기억될 최고의 명작이다’ 라는 문장에 0의 확률을 부여하게 된다. =&gt; 이 말뭉치에 한번도 나타난 적 없기 때문. n-gram모델을 통해 이 문제를 일부 해결할 수 있다. 직전 n-1개 단어의 등장확률 로 전체 단어 시퀀스 등장 확률 을 근사 하는 것이다! ‘영원히 기억될 최고의‘ 시퀀스 뒤에 명작이다 라는 단어가 올 확률을 trigram으로 근사해보면 얼마일까? P(명작이다 | 영원히, 기억될, 최고의) (유사) P(명작이다 | 기억될, 최고의) = Freq(기억될, 최고의, 명작이다) / Freq(명작이다) = 17 / 298 위와 같이 단어를 슬라이딩 해가면서 수식을 풀어 생각한다면 전체 문장 ‘영원히 기억될 최고의 작품이다’를 trigram으로 계산하기 위한 수식은 다음과 같다. 영원히 기억될 이 등장할 확률 * 영원히 기억될 뒤에 최고의 가 등장할 확률 * 기억될 최고의 뒤에 명작이다 가 등장할 확률 [ 카운트 기반 접근방식의 본질적 한계 ] 희소문제 : Sparcity Problem 여전히 희소문제는 존재한다. 코퍼스 내에 단어시퀀스가 없을(카운트하지 못할) 확률은 여전히 존재. n의 선택은 trade-off : n의 크기를 키우면 예측의 정확도는 높아지지만, 코퍼스에서 해당 n개의 시퀀스를 카운트할 확률은 낮아짐(희소문제 증가), 모델사이즈 커짐. 반대로 n을 작게 선택하면 훈련 코퍼스에서 카운트는 잘 되겠지만 근사의 정확도는 현실의 확률분포와 멀어짐. =&gt; n은 최대 5를 넘어서는 안된다고 권장됨. NNLM(Neural Net Language Model)을 통해 언어 모델 또한 단어의 유사도를 학습 할 수 있도록 설계. 훈련 코퍼스에 없는 단어 시퀀스도 예측을 통해 유사한 단어 시퀀스를 참고하여 확률을 계산해낸다. 워드 임베딩의 아이디어이기도 한다. 단어를 continuous한 밀집벡터의 형태로 표현하여 희소문제를 해결(?) long-term dependency : 정해진 개수의 전 토큰만을 보기 때문에 볼 수 있는 시퀀스의 범위가 한정됨. 이는 모델의 정확도와 연관 An adorable little boy is spreading ( ? ) 위와 같은 문장이 있을 때 정답은 insults, smile 둘 중 하나라고 해보자. 문맥상 “작고 사랑스러운 아이가 (미소)를 퍼뜨렸다” 가 적절함을 알 수 있다. 하지만 만약 작고 사랑스러운 이라는 밑줄 친 부분을 예측에 고려하지 않는다면 엉뚱한 답 insults를 고를 수 있다. 신경망 기반 언어모델 카운트 기반 접근은 그 방식상 본질적인 한계를 갖는다. 이를 극복하기 위해 다양한 방법 시도되었지만(백오프, 스무딩) 본질적인 n-gram 언어모델(고정된 개수의 단어만을 입력으로 받아야한다)에 대한 취약점은 해결하지 못함. RNNLM(Recurrent Neural Network Language Model) 예문 what will the fat cat sit on 의 RNNLM 학습/사용 과정을 보자. 1) 훈련이 끝난 모델을 사용할 경우 RNNLM은 예측 과정에서 이전 시점의 출력을 현재 시점의 입력으로 한다. RNNLM은 what을 입력받으면, will을 예`하고 이 will은 다음 시점의 입력이 되어 the를 예측한다. 이것이 반복되어 네번째 시점의 cat은 앞서 나온 what, will, the, fat이라는 시퀀스로 인해 결정된 단어가 된다. 2) 모델을 훈련시키는 경우 위의 샘플에 대해 what will the fat cat sit 시퀀스를 모델의 입력으로 넣으면, will the fat cat sit on를 예측하도록 훈련한다. 이때 will, the, fat, cat, sit, on은 각 시점의 레이블(yt)가 된다. 이러한 RNN 훈련 기법을 교사 강요(teacher forcing) 라고 한다. 교사 강요(teacher forcing) : 테스트(실제 모델 사용) 과정에서 t 시점의 출력이 t+1 시점의 입력으로 사용되는 RNN 모델을 훈련시킬 때 사용하는 훈련 기법입니다. 훈련할 때 교사 강요를 사용할 경우, 모델이 t 시점에서 예측한 값을 t+1 시점에 입력으로 사용하지 않고, t 시점의 레이블. 즉, 실제 알고있는 정답을 t+1 시점의 입력으로 사용합니다. RNNLM의 학습 구조 임베딩층 : et=lookup(xt) 은닉층 : ht=tanh(Wxet+Whht−1+b) 출력층 : yt^=softmax(Wyht+b) 사용되는 손실함수 : cross-entropy 학습 과정에서 학습되는 가중치 행렬 : E(임베딩 행렬), Wx, Wh, Wy 2-3. 어떤 단어가 같이 쓰였는가분포가정: 자연어 처리에서 분포란 특정 범위(=윈도우)내에 동시에 등장하는 단어 또는 문맥의 집합 을 가리킨다. 어떤 단어 쌍이 비슷한 문맥 환경에서 자주 등장한다면 그 의미 또한 유사할 것이라는게 분포가정의 전제이다. 즉, 자연어를 사용하는 화자들이 특정 단어를 실제 어떻게 사용하는지 관찰 함으로서 단어의 의미를 밝힐 수 있다는 의미.","link":"/2020/02/16/ai-study2/"},{"title":"[딥러닝 스터디] 자연어 처리의 전처리","text":"다음의 책을 공부하며 정리한 내용입니다. https://wikidocs.net/22886 자연어 처리의 전처리 자연어 처리를 위해 자연어 데이터는 일반적으로 토큰화, 단어집합생성, 정수인코딩, 패딩, 벡터화의 과정을 거친다. 토큰화 주어진 텍스트를 단어/문자 단위로 자르는 것을 의미한다. 토큰화 도구 spaCy, NLTK: English Tokenization .split(): 파이썬 기본함수. 띄어쓰기 등으로 토큰화한다면.. 12345678# tokenizer 도구 사용해보기 - 상세 코드는 wikidocs.net/64157 참고import spacytext = \"A dog run back corner near bedrooms\"spacy_text = spacy.load('en')for token in spacy_text.tokenizer(text): print(token.text) 1234567Adogrunbackcornernearbedrooms 한국어 토큰화 영어와 달리 한국어는 띄어쓰기 단위로 토큰화 하면 ‘사과가 =/= 사과는’ 으로 인식되어 단어집합이 불필요하게 커진다. 형태소 토큰화 사용 : 형태소 분석기를 사용해 토큰화를 진행한다. 12345678# 형태소 분석기 중 mecab을 사용해 한국어 형태소 토큰화한다.# !git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git# %cd Mecab-ko-for-Google-Colab# !bash install_mecab-ko_on_colab190912.shfrom konlpy.tag import Mecabtokenizer = Mecab()print(tokenizer.morphs(\"사과의 놀라운 효능이라는 글을 봤어. 그래서 오늘 사과를 먹으려고 했는데 사과가 썩어서 슈퍼에 가서 사과랑 오렌지 사왔어\")) 단어집합의 생성: 단어집합(vocabulary)란 중복을 제거한 텍스트 내 총 단어의 집합(set)을 의미한다. (실습) 네이버 영화 리뷰 데이터를 통해 단어집합 생성123456789101112# 20만개의 영화리뷰에 대해 긍정 1, 부정 0으로 레이블링한 네이버 데이터를 다운받는다.import urllib.requestimport pandas as pdimport numpy as npimport matplotlib.pyplot as plturllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")data = pd.read_table('ratings.txt') # 데이터프레임에 저장print(data[15:20]) # 15번 ~ 20번까지의 리뷰 5개 뽑아보기# data는 해시맵으로 특정 리뷰의 내용에만 접근하기 위한 키는 document이다print(data['document'][15]) 12345678[결과] id document label15 9034036 평점 왜 낮아? 긴장감 스릴감 진짜 최고인데 진짜 전장에서 느끼는 공포를 생생하게 ... 116 979683 네고시에이터랑 소재만 같을 뿐.. 아무런 관련없음.. 117 165498 단연 최고 118 8703997 가면 갈수록 더욱 빠져드네요 밀회 화이팅!! 119 9468781 어?생각없이 봤는데 상당한 수작.일본영화 10년내 최고로 마음에 들었다.강렬한 임팩... 1평점 왜 낮아? 긴장감 스릴감 진짜 최고인데 진짜 전장에서 느끼는 공포를 생생하게 전해준다. 12345678910111213141516171819202122232425from konlpy.tag import Mecab# 임의의 10000개의 리뷰를 sample data로 사용한다.sample_data = data[:10000] # 한글과 공백을 제외하고 불필요한 문자는 모두 제거한다. - 정규표현식 사용sample_data['document'] = data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")# 불용어를 제거해준다. - 인터넷 검색 시 검색 용어로 사용하지 않는 단어. 관사, 전치사, 조사, 접속사 등은 검색 색인 단어로 의미가 없는 단어stopwords=['뭐','으면','을','의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']tokenizer = Mecab()res = []for sentence in sample_data['document']: tmp = [] tmp = tokenizer.morphs(sentence) tokenized = [] for token in tmp: if not token in stopwords: tokenized.append(token) res.append(tokenized)print(res[:2]) 12345678[결과]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy import sys[['어릴', '때', '보', '고', '지금', '다시', '봐도', '재밌', '어요', 'ㅋㅋ'], ['디자인', '배우', '학생', '외국', '디자이너', '그', '일군', '전통', '통해', '발전', '해', '문화', '산업', '부러웠', '는데', '사실', '우리', '나라', '에서', '그', '어려운', '시절', '끝', '까지', '열정', '지킨', '노라노', '같', '전통', '있', '어', '저', '같', '사람', '꿈', '꾸', '고', '이뤄나갈', '수', '있', '다는', '것', '감사', '합니다']] 1234567891011import nltkfrom nltk import FreqDist# 단어-빈도수 조합으로 이루어진 단어집합 해시맵 vocab을 생성한다.# NLTK에서는 빈도수 계산 도구인 FreqDist()를 지원한다.vocab = FreqDist(np.hstack(res))print('단어 [별로]의 빈도수는? ', vocab['별로'], '번')# most_common(N) : 가장 빈도수가 높은 N개의 단어를 반환# 상위 500개의 단어만 보존vocab = vocab.most_common(500) 12[결과]단어 [별로]의 빈도수는? 37 번 각 단어에 고유한 정수 부여 각 토큰에 고유한 정수를 부여한다. 0과 1은 특수 인덱스로 사용한다. 인덱스 0 : 단어집합에 없는 토큰 인덱스 1 : 패딩 토큰(길이맞추기용) 12345678910111213141516171819202122232425word_to_index = {}# 단어들에 순차적으로 2~ 501까지의 인덱스를 부여한다word_to_index = {word[0] : index + 2 for index, word in enumerate(vocab)}# 특수 인덱스word_to_index['unk'] = 0word_to_index['pad'] = 1encoded = []for review in res: tmp = [] for word in review: try: # 각 글자를 해당하는 정수로 변환한다. tmp.append(word_to_index[word]) except KeyError: # 단어 집합에 없는 단어일 경우(=빈도수 상위 500 이외의 단어) unk로 대체된다. tmp.append(word_to_index['unk']) encoded.append(tmp)# 기존의 리뷰가 성공적으로 encoding 되었는지 확인해보기print(encoded[:2]) 1[[294, 51, 6, 4, 89, 63, 86, 11, 21, 34], [0, 79, 0, 0, 0, 54, 0, 0, 0, 0, 48, 0, 0, 0, 19, 314, 136, 319, 26, 54, 0, 278, 169, 72, 0, 0, 0, 32, 0, 8, 36, 140, 32, 68, 383, 0, 4, 0, 22, 8, 123, 29, 320, 103]] Padding: 길이가 다른 문장들을 모두 동일한 크기로 바꿔주는 작업 인코딩한 리뷰를 모두 일정한 길이로 변환해준다. 특정 길이로 모든 샘플들의 길이를 맞춰준다. 정한 길이보다 짧은 샘플들에는 ‘pad’ 토큰을 추가하여 길이를 맞춰준다. 리뷰의 길이를 그래프로 출력하는 코드 12345678max_len = max(len(l) for l in encoded)print('리뷰의 최대 길이 : %d' % max_len)print('리뷰의 최소 길이 : %d' % min(len(l) for l in encoded))print('리뷰의 평균 길이 : %f' % (sum(map(len, encoded))/len(encoded)))plt.hist([len(s) for s in encoded], bins=50)plt.xlabel('length of sample')plt.ylabel('number of sample')plt.show() 12max_len = max(len(l) for l in encoded)print('리뷰의 최대 길이 : %d' % max_len) 12[결과]리뷰의 최대 길이 : 81 123456789# 리뷰 최대 길이인 81로 모든 리뷰의 길이를 맞춰준다.pad_len = 81for review in encoded: if len(review) &lt; pad_len: review += [word_to_index['pad']] * (pad_len - len(review)) # 기존의 리뷰가 성공적으로 padding 되었는지 보기print(encoded[0]) 12[결과][294, 51, 6, 4, 89, 63, 86, 11, 21, 34, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]","link":"/2020/02/17/ai-study4/"},{"title":"[딥러닝 스터디] 케라스(Keras) 실습","text":"다음의 책을 공부하며 정리한 내용입니다. https://wikidocs.net/48649 https://wikidocs.net/32105 케라스 공식문서 딥러닝 라이브러리 케라스의 사용법을 익히고 실제 RNN모델을 설계해본다. 케라스는 딥러닝을 도와주는 파이썬 라이브러리이다. 케라스 훑어보기전처리 도구keras.preprocessing.text.Tokenizer(): 토큰화, 정수 인코딩에 사용 사용 예시 1keras.preprocessing.text.Tokenizer(num_words=None, filters='!\"#$%&amp;()*+,-./:;&lt;=&gt;?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0) 모든 문장부호/구두점 삭제 공백 기준 토큰화 0은 reserved idx로 어떤 단어에도 부여되지 않는다. 각 Argument의 의미는 아래와 같다. num_words : Integer. 사용할 단어집합의 최대 크기 지정. Num_words - 1 words will be kept. filters : String. 텍스트에서 걸러낼 문자집합. 걸러내는 기본값은 모든 문장부호(punctuations), 탭, 개행이다.( ‘ 제외) lower : Boolean. 텍스트를 소문자로 변환할지 여부 split : String. 단어 분리에 사용할 seperator. char_level : Boolean. True인 경우 모든 글자가 토큰으로 간주된다(Char RNN) oov_token : 값을 주게 되면, 해당 값은 단어집합에 없는 단어를 대체할 word_index가 된다. pad_sequence(): 각 샘플(= 각 문장)은 길이가 다르다. 모델의 입력으로 동일한 크기의 샘플을 넣기 위해, 모든 샘플의 길이를 동일하게 맞춰준다. 정해준 길이보다 길이가 긴 샘플은 일부를 자른다 정해준 길이보다 길이가 짧은 샘플은 값을 0으로 채워준다. 해당 함수는 num_samples 길이의 시퀀스 리스트를 (num_samples, num_timesteps)의 2차원 텐서로 변환한다. 1keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0) 각 Argument의 의미는 아래와 같다 sequences : List of lists. 예를들어 [[1, 2, 3], [3, 4, 5, 6], [7, 8]]. 각각의 element는 시퀀스이다. maxlen : Int. 시퀀스들 중 최대길이. 주어지지 않으면 자동으로 가장 긴 시퀀스 길이가 사용된다. padding : String. 어느위치에 패딩할 것인지 정한다. 시퀀스 앞 or 뒤? pre나 post를 넣어준다. truncating : String. 시퀀스 길이가 maxlen보다 길 경우 어느 위치에서 자를 것인지 정한다. 마찬가지로 pre나 post를 넣어준다. 반환 자료형은 다음과 같다. x : Numpy array =&gt; (len(sequences), maxlen) 워드 임베딩Embedding(): 텍스트 내의 positive integers들을 밀집벡터의 형태로 변환한다. 임베딩 과정을 통해 만들어진 밀집벡터를 임베딩 벡터라고 부르기도 한다. eg. [[4], [20]] -&gt; [[0.25, 0.1], [0.6, -0.2]] 임베딩 벡터는 랜덤값에서 시작하여 인공신경망의 가중치가 학습됨에 따라 값이 학습되게 된다. 모델의 첫번째 층 레이어로만 사용할 수 있다. 1keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None) 글자 단위 RNN(Char RNN): 입출력의 단위가 글자인 RNN을 케라스로 구현하여 언어모델의 훈련/테스트 과정을 이해한다.","link":"/2020/02/19/ai-study6/"},{"title":"[딥러닝 스터디] 자연어 전처리 실습","text":"자연어 처리 라이브러리인 토치텍스트를 활용해 이전 포스트의 전처리 이론을 실제로 구현해보자. 토치텍스트: 텍스트에 대한 여러 추상화 기능을 제공하는 자연어 처리 라이브러리 토치텍스트 제공 기능 파일 로드하기(File Loading) : 다양한 포맷의 코퍼스를 로드한다. 토큰화(Tokenization) : 문장을 단어 단위로 분리한다. 단어 집합 생성(Vocab) : 단어 집합을 만든다. 정수 인코딩(Integer encoding) : 전체 코퍼스의 단어들을 각각의 고유한 정수로 맵핑한다. 단어 벡터(Word Vector) : 단어 집합의 단어들에 고유한 임베딩 벡터를 만들어줍니다. 랜덤값으로 초기화한 값일 수도 있고, 사전 훈련된 임베딩 벡터들을 로드할 수도 있습니다. 배치화(Batching) : 훈련 샘플들의 배치를 만들어줍니다. 이 과정에서 패딩 작업(Padding)도 이루어집니다. 실습 1. IMDB 리뷰데이터 분류하기(영어)데이터 다운 및 용도에 따른 분류 진행(훈련/테스트) 데이터는 text(리뷰데이터)와 sentiment(리뷰의 긍정:1/부정:0 여부) 1234567891011121314151617181920# 토치텍스트 설치pip install torchtextimport urllib.requestimport pandas as pd# IMDB 리뷰 데이터 다운로드urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")# 데이터 csv파일로 저장, 상위 5개 행 출력해본다df = pd.read_csv('IMDb_Reviews.csv', encoding='latin1')df.head()# 훈련 데이터와 테스트 데이터로 분류(총 5만개)train_df = df[:40000]test_df = df[40001:]# 각 데이터를 csv 파일로 저장 (index=False :: 인덱스를 저장하지 않음)train_df.to_csv(\"train_data.csv\", index=False)test_df.to_csv(\"test_data.csv\", index=False) 필드 정의하기(torchtext.data) torchtext.data 의 Field함수를 활용해 진행할 자연어 전처리를 정의할 수 있다. sequential : 순차적인 데이터 여부. (True가 기본값) LABEL은 긍정/부정의 단순한 클래스를 나타내는 숫자값이지 순차적 데이터가 아니므로 False이다. use_vocab : 단어 집합을 만들 것인지 여부. (True가 기본값) tokenize : 어떤 토큰화 함수를 사용할 것인지 지정. (string.split이 기본값) lower : 영어 데이터를 전부 소문자화한다. (False가 기본값) batch_first : 신경망에 입력되는 텐서의 첫번째 차원값이 batch_size가 되도록 한다. (False가 기본값) is_target : 레이블 데이터 여부. (False가 기본값) fix_length : 최대 허용 길이. 이 길이에 맞춰서 패딩 작업(Padding)이 진행된다. 12345678910from torchtext.data import TabularDataset# 경로, 훈련데이터, 테스트데이터, 데이터포멧, 텍스트객체train_data, test_data = TabularDataset.splits( path='.', train='train_data.csv', test='test_data.csv', format='csv', fields=[('text', TEXT), ('label', LABEL)], skip_header=True)# 훈련 데이터의 샘플을 확인한다.print(vars(train_data[1])['text'])print(vars(train_data[1])['label']) 123[결과]['believe', 'it', 'or', 'not,', 'this', 'was', 'at', 'one', 'time', 'the', 'worst', 'movie', 'i', 'had', 'ever', 'seen.', 'since', 'that', 'time,', 'i', 'have', 'seen', 'many', 'more', 'movies', 'that', 'are', 'worse', '(how', 'is', 'it', 'possible??)', 'therefore,', 'to', 'be', 'fair,', 'i', 'had', 'to', 'give', 'this', 'movie', 'a', '2', 'out', 'of', '10.', 'but', 'it', 'was', 'a', 'tough', 'call.']0 단어집합을 생성한다. 전체 리뷰의 단어들 내에서 중복을 제거한 단어집합을 생성한다. 각 단어에 고유한 정수를 부여한다(정수 인코딩) 정의한 필드 객체의 .build_vocab() 함수를 활용해 단어집합을 생성할 수 있다. 1234567# 리뷰 데이터의 단어집합을 만든다.# min_freq : 단어집합에 추가되기 위한 최소 등장빈도조건# max_size : 단어집합의 최대 크기TEXT.build_vocab(train_data, min_freq=10, max_size=10000)print('Size of vocab : ', len(TEXT.vocab))print('Integer index of word [the] : ', TEXT.vocab.stoi['the']) 123[결과]Size of vocab : 10002Integer index of word [the] : 2 이때 단어집합의 크기는 기존에 정의한 10000이 아닌 10002임을 알 수 있다. 더해진 두개는 토치텍스트가 자동으로 추가한 특별토큰 unk\\와 pad\\이다. unk는 0, pad는 1의 정수가 부여된다. (+) 데이터로더 만들기 : 특정 배치크기로 데이터를 로드하도록 하는 데이터 로더를 만든다. torchtext.data의 Iterator를 사용해 만들 수 있다. 12345from torchtext.data import Iterator# 배치사이즈 100으로 훈련데이터에 대한 데이터로더를 만든다train_loader = Iterator(dataset=train_data, batch_size=100)print(\"len of train data : \", len(train_data), \" | num of batches : \", len(train_loader)) 12[결과]len of train data : 40000 | num of batches : 400 실습 2. 네이버 영화데이터 분류하기(한국어): 이전 IMDB데이터를 토치텍스트로 전처리 한 것과 마찬가지의 과정으로 진행한다. 네이버 영화리뷰데이터 다운 훈련데이터/테스트 데이터로 분류 필드 정의하기(전처리 방식 지정) 데이터셋 제작하기(전처리 수행) 단어집합 생성/정수인코딩 수행 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 한국어 형태소 분석기 Mecab 설치!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git%cd Mecab-ko-for-Google-Colab!bash install_mecab-ko_on_colab190912.sh# 1.네이버 영화 리뷰데이터 다운import urllib.requestimport pandas as pdurllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")# 2.훈련 데이터와 테스트 데이터로 분리한다.train_data = pd.read_table('ratings_train.txt')test_data = pd.read_table('ratings_test.txt')from torchtext import datafrom konlpy.tag import Mecab# 3.필드 정의하기(전처리 방식 지정)TEXT = data.Field(sequential=True, use_vocab=True, # 단어집합을 만든다 tokenize=Mecab().morphs, # 토크나이저로는 Mecab 사용. lower=True, batch_first=True, fix_length=20) # 패딩 길이는 20LABEL = data.Field(sequential=False, use_vocab=False, is_target=True)# ID필드는 사용하지 않는다. # 디민 TabularDataset.splits()은 받은 데이터를 앞에서부터 순서대로 자르므로 필요함.# 네이버 영화리뷰 데이터는 [리뷰아이디, 리뷰, 라벨] 세가지로 이뤄져있기 때문ID = data.Field(sequential=False, use_vocab=False,) from torchtext.data import TabularDataset# 4.데이터셋 제작하기(전처리 수행)train_data, test_data = TabularDataset.splits( path='.', train='ratings_train.txt', test='ratings_test.txt', format='tsv', fields=[('id', ID), ('text', TEXT), ('label', LABEL)], skip_header=True)print('훈련 샘플의 개수 : {}'.format(len(train_data)))print('테스트 샘플의 개수 : {}'.format(len(test_data)))print('훈련 데이터 예제 : {}'.format(vars(train_data[0]))) 1234[결과]훈련 샘플의 개수 : 150000테스트 샘플의 개수 : 50000훈련 데이터 예제 : {'id': '9976970', 'text': ['아', '더', '빙', '.', '.', '진짜', '짜증', '나', '네요', '목소리'], 'label': '0'} 12345# 5.단어집합을 생성한다(정수인코딩 수행)TEXT.build_vocab(train_data, min_freq=10, max_size=10000)# 생성된 단어집합 내 단어 확인해보기print('단어 \"좋아\"의 인덱스는 [{}]'.format(TEXT.vocab.stoi['좋아'])) 12[결과]단어 &quot;좋아&quot;의 인덱스는 [8343]","link":"/2020/02/17/ai-study5/"},{"title":"[딥러닝 스터디] 컴퓨터 비전을 위한 딥러닝","text":"케라스 창시자에게 배우는 딥러닝 책을 참고하였습니다. 합성곱 신경망: 텐서플로 자격증을 공부하면서 컨브넷에 대한 이론적 이해가 많이 부족하다고 느꼈다. 이론 베이스가 약하니 모델을 어떻게 변형해야 할지도 감이 안와서 책을 보면서 좀 차근차근 다시 이해해보려고 한다. https://wikidocs.net/64066 의 포스트를 공부한 내용이 포함되어 있습니다. 합성곱 신경망(CNN) 기본개념 이미지의 공간적인 구조에 대한 정보 를 보존하며 학습하기 위해 사용하는 신경망 이미지는 기본적으로 높이, 너비, 채널로 이루어진 3차원 텐서이다. 컬러 이미지 내 하나의 픽셀은 세가지 색(삼원색)의 조합으로 이뤄진다. 이는 해당 픽셀이 (1, 1, 3)의 3차원 텐서임을 의미한다. 따라서 이미지가 N*N 크기인 경우 특정 컬러 이미지는 (N, N, 3)의 3차원 텐서로 표현된다고 말할 수 있다. 합성곱(convolution)은 이미지의 특징을 추출해내는 연산 이다. 이미지에 커널을 사용해 쭉 훑어내면 결과 특성맵이 나오게 된다. 합성곱 신경망의 가중치 간단한 컨브넷 예제간단한 컨브넷 예제123456789101112from keras import layersfrom keras import modelsmodel = models.Sequential()model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))model.add(layers.MaxPooling2D((2, 2)))model.add(layers.Conv2D(64, (3, 3), activation='relu'))model.add(layers.MaxPooling2D((2, 2)))model.add(layers.Conv2D(64, (3, 3), activation='relu'))model.add(layers.Flatten())model.add(layers.Dense(64, activation='relu'))model.add(layers.Dense(10, activation='softmax')) 컨브넷은 (이미지 높이, 이미지 너비, 채널의 수) 크기의 입력텐서를 사용한다. 이때 배치차원은 포함하지 않는다. 채널의 수는 Conv2D 층에 전달된 첫번째 매개변수에 의해 조절된다.: 위 코드의 경우 32 또는 64개 ((3, 3, 64) 크기인) 마지막 층의 출력텐서를 fully-connected network에 연결한다 : layers.Dense() 이는 Dense 층을 쌓은 분류기로 1D 벡터만을 처리한다. 따라서 이전층의 출력인 3D텐서를 1D텐서로 펼쳐야 한다.: layers.Flatten() 대부분의 컨브넷에서 특성맵의 깊이는 점진적으로 증가하고(32, 64, 128…), 특성맵의 크기는 점진적으로 감소한다(28x28, 26x26, 13x13…). 합성곱 연산 Dense 층은 입력특성공간에 있는 전역패턴을 학습하지만, 합성곱 층은 지역패턴을 학습한다. 합성곱 연산은 입력 특성맵(input feature map) 3D텐서에 적용된다. 이 텐서는 2개의 공간축(높이, 너비)과 하나의 깊이축(채널축)으로 구성된다. RGB 이미지는 3개의 컬러채널을 가지므로 깊이축의 차원이 3. MNIST와 같은 흑백 이미지는 깊이축의 차원이 1. 합성곱 연산은 이러한 입력 특성맵에서 작은 패치를 추출, 변환하여 출력 특성맵 3D텐서를 만들어낸다. 출력텐서의 깊이는 층의 매개변수로 결정되기 때문에 상황에 따라 다르다. 즉, 여기서의 깊이축의 채널은 더이상 RGB와 같은 특정 컬러를 의미하지 않는다. 대신 일종의 필터를 의미한다.: 필터는 입력 데이터의 어떤 특성을 인코딩한다. [ MNIST 데이터를 통한 입출력 특성맵의 이해 ] 첫번째 합성곱 층이 (28, 28, 1)의 특성맵을 입력으로 받아 (26, 26, 32)크기의 특성맵을 출력한다. = 입력에 대해 32개의 필터를 적용한다 (26, 26) 크기의 32개 출력채널 각각은 입력의 각 위치에서의 필터 패턴에 대한 응답을 의미한다.응답맵이라고 칭한다. [ 컨브넷의 특징 ] translation invariant : 이미지의 어느 한 곳에서 특정 패턴을 학습했다면, 이미지의 다른 부분에서 같은 패턴을 인식해낼 수 있다. 이는 세상은 평행 이동에 따라 다르게 인식되지 않는다는 우리의 인식방법과 동일하다. 반면, 완전 연결 네트워크는 새로운 위치에 나타난 것은 새로운 특성으로 인식한다. 공간적 계층구조 학습 : 합성곱 연산의 기본적인 프로세스는 다음과 같다.[ 첫번째 합성곱 층 ] : 모서리와 같은 작은 지역 패턴을 학습.[ 두번째 합성곱 층 ] : 첫번째 층의 특성으로 구성된 더 큰 패턴을 학습. 이러한 방식을 통해 더 복잡하고 추상적인 시각적 개념을 효과적으로 학습 가능하다. [ 합성곱의 핵심 parameter ] 입력으로부터 뽑아낼 패치크기 : 3x3, 5x5 크기를 주로 사용한다. 특성맵의 출력 깊이 : 합성곱으로 계산할 필터의 수이다. 위의 예시에서는 32로 시작해서 64로 끝남. 패딩과 스트라이드Padding : 입력 특성맵의 가장자리에 적절한 개수의 행과 열을 추가하여 입력 특성맵과 출력특성맵의 크기가 같도록 한다. 케라스의 Conv2D층에서 패딩은 padding 변수로 설정 가능하다. valid : 패딩을 사용하지 않음 same : 패딩을 사용함. 출력 특성맵의 높이, 너비가 입력 특성맵과 같아진다. Stride: 입력 특성맵 위를 지나가는 윈도우 간의 거리(기본은 1씩 움직인다.) 강제적으로 입력 특성맵을 다운샘플링 하는데에 사용된다. 실전에서는 드물게 사용된다. 특성맵의 다운샘플링에는 주로 max pooling 연산을 사용한다. 최대 풀링 연산 스트라이드와 같이 특성맵을 강제적으로 다운샘플링 하는데에 사용한다. 입력 특성맵에서 각 윈도우별로 추출된 패치에 대해 각 채널별로 최대값을 출력한다. 보통 2x2윈도우와 스트라이드 2를 사용하여 특성맵을 절반 크기로 다운샘플링한다. : 당연하게도 평균풀링 등 다른 방법도 있다. 하지만 최대 풀링연산이 가장 성능이 좋다. [ 최대 풀링 연산을 하는 이유 ] 특성맵의 가중치 개수를 줄인다.: 너무 많은 가중치로 인한 overfitting 방지 연속적인 합성곱 층이 점점 커지는 윈도우를 통해 입력 특성맵을 바라보도록 함으로서 필터의 공간적인 계층 구조를 형성한다. (?) 따라서 일반적으로 컨브넷의 서브샘플링은 다음의 방법을 사용한다. (1) 스트라이드가 없는 합성곱으로 조밀한 특성맵을 만든다.(2) 작은 각각의 패치에 대해 최대로 활성화된 특성을 고른다.","link":"/2020/06/21/ai-study9/"},{"title":"[딥러닝 스터디] Attention을 활용한 기계번역","text":"다음의 책을 공부하며 정리한 내용입니다. https://wikidocs.net/24996 : seq2seq 정리 https://wikidocs.net/22893 : 어텐션 모델 정리 https://www.youtube.com/watch?v=c8y9ZAb9aks&amp;t=1032s : seq2seq에서 attention까지(매우 좋음, 꼭 참고하세요) https://www.tensorflow.org/tutorials/text/nmt_with_attention : attention 실습 시퀀스-투-시퀀스(seq2seq): 입력된 시퀀스로부터 다른 도메인의 시퀀스를 출력하는 모델. 이는 다음과 같은 분야에서 사용된다. 챗봇: 입력시퀀스와 출력시퀀스를 각각 질문/대답으로 구성하면 챗봇을 만들 수 있다. 기계번역: 입력시퀀스와 출력시퀀스를 입력/번역문장으로 구성하면 번역기를 만들 수 있다. Text Summerization, Speech to Text 등에 사용될 수 있다. seq2seq 모델은 기본적으로 위의 구조를 띄고 있다. 인코더와 디코더는 두개의 RNN 아키텍처이다. 입력 문장을 처리하는 RNN셀을 인코더, 출력 문장(번역된 문장)을 처리하는 RNN셀을 디코더라고 하는 것. 중간의 컨텍스트 벡터는 인코더 마지막 시점의 히든 스테이트의 크기이다. 즉, 이전의 내용이 함축된 하나의 벡터이다. 이때 디코더에서 단순히 매 단계마다 가장 가능성이 높은 단어 하나를 선택하는 방식은 생각보다 효율적이지 않다. 이때 적용하는 방법이 Beam search. Beam search : 매 스텝마다 가장 ㄴㄴ 높은 n개의 단어를 선택하여, 이 N개의 단어 각각에 대해 다음 스텝에서 등장할 수 있는 모든 단어들의 확률을 예측한다. 이러한 방식으로 매 스텝마다 n개의 후보군을 유지하여 최적의 시퀀스 후보를 뽑아낸다. Attention model seq2seq 모델은 기본적으로 인코더 -&gt; [컨텍스트 벡터] -&gt; 디코더 의 구조를 갖는다. 이러한 모델의 문제는 아래와 같다 컨텍스트 벡터는 결국 하나의 벡터에 불과하다. 인코더의 모든 정보를 하나의 고정된 크기의 벡터에 압축하다 보면 필연적으로 정보의 손실이 발생하게 된다. RNN의 고질적인 Vanishing gradient 문제가 발생한다. : 이러한 문제는 결과적으로 입력 시퀀스가 길어질수록 번역의 품질이 저하되는 문제를 야기한다. Attention Overview어텐션 모델의 기본 아이디어는 다음과 같다. 디코더의 매 time step마다 인코더에서의 전체 입력문장을 다시 한번 참고한다. 이때 입력 문장의 전체 토큰을 동일한 비중으로 참고하는 것이 아니라, 해당 시점에서 예측해야할 단어와 연관이 있는 입력토큰 부분을 좀더 집중(attention)해서 참고한다. Dot product attention어텐션은 다양한 종류가 있다. 그 중 가장 기본적인 닷 프로덕트 어텐션의 구조를 살펴보자. 먼저 기본적인 용어 정의, seq2seq모델과 어텐션 모델의 차이점을 알아보자. 1, 2, 3… n : 인코더의 시점 h1, h2, h3… hn : 각 시점에서의 인코더의 은닉 상태(hidden state) t : 디코더의 현재시점 st : 현재 시점에서의 디코더의 은닉 상태 이전에 배웠던 seq2seq에서 디코더는 두개의 값(이전시점의 은닉상태, 이전시점의 출력)을 통해 현재시점의 은닉상태를 계산했다. 이때 어텐션 모델에서는 계산을 위해 필요한 값이 하나 더 추가된다. 바로 t시점의 어텐션 값 at이다. 따라서 어텐션 모델은 (seq2seq + 어텐션 값 계산) 인 모델이다. 즉, 어텐션 모델에서의 핵심은 이 어텐션 값을 어떻게 구하는가이며, 이 과정에서 어텐션 스코어값을 구하는 방법에 따라 닷 프로덕트 어텐션, 루옹 어텐션, 바다나우 어텐션 등으로 종류가 나뉘게 된다. 또한 모든 어텐션 값 at는(“값”이라는 명칭에서 예상할 수 있듯) 스칼라 값이다. Step 1. 어텐션 스코어를 구한다. 어텐션 스코어는 다음을 의미한다. Attention score : 인코더의 각 은닉상태 h1 - hn이 현재 시점의 디코더 은닉상태 st와 얼마나 유사한지의 정도 닷 프로덕트 어텐션에서는 이 스코어 값을 구하기 위해 st와 hi(i : 1~n)를 닷 프로덕트 한다. 이때 둘다 열벡터이므로 디코더의 은닉상태 st값을 전치하여 내적한다. 따라서 dot product attention의 attention score 함수 수식은 다음과 같다. score(st, hi) = stT * hi 따라서 디코더의 현재 시점 t에 대한 은닉상태 st와 인코더의 모든 시점에 대한 은닉상태의 어텐션 스코어의 모음(et)은 아래와 같다. et = [stT * h1, …, stT * hN] Step 2. Softmax를 통해 Attention Distribution(어텐션 분포)를 구한다. 구해낸 모든 어텐션 스코어의 모음, et에 softmax를 적용해 확률 분포를 얻어낸다. 이를 통해 얻어낸 분포를 Attention Distribution(어텐션 분포)라 하며, 각각의 값을 Attention Weight(어텐션 가중치)라고 한다. 어텐션 분포와 어텐션 값은 디코더의 현재시점 t에 대해 정의된다. Attention Distribution : 어텐션 스코어의 모음에 softmax를 적용해 얻어낸 확률분포. 어텐션 가중치의 모음값 Attention Weight : 어텐션 분포의 각각의 값 따라서 어텐션 분포를 αt의 식은 다음과 같다. αt = softmax(et) Step 3. Attention Weight과 인코더 은닉상태를 가중합하여 Attention Value를 구한다. 구해낸 Attention Distribution의 각 Attention Weight들을 해당 시점의 인코더 은닉상태(h1 ~ hN)와 가중합(Weighted sum) 한다. 결과로 나오는 벡터 a는 최종 어텐션 값, 즉 Attention Value가 되며 이는 인코더의 문맥을 내포하고 있다는 의미에서 Context Vector라고 부르기도 한다. a = ∑αti * hi (i : 1~N, ati : i번째 어텐션 분포의 값) Step 4. 어텐션 값과 현재 상태 대코더의 은닉상태 st를 연결한다(Concatenation). 최종적으로 구해낸 어텐션 값(컨텍스트 벡터) a를 현재 시점의 디코더 은닉상태 st와 결합한다. 이때 둘을 연결해 하나의 벡터로 만드는(concatenation) 작업을 수행한다. 해당 결합 작업을 통해 산출된 최종 벡터 vt는 t시점의 디코더 예측값 y_hat를 도출하기 위한 연산의 입력값으로 사용된다. Bahdanau Attention(바다나우 어텐션): 위에서 어텐션의 종류는 step 1의 어텐션 스코어를 구하는 방법에 따라 달라진다고 했다. 닷 프로덕트 어텐션은 인코더의 각 은닉상태 h1 ~ hN과 현재시점 디코더 은닉상태 st의 유사도인 어텐션 스코어를 내적으로 구하였기 때문에 닷 프로덕트 어텐션이라는 이름이 붙었다. 이때, 현재시점 디코더의 은닉상태 : query 이전 인코더의 모든 은닉상태 : key(=value) 라고 한다면 닷 프로덕트 어텐션의 스코어 함수는 아래와 같을 것이다. score(query, key) = queryT * key 이때 바다나우 어텐션은 아래와 같은 스코어 함수를 사용한다. score(query, key) = vT * tanh(W1 * key + W2 * query) : vT는 transposed weight vector","link":"/2020/02/23/ai-study7/"},{"title":"맥 Permission denied writing to file","text":"맥은 가끔보면 편한건지 불편한건지 모르겠다. 방금도 VSCode로 프로젝트 실습하다가 안되길래 개빡쳐서 알아보고 쓰는글임. Permission denied writing to file 오류가 떴다. 아니 내가 만든 프로젝트를 내가 편집하겠다는데 왜 안돼 왜… 왜…. why… https://support.apple.com/ko-kr/guide/mac-help/mchlp1203/mac 해결방법은 위의 링크에. 폴더 컨텍스트 메뉴에서 정보 가져오기 누르면 위의 메뉴가 뜬다. 오른쪽 아래 자물쇠 잠금해제 권한 변경 는 안됨. 응 안돼 돌아가^^ 아 Gae BBAK Chin da.. 결국 그냥 https://medium.com/@AnkitMaheshwariIn/mac-vs-code-error-permission-denied-writing-to-file-bb112180ede 터미널에서 해당 디렉터리에 대해 권한 풀어준다. sudo chmod -R 777","link":"/2020/02/24/change-permission/"},{"title":"코딩테스트 준비하기 - (1) Arrays","text":"코딩테스트를 준비할 일이 생겼다. Codility를 통해 공부하자. 어제 아주 기본적인 문제를 풀었는데 정확도가 80%밖에 되지 않았다 제길ㅠ 한창 코테 준비할땐 그래도 나쁘지 않았던 것 같은데… 계속하지 않으면 금방 까먹는 듯 하다. 난이도별로 여러개의 예제가 엄선되어 있어서 좋다. 백준의 경우에는 너무 많은 예제가 중구난방으로 있어서 뭘 풀어야 할지 감을 잡기 어려운데 그런면에서 훨씬 잘되어 있는 것 같다. 알고리즘에는 역시 C지! 익숙한 C언어로 풀어보자. Question1 - Cyclic Rotation123456789101112131415161718192021222324252627282930313233343536An array A consisting of N integers is given. Rotation of the array means that each element is shifted right by one index, and the last element of the array is moved to the first place. For example, the rotation of array A = [3, 8, 9, 7, 6] is [6, 3, 8, 9, 7] (elements are shifted right by one index and 6 is moved to the first place).The goal is to rotate array A K times; that is, each element of A will be shifted to the right K times.Write a function:class Solution { public int[] solution(int[] A, int K); }that, given an array A consisting of N integers and an integer K, returns the array A rotated K times.For example, given A = [3, 8, 9, 7, 6] K = 3the function should return [9, 7, 6, 3, 8]. Three rotations were made: [3, 8, 9, 7, 6] -&gt; [6, 3, 8, 9, 7] [6, 3, 8, 9, 7] -&gt; [7, 6, 3, 8, 9] [7, 6, 3, 8, 9] -&gt; [9, 7, 6, 3, 8]For another example, given A = [0, 0, 0] K = 1the function should return [0, 0, 0]Given A = [1, 2, 3, 4] K = 4the function should return [1, 2, 3, 4]Assume that:N and K are integers within the range [0..100];each element of array A is an integer within the range [−1,000..1,000].In your solution, focus on correctness. The performance of your solution will not be the focus of the assessment. Array를 받는다 Array를 Rotate 한다는것은 오른쪽으로 한칸 미는것을 의미 -&gt; 바보같이 왼쪽으로 한칸 미는걸로 풀어서 헤맸다 Array를 K번 Rotate한 결과를 리턴한다. 문제 solution에서 vector array를 사용한다. 오랜만에 vector를 보니 잘 기억나지 않아서 정리! http://www.cplusplus.com/reference/vector/vector/ 123456789101112/** 벡터의 선언 */vector&lt;int&gt; v; //int형 백터 생성vector&lt;int&gt;v(4); //int형 백터 생성 후 크기를 4로 할당(모든 백터요소 0으로 초기화)vector&lt;int&gt;v = { 1, 2, 3}; //int형 백터 생성 후 1, 2, 3 으로 초기화vector&lt;int&gt;v[] = {{ 1, 2}, {3, 4}}; //int형 백터 배열 생성(행은 가변이지만 열은 고정)vector&lt;vector&lt;int&gt;&gt; v; //2차원 백터 생성(행과 열 모두 가변)vector&lt;int&gt; v = { 1, 2, 3, 4, 5}; v.assign(5, 10); //백터 범위를 5로 지정하고 정수 10으로 초기화/** 벡터의 사용 */v.begin(); //벡터 시작점의 주소값 반환(Start index of an array)v.end(); //벡터 끝부분+1의 주소값 반환(Length of an array) Solution12345678910111213141516171819202122vector&lt;int&gt; solution(vector&lt;int&gt; &amp;A, int K) { // write your code in C++14 (g++ 6.2.0) int arrLen = A.size(); int startIdx = arrLen - K; int endIdx = arrLen - 1; if(arrLen == 0) return vector&lt;int&gt;(0); if(arrLen &lt; K) { startIdx = arrLen - (K % arrLen); } vector&lt;int&gt; ret; for(int i = startIdx; i&lt;=endIdx; i++){ ret.push_back(A[i]); } for(int j = 0; j&lt;startIdx; j++){ ret.push_back(A[j]); } return ret;} 인덱스만 찾는다 empty array에 대한 예외처리 잊지말자! Question 2 - Odd occurencies in array1234567891011121314151617181920212223242526272829A non-empty array A consisting of N integers is given. The array contains an odd number of elements, and each element of the array can be paired with another element that has the same value, except for one element that is left unpaired.For example, in array A such that: A[0] = 9 A[1] = 3 A[2] = 9 A[3] = 3 A[4] = 9 A[5] = 7 A[6] = 9the elements at indexes 0 and 2 have value 9,the elements at indexes 1 and 3 have value 3,the elements at indexes 4 and 6 have value 9,the element at index 5 has value 7 and is unpaired.Write a function:class Solution { public int solution(int[] A); }that, given an array A consisting of N integers fulfilling the above conditions, returns the value of the unpaired element.For example, given array A such that: A[0] = 9 A[1] = 3 A[2] = 9 A[3] = 3 A[4] = 9 A[5] = 7 A[6] = 9the function should return 7, as explained in the example above.Write an efficient algorithm for the following assumptions:N is an odd integer within the range [1..1,000,000];each element of array A is an integer within the range [1..1,000,000,000];all but one of the values in A occur an even number of times. non-empty array는 N개의 원소로 이루어져있다. N개의 원소는 각자 짝이 있다 짝이 없는 원소 한개를 찾아라 My Solution(67%)1234567891011121314151617181920212223242526#include &lt;map&gt;#include &lt;algorithm&gt;int solution(vector&lt;int&gt; &amp;A) { // write your code in C++14 (g++ 6.2.0) // Unpaired value일 확률이 있는 값들의 집합 vector&lt;int&gt; unpaired; // 숫자 k, k의 등장횟수 map&lt;int, int&gt; memory; for(int i=0; i&lt;A.size(); i++){ int k = A[i]; memory[k]++; if(memory[k] % 2 == 1){ // odd occurency unpaired.push_back(k); } else { unpaired.erase(remove(unpaired.begin(), unpaired.end(), k), unpaired.end()); } } return unpaired[0];} 로직 자체는 맞지만 원소개수가 많아지면 타임아웃에러 발생. O(N**2) Other Solution(100%) 아이디어가 좋네.. 받아온 배열을 정렬한다. 정렬한 배열은 인덱스 0에서부터 2개씩 건너뛰며 루프를 돌린다. 현재 값이 다음값과 다르면 얘는 홀수개인놈. 얘 이후로는 쭉 인덱스가 깨져서 짝수개로 pair가 나뉘지 않는다. 현재값이 마지막 값이면 얘가 홀수개인놈. 12345678910111213def test3(A): if len(A) == 1: return A[0] A = sorted(A) print(A) for i in range(0, len(A), 2): if i+1 == len(A): return A[i] if A[i] != A[i+1]: return A[i]test3([1,2,1,2,3]) My Solution 2(100%) c++의 sort함수는 기본적으로 오름차순 정렬을 수행한다. sort(배열 시작주소, 배열 마지막주소 + 1) 12345678int solution(vector&lt;int&gt; &amp;A){ sort(A.begin(), A.end()); for(int i=0; i&lt;A.size(); i+=2){ if(i == A.size()-1) return A[i]; if(A[i] != A[i+1]) return A[i]; }}","link":"/2020/10/08/codility1/"},{"title":"코딩테스트 준비하기 - (3) Counting Elements","text":"Codility사이트는 해당 Lessons관련 이론 pdf파일도 같이 제공해준다. pdf 파일이 굉장히 대학시절 알고리즘 교재에서 본것처럼 생겼다. 여튼 생짜로 머리에서 아이디어를 꺼내는 것 보다 이 관련 자료를 읽고 힌트를 얻어 문제를 푸는게 훨씬 유용한 것 같다!! Counting Elements.pdf 그룹 A와 B가 있다. 두 그룹에서 하나의 페어를 찾아 바꿈으로서 각 그룹의 총합이 같도록 만들수 있는지를 판별하려면? 각 그룹의 총합의 차를 구한다. 그룹1의 총합이 10, 그룹2의 총합이 13이라고 해보자. 이때 Question1 - FrogRiverOne123456789101112131415161718192021222324252627282930313233343536373839404142A small frog wants to get to the other side of a river. The frog is initially located on one bank of the river (position 0) and wants to get to the opposite bank (position X+1). Leaves fall from a tree onto the surface of the river.You are given an array A consisting of N integers representing the falling leaves. A[K] represents the position where one leaf falls at time K, measured in seconds.The goal is to find the earliest time when the frog can jump to the other side of the river. The frog can cross only when leaves appear at every position across the river from 1 to X (that is, we want to find the earliest moment when all the positions from 1 to X are covered by leaves). You may assume that the speed of the current in the river is negligibly small, i.e. the leaves do not change their positions once they fall in the river.For example, you are given integer X = 5 and array A such that: A[0] = 1 A[1] = 3 A[2] = 1 A[3] = 4 A[4] = 2 A[5] = 3 A[6] = 5 A[7] = 4In second 6, a leaf falls into position 5. This is the earliest time when leaves appear in every position across the river.Write a function:class Solution { public int solution(int X, int[] A); }that, given a non-empty array A consisting of N integers and integer X, returns the earliest time when the frog can jump to the other side of the river.If the frog is never able to jump to the other side of the river, the function should return −1.For example, given X = 5 and array A such that: A[0] = 1 A[1] = 3 A[2] = 1 A[3] = 4 A[4] = 2 A[5] = 3 A[6] = 5 A[7] = 4the function should return 6, as explained above.Write an efficient algorithm for the following assumptions:N and X are integers within the range [1..100,000];each element of array A is an integer within the range [1..X]. My Solution(100%) 배열초기화 참고 1-X까지의 합을 구해두고 counting board에 새로운 정수가 등록될 때마다 현재 sum을 구한다. 현재 sum이 1-X까지의 합과 같아지는 순간이 개구리가 뛸 수 있는 순간. 123456789101112131415161718192021#include &lt;string.h&gt;int solution(int X, vector&lt;int&gt; &amp;A) { // write your code in C++14 (g++ 6.2.0) int sum = (1 + X) * X / 2; bool countBoard[111111]; memset(countBoard, false, sizeof(bool) * 111111); int curSum = 0; for(int i=0; i&lt;A.size(); i++){ int k = A[i]; if(!countBoard[k]){ // K never occured before curSum += k; countBoard[k] = true; if(curSum == sum) return i; } } return -1;} Question2 - Max Counters123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051You are given N counters, initially set to 0, and you have two possible operations on them:increase(X) − counter X is increased by 1,max counter − all counters are set to the maximum value of any counter.A non-empty array A of M integers is given. This array represents consecutive operations:if A[K] = X, such that 1 ≤ X ≤ N, then operation K is increase(X),if A[K] = N + 1 then operation K is max counter.For example, given integer N = 5 and array A such that: A[0] = 3 A[1] = 4 A[2] = 4 A[3] = 6 A[4] = 1 A[5] = 4 A[6] = 4the values of the counters after each consecutive operation will be: (0, 0, 1, 0, 0) (0, 0, 1, 1, 0) (0, 0, 1, 2, 0) (2, 2, 2, 2, 2) (3, 2, 2, 2, 2) (3, 2, 2, 3, 2) (3, 2, 2, 4, 2)The goal is to calculate the value of every counter after all operations.Write a function:class Solution { public int[] solution(int N, int[] A); }that, given an integer N and a non-empty array A consisting of M integers, returns a sequence of integers representing the values of the counters.Result array should be returned as an array of integers.For example, given: A[0] = 3 A[1] = 4 A[2] = 4 A[3] = 6 A[4] = 1 A[5] = 4 A[6] = 4the function should return [3, 2, 2, 4, 2], as explained above.Write an efficient algorithm for the following assumptions:N and M are integers within the range [1..100,000];each element of array A is an integer within the range [1..N + 1]. 길이 N의 카운터 배열이 있다(0으로 초기화됨) 각 카운터에 대해 어떤 연산을 할지 기준이 되는 연산배열 A가 있다. 배열A의 값에 따라 카운터 연산이 달라진다(A의 길이는 M) A[k]의 값 X가 1보다 크거나 같고 N보다 작거나 같다면 counter[X]++ A[k]의 값이 N+1과 같다면 counter배열의 모든 값은 현재 카운터 중 최대값으로 변경 배열A의 모든 값의 범위는 [1, N+1] 연산이 완료된 이후의 카운터 배열을 반환하라. My Solution1(77%) 동적 배열할당시에 new와 delete 키워드를 사용한다. 동적배열 할당 및 해제 int *counter 로 전역변수 선언 counter = new int[N]() 길이 N의 배열 동적 생성후 0으로 초기화한다. 1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;// Max Counterint *_counter;vector&lt;int&gt; counter;int maxCounterVal;// Max Countervector&lt;int&gt; solution(int N, vector&lt;int&gt; &amp;A) { // write your code in C++14 (g++ 6.2.0) // 길이 N의 카운터 배열 생성후 0으로 초기화 // _counter = new int[N](); counter.resize(N); maxCounterVal = 0; for(int i=0; i&lt;A.size(); i++){ int K = A[i]; if(K == N+1){ fill(counter.begin(), counter.end(), maxCounterVal); } else{ counter[K-1]++; if(counter[K-1] &gt; maxCounterVal) maxCounterVal = counter[K-1]; } } return counter;} 문제에서 얘기하는 내용을 그대로 정직하게 구현함. 값은 제대로 반환하지만 large dataset에서 timeout error가 발생한다. 해당 레슨의 핵심이 Counting Elements인 것에 착안해 좀더 고민을 해봤다. 모든 max 연산이 있을때마다 fill을 수행하는 것이 비효율적이다. 최악의 경우 O(N*M)의 성능을 가진 알고리즘. My Solution2(100%)1234567891011121314151617181920212223242526272829303132333435363738#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;// Max Countervector&lt;int&gt; counter;int maxCounterVal;// Max Countervector&lt;int&gt; solution(int N, vector&lt;int&gt; &amp;A) { // 길이 N의 카운터 배열 생성후 0으로 초기화 counter.resize(N); int prevMax = 0; int curMax = 0; for(int i=0; i&lt;A.size(); i++){ int whatToDo = A[i]; if(whatToDo == N+1){ prevMax = curMax; // curMax = 0; // 이부분이 틀렸다. } else{ int idx = whatToDo - 1; int howOftenAppeared = counter[idx]; if(howOftenAppeared &lt; prevMax){ counter[idx] = prevMax+1; } else{ counter[idx]++; } if(counter[idx] &gt; curMax) curMax = counter[idx]; } } for(int i=0; i&lt;counter.size(); i++){ if(counter[i] &lt; prevMax) counter[i] = prevMax; } return counter;} max변환 연산이 나오면 변환연산 기준max를 저장해둔다. max변환 연산이 아닌 경우는 해당 원소의 카운트값(howOftenAppeared)이 변환연산 기준max보다 큰지 작은지를 비교해서 현재의 변환연산 기준max + 1이나 그냥 +1 이렇게 두가지로 연산 분리한다. 현재의 max는 계속 업데이트 하다가 변환연산이 나올때마다 변환연산 기준max에 저장해준다. 최종적으로 다시 전체 카운터 배열을 순회하면서 변환연산 기준max보다 작은값은 기준max값으로 변환해준다. 아 머리아파ㅠ Question 3 - FindSmallestInteger123456789101112131415161718This is a demo task.Write a function:class Solution { public int solution(int[] A); }that, given an array A of N integers, returns the smallest positive integer (greater than 0) that does not occur in A.For example, given A = [1, 3, 6, 4, 1, 2], the function should return 5.Given A = [1, 2, 3], the function should return 4.Given A = [−1, −3], the function should return 1.Write an efficient algorithm for the following assumptions:N is an integer within the range [1..100,000];each element of array A is an integer within the range [−1,000,000..1,000,000]. N개의 정수로 이루어진 배열 A A 배열에 없는 가장 작은 정수 X를 찾아라(X&gt;0) My Solution(100%) 아무리 고민해도 그냥 배열 여러번 순회하는 아이디어밖에 떠오르지 않았다. 이경우 시간복잡도가 대충 O(2N)정도 될것같아서.. 그냥 가장 간단하게 풀었다. 의외로 통과 12345678910111213141516171819bool counter[1111111] = {false};bool onePositive = false;int solution(vector&lt;int&gt; &amp;A) { // write your code in C++14 (g++ 6.2.0) counter[0] = true; for(int i=0; i&lt;A.size(); i++){ int arrVal = A[i]; if(arrVal &lt;= 0) continue; else onePositive = true; if(!counter[arrVal]) counter[arrVal] = true; } if(!onePositive) return 1; for(int i=0; i&lt;1000000; i++){ if(!counter[i]) return i; } return 1000000;}","link":"/2020/10/09/codility3/"},{"title":"[딥러닝 스터디] Attention을 활용한 기계번역(실습)","text":"텐서플로우 공식 가이드 중 Neural machine translation with attention 문서의 실습을 참고하였습니다. Neural machine translation with attention 스페인어에서 영어로 기계번역을 수행하는 seq2seq 모델을 직접 구현해본다. 기본적인 데이터의 처리 과정은 이전과 같다. 전처리 과정은 생략하고 실제 인코더-어텐션-디코더를 클래스 형태로 구현하는 부분의 코드를 분석해본다. Encoder1. 클래스 설계123456789101112131415161718class Encoder(tf.keras.Model): def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz): super(Encoder, self).__init__() self.batch_sz = batch_sz self.enc_units = enc_units self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform') def call(self, x, hidden): x = self.embedding(x) output, state = self.gru(x, initial_state = hidden) return output, state def initialize_hidden_state(self): return tf.zeros((self.batch_sz, self.enc_units)) [기본 파이썬 문법] class Encoder(tf.keras.Model) : Encoder 클래스는 tf.keras.Model 클래스를 상속 __ init __ : 클래스 생성자. 객체 생성 시점에 자동 호출 super(Encoder, self).__ init __() : 부모 클래스 초기화. super()와 super(A, self)의 차이점 참고 [코드 분석] tf.keras.layers.Embedding() 단어를 밀집벡터로 만드는 케라스 함수. 임베딩 층을 만든다. ( 샘플의 수(시퀀스 길이), 입력크기(단어집합 크기)) 인 2D 텐서를 입력으로 받아 ( 샘플의 수(시퀀스 길이), 입력크기(단어집합 크기), 임베딩 차원) 인 3D 텐서를 반환한다. 호출 위한 기본 파라미터는: input_dim(단어집합 크기), output_dim(임베딩 차원) 이다. tf.keras.layers.GRU() 12345678910tf.compat.v1.keras.layers.GRU( units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, reset_after=False, **kwargs) units: Positive integer, dimensionality of the output space. 출력 텐서의 차원. return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence. 모든 시점의 output을 출력할것인지(true), 아니면 최종 시점의 output만 출력할 것인지 결정. return_state: Boolean. Whether to return the last state in addition to the output. 최종 시점의 output뿐만 아니라 최종 시점의 은닉상태도 출력할지를 결정 호출 위한 기본 파라미터는: inputs (3D tensor), training, initial_state 2. 사용1234567encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)# sample inputsample_hidden = encoder.initialize_hidden_state()sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape)) 3. 코드분석 - Embedding layer의 통과위의 코드는 이전의 전처리를 수행해야 시행해볼 수 있다. 바로 인코더 모델의 모습만 확인해 볼 수 있도록 임의의 텐서를 만들어 모델 구조를 확인해보자. 12345678910111213141516171819202122232425262728293031import tensorflow as tfclass Encoder(tf.keras.Model): def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz): super(Encoder, self).__init__() self.batch_sz = batch_sz self.enc_units = enc_units self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) self.rnn = tf.keras.layers.SimpleRNN(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform') def call(self, x, hidden): x = self.embedding(x) print ('Encoder input shape: {}'.format(x.shape)) output, state = self.rnn(x, initial_state = hidden) return output, state def initialize_hidden_state(self): return tf.zeros((self.batch_sz, self.enc_units))example_input_batch = tf.zeros((3, 7))encoder = Encoder(12, 4, 6, 3)# sample inputsample_hidden = encoder.initialize_hidden_state()sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))encoder.summary() 위의 코드는 단어집합 크기 : 12 임베딩 차원 : 4 은닉상태의 크기 : 6 배치크기 : 3 인 경우이다. 이때 입력 배치는 (3, 7)의 텐서이다. 공부를 하면서 헷갈리는 부분이 있어서 텐서의 크기를 단어집합 크기와 동일하게 3, 12로 잡고 싶었는데 그렇게 하면 out of bound 인덱스 오류가 나더라. 즉, 모델의 단어집합 크기와 동일한 크기의 텐서를 초기 입력으로 넣을 수 없는 듯 하다. 어쩔 수 없이 만든 그림은 (1) 모델의 단어집합 크기가 12인 경우 모델의 모습 과 (2) 모델의 초기 입력 텐서의 크기가 (3(=batch_sz), 12)인 경우 두개의 짬뽕이 되어버림. 위의 코드를 시행하면 아래의 결과가 나온다. 임베딩 레이어 케라스의 Embedding 함수는 단어집합의 크기와 임베딩 차원을 변수로 받아 임베딩 레이어를 만들어준다. 이때 레이어에 모델을 추가하는 것과 모델에 들어가는 텐서는 별도이다. 난 이 개념을 이해하는게 넘나 어려웠다..ㅋㅋㅋㅠ 이게 뭔말인고 하니… 위의 그림은 시퀀스 길이가 12, 시퀀스 개수가 3, 임베딩 차원이 4인 경우 Embedding Layer를 통과했을때 텐서의 크기변환 시각화이다. 즉, 아래와 같은 예시가 있다고 가정하자. [[I, am, studying, neural, language, machine, translation, in, a, cafe, near, home], [I, am, studying, language], [neural, machine, translation]] 이때 각 시퀀스를 12의 길이로 패딩해주자. [ [I, am, studying, neural, language, machine, translation, in, a, cafe, near, home], ​ [I, am, studying, language, , , , , , , , ], ​ [neural, machine, translation, , , , , , , , , ]] 패딩된 시퀀스를 정수 인코딩해주면 대충 아래처럼 된다. [[1, 2, 3, …, 12], [1, 2, 3, 5, 0, 0, … 0], [4, 6, 7, 0, 0….. 0]] = 크기 (3, 12) 그럼 이 (3, 12)의 텐서가 Embedding(단어집합 크기, 임베딩차원) 으로 만들어진 임베딩 레이어에 들어가는거다. 이때 단어집합의 크기를 14라고 하면(단어장 개수 + + ) 해당 텐서가 들어가는 임베딩 레이어 모델 에는 임베딩 작업을 위한 룩업 테이블 이 생성되고, 이때 이 룩업테이블의 크기는 임베딩 레이어의 파라미터의 개수 가 된다. num of parameters in Embedding layer14(vocab sz) * 4(embedding dim) 위의 코드에서는 example_input_batch가 입력으로 들어가는데 코드 설명을 보면 (64, 16)의 크기이며 단어장 크기는 9000정도라고 한다. 또한 임베딩 차원은 256이라고 한다. 그럼 결국 다음과 같다. 길이가 16인 시퀀스가 64개 있다. : 16개의 단어로 이뤄진 문장이 64개 (64, 16)인 이 입력텐서는 임베딩 레이어를 거치면 (64, 16, 9000) 이 된다. 임베딩 레이어의 파라미터 개수는 9000 * 256 4. 코드분석 - RNN 은닉층의 통과원본 코드에서는 GRU를 사용했지만 보다 용이한 (나의)이해를 위해 사용하는 은닉층을 SimpleRNN으로 변경해보았다. 아까 위에서 임베딩 층을 통과하면서 (시퀀스 개수, 시퀀스 길이, 임베딩 차원) 으로 변환된 텐서는 RNN의 입력으로 들어가게 된다. 그리고 은닉층을 통과한 텐서는 위의 그림처럼 변환되게 된다. 이때 units 은 은닉층의 크기 를 의미한다. 은닉층의 파라미터는 아래 그림과 같다. 1번 그림의 vocab_sz는 sequence length인데 바꾸기가 귀찮았다. 여튼 내가 이해한 것은 이랬고, 결국 두개를 합쳐서 그려보면 아래와 같아진다. 중간의 (3, 6) 텐서가 현재시점의 은닉상태이다. 즉, hidden state의 shape은 (num of sequence, 은닉상태 크기) 이다. Attention1. 클래스 설계12345678910111213141516171819202122232425262728class BahdanauAttention(tf.keras.layers.Layer): def __init__(self, units): super(BahdanauAttention, self).__init__() self.W1 = tf.keras.layers.Dense(units) self.W2 = tf.keras.layers.Dense(units) self.V = tf.keras.layers.Dense(1) def call(self, query, values): # query hidden state shape == (batch_size, hidden size) # query_with_time_axis shape == (batch_size, 1, hidden size) # values shape == (batch_size, max_len, hidden size) # we are doing this to broadcast addition along the time axis to calculate the score query_with_time_axis = tf.expand_dims(query, 1) # score shape == (batch_size, max_length, 1) # we get 1 at the last axis because we are applying score to self.V # the shape of the tensor before applying self.V is (batch_size, max_length, units) score = self.V(tf.nn.tanh( self.W1(query_with_time_axis) + self.W2(values))) # attention_weights shape == (batch_size, max_length, 1) attention_weights = tf.nn.softmax(score, axis=1) # context_vector shape after sum == (batch_size, hidden_size) context_vector = attention_weights * values context_vector = tf.reduce_sum(context_vector, axis=1) return context_vector, attention_weights 2. 사용12345attention_layer = BahdanauAttention(10)attention_result, attention_weights = attention_layer(sample_hidden, sample_output)print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape)) Decoder1. 클래스 설계1234567891011121314151617181920212223242526272829303132333435class Decoder(tf.keras.Model): def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz): super(Decoder, self).__init__() self.batch_sz = batch_sz self.dec_units = dec_units self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform') self.fc = tf.keras.layers.Dense(vocab_size) # used for attention self.attention = BahdanauAttention(self.dec_units) def call(self, x, hidden, enc_output): # enc_output shape == (batch_size, max_length, hidden_size) context_vector, attention_weights = self.attention(hidden, enc_output) # x shape after passing through embedding == (batch_size, 1, embedding_dim) x = self.embedding(x) # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size) x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) # passing the concatenated vector to the GRU output, state = self.gru(x) # output shape == (batch_size * 1, hidden_size) output = tf.reshape(output, (-1, output.shape[2])) # output shape == (batch_size, vocab) x = self.fc(output) return x, state, attention_weights 2. 사용123456decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape)) The optimizer and the loss function123456789101112optimizer = tf.keras.optimizers.Adam()loss_object = tf.keras.losses.SparseCategoricalCrossentropy( from_logits=True, reduction='none')def loss_function(real, pred): mask = tf.math.logical_not(tf.math.equal(real, 0)) loss_ = loss_object(real, pred) mask = tf.cast(mask, dtype=loss_.dtype) loss_ *= mask return tf.reduce_mean(loss_) Checkpoints12345checkpoint_dir = './training_checkpoints'checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder) Training123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@tf.functiondef train_step(inp, targ, enc_hidden): loss = 0 with tf.GradientTape() as tape: enc_output, enc_hidden = encoder(inp, enc_hidden) dec_hidden = enc_hidden dec_input = tf.expand_dims([targ_lang.word_index['&lt;start&gt;']] * BATCH_SIZE, 1) # Teacher forcing - feeding the target as the next input for t in range(1, targ.shape[1]): # passing enc_output to the decoder predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output) loss += loss_function(targ[:, t], predictions) # using teacher forcing dec_input = tf.expand_dims(targ[:, t], 1) batch_loss = (loss / int(targ.shape[1])) variables = encoder.trainable_variables + decoder.trainable_variables gradients = tape.gradient(loss, variables) optimizer.apply_gradients(zip(gradients, variables)) return batch_loss EPOCHS = 10for epoch in range(EPOCHS): start = time.time() enc_hidden = encoder.initialize_hidden_state() total_loss = 0 for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)): batch_loss = train_step(inp, targ, enc_hidden) total_loss += batch_loss if batch % 100 == 0: print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy())) # saving (checkpoint) the model every 2 epochs if (epoch + 1) % 2 == 0: checkpoint.save(file_prefix = checkpoint_prefix) print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch)) print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))","link":"/2020/03/23/ai-study8/"},{"title":"코딩테스트 준비하기 - (4) Prefix Sums","text":"prefix sum은 부분합 배열을 의미한다. 개념은 단순하다 다음과 같은 배열 A가 있다. A = [ 1, 4, 6, 3, 7, 9 ] 이때 배열 A의 prefix sum, 즉 부분합 배열 K는 아래와 같다 K = [ 1, 5, 11, 14, 21, 30 ] 상당히 간단한 개념이다. 고등학교 수학시간에 배웠던 것 같은데. 여튼 prefix sum의 장점은 구간의 부분합을 쉽게 구할 수 있다는 점이다. 즉, A[3] + A[4] + A[5] = K[5] - K[2]이다. Question 1 - CountDiv123456789101112131415Write a function:class Solution { public int solution(int A, int B, int K); }that, given three integers A, B and K, returns the number of integers within the range [A..B] that are divisible by K, i.e.:{ i : A ≤ i ≤ B, i mod K = 0 }For example, for A = 6, B = 11 and K = 2, your function should return 3, because there are three numbers divisible by 2 within the range [6..11], namely 6, 8 and 10.Write an efficient algorithm for the following assumptions:A and B are integers within the range [0..2,000,000,000];K is an integer within the range [1..2,000,000,000];A ≤ B. 주어진 A와 B 사이의 숫자들 중 K로 나누어질 수 있는 수의 개수를 반환하라. 나누어 떨어진다의 기준이 X%K == 0 인것이 함정. 0%K == 0이므로 A,B가 0인 경우에 대한 예외처리가 필요했다. 엄청 간단하다고 생각했는데 내가 늘 그렇듯 자꾸 대충짜서 내니깐 edge case에서 예외가 많이 걸림… Codility는 테스트 케이스를 너무 조금준다ㅠㅠ 예외경우도 생각하는게 물론 개발자의 역량이라지만 코딩보다 테스트가 오래걸려서 답답한걸 어카나요..^^ㅠ My Solution(100%)1234567891011121314151617181920212223// you can use includes, for example:// #include &lt;algorithm&gt;// you can write to stdout for debugging purposes, e.g.// cout &lt;&lt; \"this is a debug message\" &lt;&lt; endl;int solution(int A, int B, int K) { // write your code in C++14 (g++ 6.2.0) int ret = 0; if(A==0){ if(B==0) return 1; if(B==K) return 2; if(B&lt;K) return 1; ret += 1; } int Adivisible = (A==0) ? 0 : (A-1) / K; int Bdivisible = B / K; if(A==B &amp;&amp; B%K==0) return 1; return ret + (Bdivisible - Adivisible);} 지금 풀고나니 생각나네 아… 이걸 그냥 부분합으로 풀걸;;;; 개멍청쓰;; Question 2 - MinDnaSequence123456789101112131415161718192021222324252627282930313233343536A DNA sequence can be represented as a string consisting of the letters A, C, G and T, which correspond to the types of successive nucleotides in the sequence. Each nucleotide has an impact factor, which is an integer. Nucleotides of types A, C, G and T have impact factors of 1, 2, 3 and 4, respectively. You are going to answer several queries of the form: What is the minimal impact factor of nucleotides contained in a particular part of the given DNA sequence?The DNA sequence is given as a non-empty string S = S[0]S[1]...S[N-1] consisting of N characters. There are M queries, which are given in non-empty arrays P and Q, each consisting of M integers. The K-th query (0 ≤ K &lt; M) requires you to find the minimal impact factor of nucleotides contained in the DNA sequence between positions P[K] and Q[K] (inclusive).For example, consider string S = CAGCCTA and arrays P, Q such that: P[0] = 2 Q[0] = 4 P[1] = 5 Q[1] = 5 P[2] = 0 Q[2] = 6The answers to these M = 3 queries are as follows:The part of the DNA between positions 2 and 4 contains nucleotides G and C (twice), whose impact factors are 3 and 2 respectively, so the answer is 2.The part between positions 5 and 5 contains a single nucleotide T, whose impact factor is 4, so the answer is 4.The part between positions 0 and 6 (the whole string) contains all nucleotides, in particular nucleotide A whose impact factor is 1, so the answer is 1.Write a function:class Solution { public int[] solution(String S, int[] P, int[] Q); }that, given a non-empty string S consisting of N characters and two non-empty arrays P and Q consisting of M integers, returns an array consisting of M integers specifying the consecutive answers to all queries.Result array should be returned as an array of integers.For example, given the string S = CAGCCTA and arrays P, Q such that: P[0] = 2 Q[0] = 4 P[1] = 5 Q[1] = 5 P[2] = 0 Q[2] = 6the function should return the values [2, 4, 1], as explained above.Write an efficient algorithm for the following assumptions:N is an integer within the range [1..100,000];M is an integer within the range [1..50,000];each element of arrays P, Q is an integer within the range [0..N − 1];P[K] ≤ Q[K], where 0 ≤ K &lt; M;string S consists only of upper-case English letters A, C, G, T. 문제가 엄청길다ㅜㅠ Nucleotide는 총 4가지가 있다. 각각은 정수값 impact factor과 매칭된다. A:1, C:2, G:3, T:4 N개의 문자열로 이뤄진 DNA sequence가 있다. 길이 M의 non-empty array P, Q 가 있다. Query K는 다음을 의미한다 DNA sequence의 P[K]와 Q[K] 위치 사이의 minical impact factor를 찾아라 My Solution(67%)123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;map&gt;using namespace std;vector&lt;int&gt; solution(string &amp;S, vector&lt;int&gt; &amp;P, vector&lt;int&gt; &amp;Q) { // write your code in C++14 (g++ 6.2.0) // nucleotide A, C, G, T의 DNA Sequence idx별 등장횟수 int count[4][55555]; // nucleotide의 impact factor map&lt;char, int&gt; impFac = {{'A', 0},{'C', 1},{'G', 2},{'T', 3}}; for(int i=0; i&lt;S.length(); i++){ char dnaChar = S.at(i); int impactFactIdx = impFac[dnaChar]; // 모든 문자의 등장횟수는 기본적으로 이전 등장횟수 count[0][i] = (i==0) ? 0 : count[0][i-1]; count[1][i] = (i==0) ? 0 : count[1][i-1]; count[2][i] = (i==0) ? 0 : count[2][i-1]; count[3][i] = (i==0) ? 0 : count[3][i-1]; // 등장한 문자의 횟수 +1 count[impactFactIdx][i] = (i==0) ? count[impactFactIdx][0]+1 : count[impactFactIdx][i-1]+1; } vector&lt;int&gt; ret; for(int i=0; i&lt;P.size(); i++){ int queryStartIdx = P[i]-1; int queryEndIdx = Q[i]; int parDiff[4] = {0}; for(int j=0; j&lt;4; j++){ parDiff[j] = queryStartIdx&lt;0 ? count[j][queryEndIdx] : count[j][queryEndIdx] - count[j][queryStartIdx]; } for(int j=0; j&lt;4; j++){ if(parDiff[j]&gt;0){ ret.push_back(j+1); break; } } } return ret;} 로직은 얼추 맞는듯 한데 large dataset에서 런타임 에러가 발생한다. push_back이 너무 느린건가.. Question 2 - MinAvgTwoSlice123456789101112131415161718192021222324252627282930313233343536373839A non-empty array A consisting of N integers is given. A pair of integers (P, Q), such that 0 ≤ P &lt; Q &lt; N, is called a slice of array A (notice that the slice contains at least two elements). The average of a slice (P, Q) is the sum of A[P] + A[P + 1] + ... + A[Q] divided by the length of the slice. To be precise, the average equals (A[P] + A[P + 1] + ... + A[Q]) / (Q − P + 1).For example, array A such that: A[0] = 4 A[1] = 2 A[2] = 2 A[3] = 5 A[4] = 1 A[5] = 5 A[6] = 8contains the following example slices:slice (1, 2), whose average is (2 + 2) / 2 = 2;slice (3, 4), whose average is (5 + 1) / 2 = 3;slice (1, 4), whose average is (2 + 2 + 5 + 1) / 4 = 2.5.The goal is to find the starting position of a slice whose average is minimal.Write a function:class Solution { public int solution(int[] A); }that, given a non-empty array A consisting of N integers, returns the starting position of the slice with the minimal average. If there is more than one slice with a minimal average, you should return the smallest starting position of such a slice.For example, given array A such that: A[0] = 4 A[1] = 2 A[2] = 2 A[3] = 5 A[4] = 1 A[5] = 5 A[6] = 8the function should return 1, as explained above.Write an efficient algorithm for the following assumptions:N is an integer within the range [2..100,000];each element of array A is an integer within the range [−10,000..10,000]. My Solution(60%) memset 사용시에는 string.h 헤더 포함해야 한다. 12345678910111213141516171819202122232425262728#include &lt;string.h&gt;using namespace std;int solution(vector&lt;int&gt; &amp;A) { int N = A.size(); // 배열 A의 길이 int parSum[N+1]; // 부분합 배열 memset(parSum, 0, sizeof(int)*(N+1)); // 배열 A의 부분합을 구한다. for(int i=0; i&lt;N; i++){ parSum[i+1] = parSum[i] + A[i]; } // 각 부분합에 대해 평균을 구한다. 동시에 부분합의 평균이 최소가 인덱스를 구한다. double min = 111111; int minIdx = 0; for(int p=0; p&lt;N; p++){ for(int q=p+1; q&lt;N; q++){ double diff = parSum[q+1] - parSum[p]; double avg = diff / (q-p+1); if(avg &lt; min){ min = avg; minIdx = p; } } } return minIdx;} 아이디어가 안떠올라서 일단 가장 간단하게 구현한 코드..ㅠ O(N^2 / 2) 이므로 당연하게도 timeout error가 났다. 구글신의 힘을 빌렸다. 아주 그냥 수학문제다 머리아파;;: https://nukeguys.tistory.com/175 Question 3 - 괄호변환 디스크 겹치는거 풀다가 도저히 머리가 이해를 못해서 카카오 신입채용 문제로 급선회 익숙한 dfs문제이다. stack의 top()연산은 stack이 비어있으면 Segmentation fault에러가 발생한다. My Solution(100%)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#include &lt;string&gt;#include &lt;vector&gt;#include &lt;stack&gt;using namespace std;string flip(string u){ // 첫번째와 마지막 문자를 제거한다. string parU = u.substr(1, u.length()-2); // 괄호방향을 뒤집는다. string ret = \"\"; for(int i=0; i&lt;parU.length(); i++){ if(parU.at(i) == '(') ret += \")\"; else if(parU.at(i) == ')') ret += \"(\"; } return ret;}bool isCorrect(string s){ stack&lt;char&gt; st; for(int i=0; i&lt;s.length(); i++){ char c = s.at(i); if(c == '('){ st.push(c); } if(c == ')'){ if(!st.empty() &amp;&amp; st.top() == '(') st.pop(); else st.push(c); } } if(st.size() &gt; 0) return false; else return true;}string solve(string p){ if(p.length() &lt;= 0) return p; int wIdx = p.length()-1; int st = 0; for(int i=0; i&lt;p.length(); i++){ char c = p.at(i); if(c == '('){ st += 1; } else if(c == ')'){ st -= 1; } if(st == 0){ // 균형잡힌 문자열 u를 얻음 wIdx = i; break; } } string u = p.substr(0, wIdx+1); string v = (wIdx == p.length()-1) ? \"\" : solve(p.substr(wIdx + 1, p.length()-1-wIdx)); if(isCorrect(u)){ // u가 올바른 문자열인 경우 return u+v; } else { // u가 올바른 문자열이 아닌 경우 string newU = \"(\"; newU += v; newU += \")\"; newU += flip(u); return newU; }}string solution(string p) { string answer = solve(p); return answer;}","link":"/2020/10/09/codility4/"},{"title":"SK 코딩테스트 후기 - String다루기","text":"SK 계열사 중 한곳에 지원, 지난 토요일 코딩테스트를 치뤘다. IDE는 후기에서 말한대로 Codility를 사용했다. 문제는 총 3문제였는데 첫 2개를 30분동안 다 풀고 마지막 1개를 결국 못풀었다… 아쉽다.. 느낌상 셋다 풀고 3번에서 효율성이 떨어지는 정도여야 통과일 것 같아서 마음을 비우고 있는 중이다. 어쨌든 이번이 첫 지원이니 너무 마음쓰지 않으련다. 다음 시험때 더 잘하면 되지. 그럼 의미에서 문제를 복기하고 헤맨 원인을 찾아보려 한다. 왜 못풀었는가: 사실 이건 어떻게 적든간에 변명밖에 되지 않는다. 내가 좀더 준비되어 있었다면 어떤 방식, 어떤 루트를 취했어도 풀었을 것이다. 일단 문제자체가 “풀이가 어려운” 스타일의 문제가 아니었다. 시험시간 내내 실제 문제를 푸는 로직이 아니라 언어 문법에 얽매어 시간을 허비했던 것이 너무나도 아쉽다. 요리로 비유하자면 요리를 하다 어려워서 시간이 다 간게 아니라 당근을 숟가락으로 썰어야 해서 당근만 썰다 끝난 기분이었다. 결국 내가 생각한 가장 큰 원인은 바보같이 이 문제를 C++로 풀려 했다는거다. 나는 이 문제를 보고, 로직을 정리하기도 전에 “아 이건 문자열을 엄청나게 다루는 문제구나. 파이썬으로 풀어야지” 뭐 이런 생각을 했어야 했다. 하지만 결국은 내탓이다. 파이썬으로 알고리즘 연습을 많이 하지않아 멈칫했고, 분명 언어를 바꿀까 고민도 했지만 끝내는 바꾸지 못했던거다. 시험 보기전에 딱 한번만이라도 파이썬으로 문제를 풀어보고 치뤘다면 아마 이 문제를 풀 수 있었을거다. 문제는 간단했다. 대충 파일명들이 하나의 긴 스트링으로 주어지고, 이 파일명에서 특정 정보 A, B를 뽑아내 A로 그루핑한 후 각 그룹내에서 B로 정렬하는거다. 그런데 바보같이 이걸 C++로 풀려 하니깐 세상에 스트링 tokenizer 함수부터 새로 짜야하더라.. 자바스크립트에 너무 익숙해져서 C++이 얼마나 문자열 다루기에 최악이었는지 잊고있었다… 그리고 그걸 시험시간 40분 남겨두고 기억해냈다ㅠ 나는 선택지가 없었다… 문제 정리1. 주어지는 파일포멧 이름.확장자, 도시, yyyy-mm-dd hh:mm:ss 2. 정리방법 도시별로 묶는다 같은 도시에서 찍힌 시간별로 정렬한다 새 이름은 [도시명] [숫자인덱스].원래확장자 숫자 인덱스는 같은 도시그룹의 개수따라 001, 002… 와 같이 leading zero 붙여준다 기존 파일명을 새 파일명으로 바꾼 배열 반환한다. 3. 기타조건 사진 M개, 날짜 2000-2020년 이름 중복가능, 모두 영어 동일도시, 동일시간은 없다","link":"/2020/10/12/codility5/"},{"title":"[실전 JSP] 오리엔테이션 및 소개","text":"해당 포스트는 인프런의 강좌 실전 JSP renew 를 공부하며 작성하였습니다. 웹 프로그램 개요: 웹 프로그램이란 인터넷 서비스를 이용해서 서로 다른 구성요소들이 통신할 수 있는 프로그램이다. 가장 간단한 흐름의 형태는 사용자가 웹서버에 리퀘스트를 날리고, 이를 웹서버가 처리하여 다시 요청한 곳으로 응답해주는 것이다. 이떄 웹서버가 처리하는 로직을 개발하는 것이 웹 프로그램 개발이라고 할 수 있다. 네트워크 프로토콜: 통신을 위한 규약으로, HTTP, FTP, SMTP, POP 등이 있다. 도메인의 구조 http(protocol) :// www(인터넷 서비스구분) . google.com(도메인) : 80(port) / index.html(경로) 웹 프로그램의 동작 원리 웹서버와 사용자간의 통신에는 html 사용 사용자 데이터 및 요청 처리/가공은 동적 데이터인 컨테이너에서 처리한다. 개발 환경 설정다음의 목록을 설치한다. JDK Eclipse(본인은 Intellij 사용) Apache Tomcat 8.5 설치(웹 컨테이너) : 최신버전은 더 높지만 안정화된 8.5버전을 많이 사용한다..","link":"/2020/03/10/jsp-study/"},{"title":"Introduction to Nuxt.js","text":"Nuxt.js is a framework for creating Vue.js application. There are some awesome features that nuxt.js provides. SEO with Server Side Rendering (SSR) Pre Rendering Code Splitting 이런 기능을 서비스에 직접 구현해낼 필요 없이 Nuxt를 사용함으로서 benefit을 얻을 수 있다. What is Nuxt.js?Server Side RenderingBenefits Search Engine Optimization(검색엔진 최적화) Meta Tags Performance Why SSR? One of the common problems javascript developers have is that it is hard to deal with SEO and Meta Tags. : 처음 fetch로 데이터 로드할때 페이지는 비어있는 상태(The page is empty on the initial load of something like the content and meta titles). 뿐만 아니라 자바스크립트가 실행되면 there is no content to index or parse. =&gt; 따라서 많은 크롤링 시스템은 자바스크립트를 지원하지 않는다. 즉, 자바스크립트로 만든 페이지는 실제 제목이 아닌 title of undefined로 검색엔진에 보이는 것. SSR key ideas: 이에 대한 해결책으로 SSR이 등장하게 된다. SSR의 아이디어는 다음과 같다. 실행중인 서버가 있으며, 이는 html응답을 생성(create the html response) 한다. 생성된 응답은 클라이언트나 크롤링 시스템에 사용된다(serve it to the client or the crawler) 따라서 API콜은 서버에서 실행되며,(the call to the API would take place on the server) 실행이 완료되면 메타데이터와 최종 페이지가 생성된다(the meta data will be set and the final page will be served). 최종적으로 크롤링 시스템이 필요로 하는 SEO정보와 메타테그는 크롤링 되는 시점에 페이지 내에 존재하게 된다. 뿐만 아니라 페이지를 서버에서 렌더링 함으로서 속도적인 이득을 볼 수 있다. Pre Rendering: Pre rendering 기법을 통해 서버가 페이지의 생성과 배포를 담당하도록 하는 대신 페이지가 먼저 생성되게 된다(?).(Instead of having a server to generate and serve a page, the pages are generated upfront) 따라서 배포 폴더는 각 페이지에 대해 하나의 html파일을 갖게 된다. 따라서 트래픽이 많은 서비스에 대해서도 무료로 호스팅이 가능하다(SSR benefits + free hosting). Code Splitting: Nuxt는 어플리케이션이 code-splitting 되도록 한다. Code splitting : 자바스크립트 코드를 multiple files로 split하기위한 테크닉. =&gt; 서비스의 비용 절감, 속도 향상 예시 서비스 전체에 총 100개의 컴포넌트가 있고, 메인 페이지에서는 10개의 컴포넌트만 사용하는 경우 : 메인 페이지에서 사용되는 자바스크립트 파일(or 번들)은 사용되지 않는 컴포넌트까지 포함하고 있을 필요가 없다. Nuxt는 자동적으로 각 페이지에 대한 자바스크립트 파일을 생성하여 프로젝트의 의존관계를 관리한다(take care of the project’s dependencies). Create Nuxt App1npx create-nuxt-app nuxt-fundamentals 서버사이드 렌더링을 사용할 것이므로 렌더링 모드만 Universal로 해주도록 한다. Official scaffolding tool create-nuxt-app 사용한다. npx는 npm 5.2.0버전부터 기본적으로 제공된다. 맥을 사용한다면 명령어 앞에 sudo를 사용해줘야 한다(플젝 돌릴때도 마찬가지) 설치 완료됐으면 프로젝트를 실행시켜보자. 프로젝트 폴더로 들어가서 npm혹은 yarn명령어 실행 1npm run dev Guided Nuxt.js Project Tour: In this lesson, we’ll show you around in our newly created Nuxt project. Please note that each directory includes a readme file, that explains what the directory is. You can safely delete the directories of the features you do not need. 폴더명 역할 assets - 아직 컴파일되지 않은 asset들을 포함한다(SASS, 이미지, 폰트 등). - vue cli 프로젝트의 asset 디렉터리와 같은 역할을 한다. components - vue.js 컴포넌트들이 위치하는 디렉터리. layouts - 말 그대로 페이지의 레이아웃을 저장하는 디렉터리.- 기본 레이아웃, 갤러리 레이아웃 같이 원하는 커스텀 레이아웃 저장. middleware - 미들웨어를 저장하는 디렉터리.- 페이지가 렌더링되기 전에 실행가능한 함수 등을 정의할 수 있다. pages - Contains your application views and routes- nuxt는 이 디렉터리에 있는 모든 vue파일을 읽어 자동으로 application router를 생성한다. plugins - 자바스크립트 플러그인을 포함한다.- 해당 플러그인들은 instantiating the route vue instance하기 전에 실행된다.- 전역 컴포넌트를 등록하거나 상수/함수를 삽입하는 위치이기도 하다(register the components globally or to inject functions or constants). static - static 파일을 저장한다. 해당 파일들은 자동으로 서버의 루트위치에 저장된다(automatically mapped to the server’s root).- 해당 위치에 저장된 파일은 웹사이트 url/파일명 으로 접근이 가능하다. store - Contains your Vuex Store- Vuex Store는 별도의 설치나 구성 없이 Nuxt에서 바로 사용할 수 있지만(out of the box), 디폴트로 disable되어있다. 각 디렉터리의 Readme.md 파일에는 해당 디렉터리의 기능이 소개되어있다. 필요없는 기능의 디렉터리는 걍 지우면 됨.","link":"/2020/02/23/nuxt-study1/"},{"title":"GithubPage 세팅하기","text":"온갖 블로그 사이트를 전전하다가 드디어 뭔가 맘에 드는 블로그 플랫폼을 발견했다…드디어 나는 정착할 블로그를 찾은 것인가..?! 참고한 사이트 https://pages.github.com/ : GithubPage Official Guide https://www.holaxprogramming.com/2017/04/16/github-page-and-hexo/ : GithubPage와 Hexo 설치하기 https://blog.zhangruipeng.me/hexo-theme-icarus/ : Hexo Official Guide Blog https://github.com/ppoffice/hexo-theme-icarus : Hexo Official Github https://alleyful.github.io/categories/Tools/Hexo/ : Hexo 설치하기 https://guides.github.com/features/mastering-markdown/ : Markdown 마스터하기 https://swtpumpkin.github.io/git/hexo/hexoImg/ : Hexo 이미지 올리기 https://mishka.kr/2019/06/10/hexo-writing/ : Hexo 글쓰기 Default GuideHexo 명령어 새 테마 적용: 새 테마 적용시에 일단 한번 클린 후 deploy 12hexo cleanhexo deploy --generate 새 글쓰기: https://mishka.kr/2019/06/10/hexo-writing/ 링크를 꼭 참고한다. 123456# layout은 post(default), draft, page가 있다.hexo new [layout] &lt;post_name&gt;hexo deploy --generate# draft로 작성시 publish 명령어 사용hexo publish [layout] &lt;post_name&gt; submodule update를 하는경우 theme폴더 내의 _config.yml파일이 지워지는 문제가 있다. 해당 파일은 항상 백업해두어야 한다ㅠ 로컬 서버 확인 1hexo s Serch Engine Optimization깃헙 페이지는 기본적으로 검색이 안되므로.. 검색엔진 최적화 작업을 따로 해주어야 구글/네이버 등 검색엔진에서 보일 수 있다. Hexo 검색엔진 최적화를 위해 참고한 사이트https://alleyful.github.io/2019/08/10/tools/hexo/hexo-guide-03/https://jeyolog.github.io/2018/08/02/hexo-검색엔진-최적화-플로그인/ 블로그 꾸미기 로고 만들기 테마폴더의 이미지 파일들을 대체해준다. icarus테마 기준 \\themes\\icarus\\source\\images 내의 favicon, logo 등의 이미지를 변경해준다. https://logohub.io/ : 로고 제작 사이트 https://www.aconvert.com/image/png-to-svg/ : png파일 svg로 변환 변경한 이미지는 hexo clean후 배포해주어야 적용된다(테마 적용하듯이 적용!) 기타 팁 생각보다 시간이 오래 걸린다. 세팅하고 익숙해지는데에 거의 반나절이 걸렸다. hexo deploy로 새 글을 발행하는 경우 내 깃헙페이지를 관리하는 실제 레포지토리에는 완성된 글/글과 관련된 블로그 파일들만 올라간다. 여튼 무슨소리냐면 내가 로컬에서 글 쓰는 환경 그 자체는 업로드되지 않는다는 얘기다. 따라서 내가 글쓰는 환경은 따로 백업을 해줘야하는데 이게 또 글 쓰는 폴더 내의 themes 폴더는 다 별도의 깃헙 레포라서 그냥 통으로 올리면 제대로 백업이 안된다. https://mishka.kr/2019/06/13/backup/ 이분이 굉장히 잘 설명해주심. 내 원격 레포를 두개 만든다. 하나는 블로그 쓰는환경 전체파일 백업용(레포1), 다른 하나는 테마 폴더만 백업용(레포2) 테마 폴더의 원격 저장소 위치를 내 원격레포1로 변경해두고 커밋 테마 폴더를 지우고 나머지 블로그 글쓰는 환경 폴더를 깃 레포로 만든다. 테마 폴더를 submodule로 현재 로컬 레포에 추가한다. 블로그 전체 글쓰는 환경 폴더를 원격레포2로 전체 커밋 이후 테마가 추가되면 git submodule add로 추가해준다. 테마 관련 설정이 변경돼도 이렇게 해주면 될 듯. Warning 로컬 테마폴더의 깃 레포 url을 바꾸지 않으면 기존 icarus 레포에 푸시를 하게 된다!!ㅋㅋ.. 대담한 한국인이 되고싶다면 시도해볼것.. 마크다운 에디터가 있으면 편할 것 같아서 또 서치를 했다. Typora 로 현재 작성중. 가볍고 심플하니 나쁘지 않다. Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/02/14/how-to-start-githubPage/"},{"title":"Working with Nuxt.js","text":"본격적으로 Nuxt.js를 활용하는 방법에 대해 배워보도록 하자. Customize the home pagenpm으로 이전 포스트의 프로젝트를 실행하면 보이는 첫 페이지. 이때 계속 말했듯 맥북은 명령어 앞에 sudo를 붙여줘야 한다. 귀찮아 죽겠네. : 위의 화면은 /pages/index.vue 파일의 내용임. 디폴트로 지역 컴포넌트, 링크, heading등을 렌더링한다. Nuxt.js Page ComponentsNuxt application에서 페이지를 만들기 위해서는 페이지 디렉터리 내에 컴포넌트를 만들면 된다. =&gt; Nuxt will automatically create the route 만들어진 Nuxt.js 앱의 소스를 확인해보면 default layout을 쓰고 있음을 알 수 있다. Default layout은 vue-cli 프로젝트의 App.vue랑 비슷한데, 마찬가지로 top-level component이다. Default layout에 적용된 스타일은 해당 레이아웃을 사용하는 모든 페이지에 일괄적으로 적용된다. 이러한 전역 스타일을 사용하는 것은 기본 폰트설정, 표 등 몇가지 경우를 제외하고는 지양해야 한다. Network 탭에서 해당 페이지를 보여주기 위해 로드된 js번들을 확인할 수 있다. 메인 페이지에서 post.vue 와 관련된 번들은 로드되지 않았다. 이것이 바로 이전 포스트에서 얘기한 Code Splitting","link":"/2020/02/24/nuxt-study2/"},{"title":"Tensorflow 개발자 자격증 준비하기(1)","text":"Basic Question구글에서 텐서플로 자격증 시험을 신규 출시(?)하였습니다. 자세한 내용은 이 링크에서 확인할 수 있습니다. 응시료가 무려 100달러. 요즘 달러도 비싼데 아주 비싼 시험입니다. 떨어지면 재응시도 제한되므로 왠만하면 한번에 붙는 것을 목표로 합시다. 첫번째 문제를 풀어보자. 12345678910111213141516# Given this data, train a neural network to match the xs to the ys# So that a predictor for a new value of X will give a float value# very close to the desired answerimport numpy as npdef solution(): xs = np.array([-9.0, 0.0, 4.0, 2.0, 1.0, 8.0], dtype=float) ys = np.array([7.0, 1.0, 2.0, 6.0, 5.0, 3.0], dtype=float) # YOUR CODE HERE return modelif __name__ == '__main__': model = solution() model.save(\"mymodel\") 1. 문제분석1-1. 조건 xs를 ys에 매칭시키는 신경망모델을 제작하라. 모델의 input shape은 [1] 생성된 모델, 즉 predictor는 특정 실수값을 입력으로 받아 desired answer인 하나의 실수값을 반환한다. 1-2. 관련이론 케라스로 구현하는 선형회귀 케라스 학습 조기종료 케라스(keras) 머신러닝 과적합 및 조기종료 시키기] 2. 풀이 간단한 선형회귀 문제라고 생각했다. 위의 링크에 있는 코드를 거의 그대로 사용할 수 있을 듯 하다. 1234# 사용할 라이브러리from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트 2-1. 모델 설계123456789101112131415# 케라스에서는 다양한 층으로 이루어진 인공신경망의 구성을 위해 Sequential()을 사용한다.# Sequential()을 model로 선언한 뒤에 model.add()코드를 통해 층을 단계적으로 추가한다.model = Sequential()# 1개의 실수 xs[i]에 대해 1개의 실수 ys[i]를 예측하는 모델이므로 출력차원과 입력차원 모두 1이다.model.add(Dense(1, input_dim=1, activation='linear'))# optimizer는 경사하강법을 사용한다. learning rate은 0.01sgd = optimizers.SGD(lr=0.01)# 손실함수는 평균제곱오차(mse)를 사용한다.model.compile(optimizer=sgd, loss='mse', metrics=['mse'])# 학습 진행한다. epoch는 300model.fit(xs, ys, batch_size=1, epochs=300, shuffle=False) 2-2. 모델 결과 그냥 300번 학습하게 뒀더니 엄청 과적합이 되는 느낌. 학습 데이터도 얼마 없고 하다보니 loss가 거의 0.0000000001 수준으로 줄어들었다. 조기종료 조건을 추가해줘봤다 123from tensorflow.keras.callbacks import EarlyStoppingearly_stopping = EarlyStopping(monitor='loss') 12# 모델 학습 함수에 early_stopping에 대한 callback인자를 추가해준다.model.fit(xs, ys, batch_size=1, epochs=300, shuffle=False, callbacks=[early_stopping]) 대충 epoch 213에서 멈추는듯. 2-3. 모델 평가1print(model.predict([10.0]))","link":"/2020/06/08/tf-study1/"},{"title":"ES6 문법정리","text":"노드 공부하면서 ES6문법도 같이 공부하련다. 노드6부터 ES6문법을 사용할 수 있다. 인터넷 익스플로러같은 낡은 브라우저에서도 사용할 수 있도록 문법을 변환해주는 babel같은 도구도 있다!! var는 이제 const 와 let 이 대체한다. 템플릿 문자열 큰/작은 따옴표로 감싸는 기존 문자열과 다르게 ``(백틱)` 으로 감싼다. 문자열 안에 변수를 넣을 수 있다. 이거 편하더라. 12345// 기존var string = num1 + ' 더하기 ' + num2 + ' 는 ' + result// 신규const string2 = `${num1} 더하기 ${num2}는 ${result}` Arrow function this binding 방식이 약간 달라짐. Arrow function 내의 this는 상위 스코프의 this를 그대로 물려받는다. Object destructuring 클래스 기존 prototype 기반 문법을 예뻐보이게 클래스로 바꾼것. 1234567891011121314151617181920212223242526// 기존var Human = function(type) { this.type = type || 'human';}; Human.isHuman = function(human) { return human instanceof Human;} Human.prototype.breathe = function() { alert('h-a-a-a-m');};var Zero = function(type, firstName, lastName) { Human.apply(this, arguments); this.firstName = firstName; this.lastName = lastName;};Zero.prototype = Object.create(Human.prototype);Zero.prototype.constructor = Zero; // 상속하는 부분Zero.prototype.sayName = function() { alert(this.firstName + ' ' + this.lastName);};var oldZero = new Zero('human', 'Zero', 'Cho');Human.isHuman(oldZero); // true 12345678910111213141516171819202122232425262728293031// 신규class Human { constructor(type = 'human') { this.type = type; } // 클래스 함수의 키워드 static으로 바뀜 static isHuman(human) { return human instanceof Human; } breathe() { alert('h-a-a-a-m'); }}class Zero extends Human { constructor(type, firstName, lastName) { super(type); this.firstName = firstName; this.lastName = lastName; } sayName() { super.breathe(); alert(`${this.firstName} ${this.lastName}`); }}const newZero = new Zero('human', 'Zero', 'Cho');Human.isHuman(newZero); // true Promise 패턴 자바스크립트와 노드의 API들이 콜백 대신 Promise를 사용한다! 콜백 지옥을 해결 Promise는 객체다. 생성된 promise객체는 성공했을때 resolve(result) 로, 실패했을때 reject(error) 로 결과를 전달한다. 전달된 결과는 then 과 catch 로 받는다. Promise의 이해 이때 문제는 Promise.then().catch().then().catch() 뭐 이런식으로 구성했을때 에러가 나면 에러가 난 위치보다 뒤에 붙여놓은 모든 catch들에서도 에러가 발생 한다. Promise.all 을 사용하면 여러 프로미스 객체들을 한번에 모아서 처리할 수 있다. 모드 프로미스가 성공하면 then, 하나라도 실패하면 catch로 연결된다.’ Promise.race 는 여러 프로미스 객채 중 가장 빨리 성공하거나 실패한 애를 보여준다. async/await 노드 7.6버전부터 지원되는 기능. 아하.. async/await이 promise보다 상위문법이었구낭! 비동기 코드를 동기식으로 표현해서 간단하게 만든다.","link":"/2020/08/19/js-study1/"},{"title":"Tensorflow 개발자 자격증 준비하기(2)","text":"Basic Classification with CNN이번에는 케라스의 패션 MNIST 데이터셋을 사용해 10개의 카테고리로 옷을 분류하는 문제를 해결해보겠다. 텐서플로 기본 튜토리얼을 참고했습니다. 다음 튜토리얼을 참고했습니다. 첫번째 신경망 훈련하기 : 기초적인 분류 문제 운동화, 셔츠 등의 옷 이미지를 분류하는 신경망 모델을 구축한다. 10개의 카테고리, 7만개의 이미지로 구성된 fasion mnist 데이터셋을 사용한다(기본 mnist 데이터셋은 손글씨 숫자로 이루어져 있다.) : 네트워크 훈련에 6만개의 이미지를 사용한다. 테스트 데이터는 1만개의 이미지를 사용한다. 1) 데이터셋 로드하기1234567# tensorflow와 tf.keras를 임포트합니다import tensorflow as tffrom tensorflow import kerasfashion_mnist = keras.datasets.fashion_mnist(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() load_data() : 4개의 NumPy 배열이 반환된다. (학습에 사용되는 훈련세트, 테스트에 사용되는 훈련세트) 각각의 이미지는 28 * 28 크기의 numpy배열이다. 각 이미지는 카테고리를 나타내는 0에서 9사이의 정수인 하나의 label과 매핑되어 있다. 2) 데이터 전처리 각 이미지가 갖는 픽셀값의 범위는 0255 이다. 이를 01사이의 값으로 조정한다. 123train_images = train_images / 255.0test_images = test_images / 255.0 첫 25개 이미지와, 각 이미지의 카테고리명을 출력해본다. 123456789plt.figure(figsize=(10,10))for i in range(25): plt.subplot(5,5,i+1) plt.xticks([]) plt.yticks([]) plt.grid(False) plt.imshow(train_images[i], cmap=plt.cm.binary) plt.xlabel(class_names[train_labels[i]])plt.show() 3) 모델 구성12345model = keras.Sequential([ keras.layers.Flatten(input_shape=(28, 28)), keras.layers.Dense(128, activation='relu'), keras.layers.Dense(10, activation='softmax')]) tf.keras.layers.Flatten : 2차원 배열의 이미지포맷을 28 * 28 = 784 픽셀의 1차원 배열로 변환한다. 이미지 내 픽셀의 행을 펼쳐서 일렬로 늘린다. 학습되는 가중치는 없다. 데이터 변환만 진행한다. tf.keras.layers.Dense : 밀집 연결층 혹은 완전 연결층이라고 지칭. 위의 코드에서 첫번째 Dense층은 128개의 노드(뉴런)를 갖는다. 두번째 층은 10개의 카테고리에 이미지가 속할 확률을 출력해내는 softmax층이다. 123model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) optimizer : 데이터와 손실 값을 바탕으로 모델의 가중치를 업데이트하는 방법 loss : 훈련하는 동안 모델의 오차를 측정하는 방법. 모델의 학습이 올바른 방향으로 향하도록 이 손실함수의 값을 최소화할 필요가 있다. metrics : 훈련단계와 테스트단계를 모니터링 하기 위해 사용한다. 위의 코드에서 지표로 사용하는 accuracy는 올바르게 분류된 이미지의 비율을 의미한다. 4) 모델 훈련1model.fit(train_images, train_labels, epochs=5) 5) 정확도 평가 테스트 데이터셋에서 모델의 성능을 비교한다. 123test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)print('\\n테스트 정확도:', test_acc) 나의 풀이: 일단 먼저 튜토리얼의 코드를 그대로 사용해봤다. 썩 성능이 좋지 않았다. 12345678910111213141516171819202122232425262728293031323334353637383940# Basic Datasets Question## Create a classifier for the Fashion MNIST dataset# Note that the test will expect it to classify 10 classes and that the # input shape should be the native size of the Fashion MNIST dataset which is # 28x28 monochrome. Do not resize the data. YOur input layer should accept# (28,28) as the input shape only. If you amend this, the tests will fail.#import tensorflow as tffrom tensorflow import kerasfashion_mnist = tf.keras.datasets.fashion_mnist(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()train_images = train_images / 255.0test_images = test_images / 255.0def solution_model(): model = keras.Sequential([ keras.layers.Flatten(input_shape=(28, 28)), keras.layers.Dense(128, activation='relu'), keras.layers.Dense(10, activation='softmax') ]) model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) model.fit(train_images, train_labels, epochs=5) return model# Note that you'll need to save your model as a .h5 like this# This .h5 will be uploaded to the testing infrastructure# and a score will be returned to youif __name__ == '__main__': model = solution_model() test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2) print('\\n테스트 정확도:', test_acc) 12345678910111213Epoch 1/51875/1875 [==============================] - 3s 2ms/step - loss: 0.4936 - accuracy: 0.8256Epoch 2/51875/1875 [==============================] - 3s 2ms/step - loss: 0.3743 - accuracy: 0.8652Epoch 3/51875/1875 [==============================] - 3s 2ms/step - loss: 0.3343 - accuracy: 0.8778Epoch 4/51875/1875 [==============================] - 3s 2ms/step - loss: 0.3118 - accuracy: 0.8846Epoch 5/51875/1875 [==============================] - 3s 2ms/step - loss: 0.2913 - accuracy: 0.8923313/313 - 0s - loss: 0.3574 - accuracy: 0.8679테스트 정확도: 0.867900013923645 실제 시험에서 테스트의 정확도는 89%, loss는 33% 이하여야 합격이다. 튜토리얼의 코드가 생각보다 성능이 안나와서 이것저것 개선을 시도해봤다. 시도 1): 단순히 생각해봤을때 가장 기본적이라고 생각되는 조건들을 추가해봤다. epoch 증가 : 학습 횟수를 5에서 30회로 늘렸다. 검증 데이터셋 사용 : fasion mnist에서 제공되는 테스트 데이터셋을 실제 학습이 잘 되고있는지를 검증하는 validation set으로 추가했다. 조기종료 조건 추가 : 학습 횟수를 늘린만큼 잘못 학습이 될 경우를 방지하기 위해 조기종료 조건을 추가했다. 대충 바뀐 코드부분은 아래와 같다. 123es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)model.fit(train_images, train_labels, epochs=30, callbacks=es, validation_data=(test_images, test_labels)) 검증 데이터셋의 오차가 4번 이상 증가하면 과적합으로 판단하고 학습을 종료시키도록 했다. 123456Epoch 16/301875/1875 [==============================] - 4s 2ms/step - loss: 0.1993 - accuracy: 0.9251 - val_loss: 0.3415 - val_accuracy: 0.8849Epoch 00016: early stopping313/313 - 0s - loss: 0.3415 - accuracy: 0.8849테스트 정확도: 0.8848999738693237 전반적으로 성능이 조금 좋아졌다. 아직 합격기준에는 미치지 못한다. 그리고 계속 이런저런 코드를 찾아보니 categorical_crossentropy라는 손실함수를 사용하는 경우도 있어서 내 코드의 sparse_categorical_crossentropy 손실함수와의 차이점이 궁금해졌다. 찾아봄. categorical_crossentropy 와 sparse_categorical_crossentropy 의 차이점은? -&gt; 원핫코딩한 데이터의 분류 = categorical_crossentropy. input shape과 output shape의 크기가 같다. 시도 2) 조기종료 조건 수정 : 데이터셋 오차의 증가 허용을 4번 -&gt; 3번으로 줄였다. 최적 모델 저장 : 모델 체크포인트를 설정해서 val_accuracy가 증가한 경우에만 모델을 저장했다. 123456789101112from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint... es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3) mc = ModelCheckpoint('best_model.h5', monitor = 'val_accuracy', mode = 'max', verbose = 1, save_best_only = True) model.fit(train_images, train_labels, epochs=30, callbacks=[es, mc], validation_data=(test_images, test_labels)) loaded_model = keras.models.load_model('best_model.h5') return loaded_model 변화가 사알짝 있었다. 5번 시도해본 결과 1번 합격기준에 맞췄다. 12345678910111213141516171819Epoch 00011: early stopping313/313 - 0s - loss: 0.3351 - accuracy: 0.8876테스트 정확도: 0.8876000046730042Epoch 00009: early stopping313/313 - 1s - loss: 0.3240 - accuracy: 0.8842테스트 정확도: 0.8841999769210815Epoch 00013: early stopping313/313 - 0s - loss: 0.3313 - accuracy: 0.8928테스트 정확도: 0.892799973487854Epoch 00014: early stopping313/313 - 0s - loss: 0.3192 - accuracy: 0.8916테스트 정확도: 0.8916000127792358Epoch 00010: early stopping313/313 - 0s - loss: 0.3199 - accuracy: 0.8863테스트 정확도: 0.8863000273704529 하지만 아직 한참 모자란다ㅠ 특히 loss부분이 크게 줄지 않는 것 같다. 시도 3): 모델 복잡도를 증가시키고 Dropout을 추가해줘봤다 12345678model = keras.Sequential([ keras.layers.Flatten(input_shape=(28, 28)), keras.layers.Dense(256, activation='relu'), keras.layers.Dropout(0.2), keras.layers.Dense(128, activation='relu'), keras.layers.Dropout(0.2), keras.layers.Dense(10, activation='softmax')]) 12345678910111213141516171819Epoch 00018: early stopping313/313 - 0s - loss: 0.3267 - accuracy: 0.8895테스트 정확도: 0.8895000219345093Epoch 00009: early stopping313/313 - 0s - loss: 0.3385 - accuracy: 0.8802테스트 정확도: 0.8802000284194946Epoch 00011: early stopping313/313 - 0s - loss: 0.3385 - accuracy: 0.8805테스트 정확도: 0.8805000185966492Epoch 00009: early stopping313/313 - 0s - loss: 0.3637 - accuracy: 0.8756테스트 정확도: 0.8755999803543091Epoch 00017: early stopping313/313 - 0s - loss: 0.3238 - accuracy: 0.8895테스트 정확도: 0.8895000219345093 오히려 결과가 더 안좋아졌다. 음.. 어떻게 해야하지 시도 4): CNN을 사용하고 모델 복잡도를 확 올려봤다. 컨볼루션 레이어를 생성하는 Conv2D 클래스는 4차원 텐서를 입력으로 받는다. 따라서 fasion_mnist의 28 * 28 이미지 데이터를 reshape해줄 필요가 있다. 12train_images = tf.reshape(train_images, shape=[60000,28,28,1])test_images = tf.reshape(test_images, shape=[10000,28,28,1]) 모델은 구글링으로 적당히 짜깁기해서 아래처럼 구성해봤다. 1234567891011model = keras.Sequential([ keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu', input_shape=(28, 28, 1)), keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'), keras.layers.MaxPooling2D(pool_size=2), keras.layers.Flatten(), keras.layers.Dense(1024, activation='relu'), keras.layers.Dropout(0.2), keras.layers.Dense(256, activation='relu'), keras.layers.Dropout(0.2), keras.layers.Dense(10, activation='softmax')]) 오 유의미한 변화가 있었다. 전반적인 loss가 0.3 이하로 줄어들고 정확도는 90%를 평균적으로 넘었다. 이정도면 턱걸이지만 시험의 통과는 가능한 수준이다. 12345678910111213141516171819Epoch 00008: early stopping313/313 - 1s - loss: 0.2781 - accuracy: 0.9010테스트 정확도: 0.9010000228881836Epoch 00008: early stopping313/313 - 2s - loss: 0.2836 - accuracy: 0.9018테스트 정확도: 0.9017999768257141Epoch 00008: early stopping313/313 - 1s - loss: 0.3023 - accuracy: 0.9014테스트 정확도: 0.9014000296592712Epoch 00008: early stopping313/313 - 1s - loss: 0.3116 - accuracy: 0.9024테스트 정확도: 0.902400016784668Epoch 00010: early stopping313/313 - 1s - loss: 0.3102 - accuracy: 0.9064테스트 정확도: 0.9064000248908997 이게 CNN을 사용해서 올라간건지 아니면 모델 복잡도를 증가시킨것도 변화에 의미가 있었는지 궁금해서 시도2) 의 모델에 CNN만 추가해서 다시 테스트해봤다. 배치를 쓰지않고 느려터진 CNN을 돌리려니 모델 학습되는걸 기다리는것만 백년걸린다. 아 힘드러. 12345678model = keras.Sequential([ keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu', input_shape=(28, 28, 1)), keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'), keras.layers.MaxPooling2D(pool_size=2), keras.layers.Flatten(), keras.layers.Dense(128, activation='relu'), keras.layers.Dense(10, activation='softmax')]) 12345678910111213141516171819Epoch 00011: early stopping313/313 - 1s - loss: 0.2710 - accuracy: 0.9044테스트 정확도: 0.9043999910354614Epoch 00011: early stopping313/313 - 1s - loss: 0.2746 - accuracy: 0.9055테스트 정확도: 0.9054999947547913Epoch 00008: early stopping313/313 - 1s - loss: 0.2923 - accuracy: 0.8992테스트 정확도: 0.8992000222206116Epoch 00010: early stopping313/313 - 1s - loss: 0.2896 - accuracy: 0.8998테스트 정확도: 0.8998000025749207Epoch 00012: early stopping313/313 - 1s - loss: 0.2843 - accuracy: 0.9051테스트 정확도: 0.9050999879837036 굉장히 애매한 결과가 나왔다. 정확도의 maximum이 모델 복잡도를 올렸을때보다 조금 높아졌지만 minimum도 그만큼 살짝 낮아졌다. 혹시나 해서 최종 레이어 이전에 20%의 비율로 dropout을 추가해주고 다시 학습시켜봤다. 12345678910111213141516171819Epoch 00013: early stopping313/313 - 1s - loss: 0.2861 - accuracy: 0.9081테스트 정확도: 0.9081000089645386Epoch 00013: early stopping313/313 - 1s - loss: 0.2754 - accuracy: 0.9056테스트 정확도: 0.9056000113487244Epoch 00013: early stopping313/313 - 1s - loss: 0.2760 - accuracy: 0.9051테스트 정확도: 0.9050999879837036Epoch 00011: early stopping313/313 - 1s - loss: 0.2751 - accuracy: 0.9064테스트 정확도: 0.9064000248908997Epoch 00013: early stopping313/313 - 1s - loss: 0.2877 - accuracy: 0.9019테스트 정확도: 0.9018999934196472 오오오 확실히 변화가 있었다. 전반적으로 정확도가 90.5% 이상으로 상승했다. 결국 Dense 레이어를 추가해서 단순히 모델 복잡도를 올려버리는 것 보다는 dropout을 추가해서 복잡도를 낮추는게 더 효과가 있었다. 여기에서 궁금해서 몇가지 더 실험을 해봤다. 생각보다 loss가 많이 낮아졌기에 손실이 높아지는걸 감수하고 학습을 좀더 진행시켜보면 정확도가 올라갈지 궁금했다. 조기종료 조건의 patience를 5로 높여봤다. 1234567Epoch 00016: early stopping313/313 - 1s - loss: 0.3029 - accuracy: 0.9076테스트 정확도: 0.9075999855995178Epoch 00013: early stopping313/313 - 1s - loss: 0.2799 - accuracy: 0.9045테스트 정확도: 0.9045000076293945 손실이 증가한거에 비해 정확도의 증가는 미미한 편이다. dropout 비율이 학습에 미치는 영향이 궁금했다. dropout 비율을 높여봤다. 1234567891011121314151617181920212223242526# Dropout : 0.5Epoch 00012: early stopping313/313 - 1s - loss: 0.2802 - accuracy: 0.9046테스트 정확도: 0.9046000242233276Epoch 00016: early stopping313/313 - 1s - loss: 0.2810 - accuracy: 0.9080테스트 정확도: 0.9079999923706055# Dropout : 0.25Epoch 00010: early stopping313/313 - 3s - loss: 0.2662 - accuracy: 0.9120테스트 정확도: 0.9120000004768372Epoch 00011: early stopping313/313 - 3s - loss: 0.2499 - accuracy: 0.9139테스트 정확도: 0.9139000177383423# Dropout : 0.3Epoch 00012: early stopping313/313 - 3s - loss: 0.2442 - accuracy: 0.9173테스트 정확도: 0.9172999858856201Epoch 00009: early stopping313/313 - 3s - loss: 0.2510 - accuracy: 0.9128테스트 정확도: 0.9128000140190125 대박!!! 드롭아웃 비율을 조절한 것 만으로도 엄청난 변화가 생겼다. 드디어 0.5는 썩 성능이 좋지 않았고 0.3정도가 적당한 듯 싶다. 신기하네. 최종모델내가 구성한 모델 중 가장 높은 성능을 보여준놈 12345678910model = keras.Sequential([ keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(28, 28, 1)), keras.layers.MaxPooling2D(pool_size=2), keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'), keras.layers.MaxPooling2D(pool_size=2), keras.layers.Flatten(), keras.layers.Dense(128, activation='relu'), keras.layers.Dropout(0.3), keras.layers.Dense(10, activation='softmax')]) 추가 (+) 어디 책에서 본 모델12345678model = keras.Sequential([ keras.layers.Conv2D(10, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)), keras.layers.MaxPooling2D(pool_size=2), keras.layers.Flatten(), keras.layers.Dropout(0.5), keras.layers.Dense(100, activation='relu'), keras.layers.Dense(10, activation='softmax')]) 123456789101112131415Epoch 00021: early stopping313/313 - 2s - loss: 0.2330 - accuracy: 0.9183테스트 정확도: 0.9182999730110168Epoch 00017: early stopping313/313 - 2s - loss: 0.2335 - accuracy: 0.9160테스트 정확도: 0.9160000085830688Epoch 00013: early stopping313/313 - 2s - loss: 0.2499 - accuracy: 0.9131테스트 정확도: 0.913100004196167Epoch 00014: early stopping313/313 - 2s - loss: 0.2392 - accuracy: 0.9165테스트 정확도: 0.9164999723434448 간단하게 생겼는데 성능이 꽤 좋다. 이유가 뭘까?","link":"/2020/06/16/tf-study2/"},{"title":"노드 시작하기","text":"노드 서버를 만들 일이 생겼습니다. 700페이지짜리 두껍고 무서운 책을 한권 샀습니다. 이름도 무려 Node.js 교과서. 그래도 뷰 공부할때보다는 확실히 덜 막막하고, 서버는 처음 개발해보는거라 약간 설레는 마음이 있습니다. 구입한 책은 Node.js 교과서 - 길벗출판사 . 노드란? Node.js는 Chrome V8 Javascript엔진으로 빌드된 Javascript 런타임이다. 서버로서의 노드 노드의 가장 큰 특징 : 1) 싱글스레드 2) 논-블로킹 모델 노드를 서버로 사용할때의 장단점 노드는 IO 처리를 잘한다(논블로킹 방식으로 처리). 하지만 노드는 CPU부하가 큰 작업에는 적합하지 않다. &gt;&gt; 작성한 코드 전체가 스레드 하나에서 처리되기 때문 따라서 노드는 개수는 많지만 크기는 작은 데이터를 실시간으로 주고받는 데에 적합하다. +) 노드에서 멀티스레드 사용이 불가능한건 아닌듯. 노드12에서 안정화된 워커스레드 기능으로 멀티스레딩 작업 가능하다고 한다. +) 당연히 그래도 그냥 C++, Ruby, Go에 비해선 느리다. 노드에는 웹서버가 내장되어 있다. 따라서 nginx, Apache와 같은 별도 웹서버를 설치할 필요가 없이 그냥 내장 웹서버 사용할 수 있다. 물론 나중에 서버 규모가 커지면 nginx같은 별도 웹서버를 노드 서버와 연결해야 한다. REPL 입력한 코드를 읽고, 해석하고, 결과를 반환하고, 종료할때까지 반복한다고 해서 REPL(Read Eval Print Loop) 라고 부른다. node의 REPL도 간단하게 터미널에 node 쳐서 실행해볼 수 있다. 종료하려면 ctrl+c 두번, 혹은 .exit 입력하면 된다. 모듈화1234567// var.jsconst odd = 'odd num';const even = 'even num';module.exports = { odd, even} module.exports로 파일의 객체들을 모듈화 후 export함으로써, var.js 파일은 모듈로서 기능한다. require 함수로 불러온다. 123456// func.jsconst { odd, even } = require('./var');function chkNum(n) =&gt; { return n % 2 ? odd : even }module.exports = chkNum; 12345678// index.jsconst { odd, even } = require('./var');const chkNum = require('./func');function chkStrNum(s) =&gt; { return s.length % 2 ? odd : even }console.log(chkNum(10)); // even num 출력console.log(chkStrNum('hello')); // odd num 출력 노드 내장객체 노드는 내장객체로 window와 document가 없다! global console 타이머 module, exports, require process 노드 내장모듈 os : 운영체제 정보를 가져온다 path : 폴더와 파일 경로를 조작한다 url : 인터넷 주소를 조작한다 querystring : url의 쿼리부분을 사용하기 쉽게 객체로 만드는 모듈 crypto : 다양한 방식의 암호화를 도와주는 모듈 util : 다양한 편의 기능을 모아둔 모듈 fs : 파일시스템에 접근하는 모듈","link":"/2020/08/19/node-study1/"},{"title":"코딩테스트 준비하기 - (2) Time complexity","text":"Lesson 3은 시간복잡도에 관한 예제들이다. 총 3문제! Question1 - FrogJmp123456789101112131415161718192021222324A small frog wants to get to the other side of the road. The frog is currently located at position X and wants to get to a position greater than or equal to Y. The small frog always jumps a fixed distance, D.Count the minimal number of jumps that the small frog must perform to reach its target.Write a function:class Solution { public int solution(int X, int Y, int D); }that, given three integers X, Y and D, returns the minimal number of jumps from position X to a position equal to or greater than Y.For example, given: X = 10 Y = 85 D = 30the function should return 3, because the frog will be positioned as follows:after the first jump, at position 10 + 30 = 40after the second jump, at position 10 + 30 + 30 = 70after the third jump, at position 10 + 30 + 30 + 30 = 100Write an efficient algorithm for the following assumptions:X, Y and D are integers within the range [1..1,000,000,000];X ≤ Y. 한번에 D씩 움직이는 개구리가 X에서 Y로 가기위해 몇번 점프해야할까? My Solution12345678910int solution(int X, int Y, int D) { // write your code in C++14 (g++ 6.2.0) int gap = Y - X; int remainder = gap % D; int jump = gap / D; if(gap == 0) return 0; if(remainder == 0) return jump; else return jump+1;} Question2 - PermMissingElem1234567891011121314151617181920212223An array A consisting of N different integers is given. The array contains integers in the range [1..(N + 1)], which means that exactly one element is missing.Your goal is to find that missing element.Write a function:class Solution { public int solution(int[] A); }that, given an array A, returns the value of the missing element.For example, given array A such that: A[0] = 2 A[1] = 3 A[2] = 1 A[3] = 5the function should return 4, as it is the missing element.Write an efficient algorithm for the following assumptions:N is an integer within the range [0..100,000];the elements of A are all distinct;each element of array A is an integer within the range [1..(N + 1)]. N개의 서로다른 정수로 이루어진 배열 A가 주어진다. 이 길이 N의 배열 A는 1 ~ N+1 까지의 수로 이뤄진다. 즉, 한개가 빠져있는것. 빠진놈을 찾아라 My Solution(50%)12345678910111213#include &lt;algorithm&gt;int solution(vector&lt;int&gt; &amp;A) { // 받아온 배열 정렬 sort(A.begin(), A.end()); if(A.size() == 0) return 0; if(A.size() == 1) return 1; for(int i=0; i&lt;A.size(); i++){ if(A[i]-1 != i) return i; }} 왜 이게 50%지? 디버깅이 안되니 불편하다ㅠㅠㅠ 디버깅할 방법을 찾아봐야겠음… Question3 -12345678910111213141516171819202122232425262728293031323334353637383940A non-empty array A consisting of N integers is given. Array A represents numbers on a tape.Any integer P, such that 0 &lt; P &lt; N, splits this tape into two non-empty parts: A[0], A[1], ..., A[P − 1] and A[P], A[P + 1], ..., A[N − 1].The difference between the two parts is the value of: |(A[0] + A[1] + ... + A[P − 1]) − (A[P] + A[P + 1] + ... + A[N − 1])|In other words, it is the absolute difference between the sum of the first part and the sum of the second part.For example, consider array A such that: A[0] = 3 A[1] = 1 A[2] = 2 A[3] = 4 A[4] = 3We can split this tape in four places:P = 1, difference = |3 − 10| = 7P = 2, difference = |4 − 9| = 5P = 3, difference = |6 − 7| = 1P = 4, difference = |10 − 3| = 7Write a function:int solution(vector&lt;int&gt; &amp;A);that, given a non-empty array A of N integers, returns the minimal difference that can be achieved.For example, given: A[0] = 3 A[1] = 1 A[2] = 2 A[3] = 4 A[4] = 3the function should return 1, as explained above.Write an efficient algorithm for the following assumptions:N is an integer within the range [2..100,000];each element of array A is an integer within the range [−1,000..1,000]. non-empty array A는 N개의 정수로 이루어짐 P를 기점으로 배열 A는 0(P-1), P(N-1)의 두개 파트로 나뉜다. 각 파트의 합의 차이를 최소로 만드는 P를 찾아서 그 최소값을 반환하라(이때 파트간 합의 차는 절대값 씌운다.) My Solution(76%) 양끝에서 인덱스가 같이 다가오는 아이디어로 풀어봤다. 왼쪽집합과 오른쪽 집합의 합을 구해가면서 집합의 차가 작아지는 방향으로 계속 움직이도록 한다. 결과는 76점ㅠㅠ 뭘 빼먹은걸까… 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// you can use includes, for example:// #include &lt;algorithm&gt;// you can write to stdout for debugging purposes, e.g.// cout &lt;&lt; \"this is a debug message\" &lt;&lt; endl;int solution(vector&lt;int&gt; &amp;A) { // write your code in C++14 (g++ 6.2.0) int startIdx = 0; int endIdx = A.size()-1; int sumLeft = A[startIdx]; int sumRight = A[endIdx]; if(A.size() == 2) return abs(sumLeft - sumRight); while(true){ if(sumLeft == sumRight){ if(endIdx - startIdx == 1){ return 0; } else if(endIdx - startIdx == 2){ return abs(A[startIdx+1]); } else{ if(abs(A[startIdx+1] &lt;= abs(A[endIdx-1]))){ startIdx++; sumLeft += A[startIdx]; } else{ endIdx--; sumRight += A[endIdx]; } } } // 더 값이 큰 집합을 작아지게 만들거나 // 더 값이 작은 집합을 커지게 만든다 else{ if(startIdx+1 &gt;= endIdx){ return abs(sumLeft - sumRight); } int ifMoveRight = abs((sumLeft + A[startIdx+1]) - sumRight); int ifMoveLeft = abs(sumLeft - (sumRight + A[endIdx-1])); if(ifMoveRight &lt;= ifMoveLeft){ startIdx++; sumLeft += A[startIdx]; } if(ifMoveRight &gt; ifMoveLeft){ endIdx--; sumRight += A[endIdx]; } } }} My Solution2(100%) 배열을 순회하면서 각 인덱스까지의 합을 저장한다. 반대로도 병렬 수행 전체 배열에 대해 두개 배열의 차를 구한다. 최소값을 같이 구한다. 이렇게하면 아마도 O(2N) 12345678910111213141516171819202122232425int solution(vector&lt;int&gt; &amp;A) { // write your code in C++14 (g++ 6.2.0) int N = A.size(); vector&lt;int&gt; moveRightBoard(N); vector&lt;int&gt; moveLeftBoard(N); moveRightBoard[0] = A[0]; moveLeftBoard[N-1] = A[N-1]; if(N == 2) return abs(A[0] - A[1]); for(int i=1, j=N-2; i&lt;A.size(); i++, j--){ moveRightBoard[i] = moveRightBoard[i-1] + A[i]; moveLeftBoard[j] = moveLeftBoard[j+1] + A[j]; } int min = 9999999999999999; for(int i=0; i&lt;N-1; i++){ int diff = abs(moveRightBoard[i] - moveLeftBoard[i+1]); if(diff &lt; min){ min = diff; } } return min;}","link":"/2020/10/08/codility2/"},{"title":"Tensorflow 개발자 자격증 준비하기(5)","text":"Time Series Analysis시계열 데이터의 처리. 1. 문제1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import csvimport tensorflow as tfimport numpy as npimport urllib# DO NOT CHANGE THIS CODEdef windowed_dataset(series, window_size, batch_size, shuffle_buffer): series = tf.expand_dims(series, axis=-1) ds = tf.data.Dataset.from_tensor_slices(series) ds = ds.window(window_size + 1, shift=1, drop_remainder=True) ds = ds.flat_map(lambda w: w.batch(window_size + 1)) ds = ds.shuffle(shuffle_buffer) ds = ds.map(lambda w: (w[:-1], w[1:])) return ds.batch(batch_size).prefetch(1)def solution_model(): url = 'https://storage.googleapis.com/download.tensorflow.org/data/Sunspots.csv' urllib.request.urlretrieve(url, 'sunspots.csv') # Your data should be loaded into 2 Python lists called time_step # and sunspots. They are decleared here. time_step = [] sunspots = [] with open('sunspots.csv') as csvfile: reader = csv.reader(csvfile, delimiter=',') next(reader) for row in reader: sunspots.append(# YOUR CODE HERE) time_step.append(# YOUR CODE HERE) # You should use numpy to create # - your series from the list of sunspots # - your time details from the list of time steps series = # YOUR CODE HERE time = np.array(time_step) # You should split the dataset into training and validation splits # At time 3000. So everything up to 3000 is training, and everything # after 3000 is validation. Write the code below to achieve that. split_time = 3000 time_train = # YOUR CODE HERE x_train = # YOUR CODE HERE time_valid = # YOUR CODE HERE x_valid = # YOUR CODE HERE # DO NOT CHANGE THIS CODE window_size = 30 batch_size = 32 shuffle_buffer_size = 1000 tf.keras.backend.clear_session() # You can use any random seed you want. We use 51. :) tf.random.set_seed(51) np.random.seed(51) train_set = windowed_dataset(x_train, window_size=window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size) model = tf.keras.models.Sequential([ # YOUR CODE HERE. DO NOT CHANGE THE FINAL TWO LAYERS FROM BELOW tf.keras.layers.Dense(1), # The data is not normalized, so this lambda layer helps # keep the MAE in line with expectations. Do not modify. tf.keras.layers.Lambda(lambda x: x * 400) ]) # YOUR CODE HERE TO COMPILE AND TRAIN THE MODEL return model# Note that you'll need to save your model as a .h5 like this# This .h5 will be uploaded to the testing infrastructure# and a score will be returned to youif __name__ == '__main__': model = solution_model() model.save(\"mymodel.h5\") 주어진 csv파일을 가공하여 태양 흑점의 위치를 추적하는 모델을 생성한다. Mean Absolute Error의 값이 최대 20 이하여야 한다. 2. 데이터 가공[ csv데이터 가공 ]이전과는 다르게 csv데이터를 사용하는 듯 하다. csv데이터를 다운받아와 저장한 뒤 대략적인 데이터 구조를 보면 아래와 같다. 1234567import urllibimport pandas as pdurllib.request.urlretrieve('https://storage.googleapis.com/download.tensorflow.org/data/Sunspots.csv', 'sunspots.csv')sunspots = pd.read_csv('sunspots.csv', sep=\",\")print(sunspots) sunspots.csv 데이터의 열은 아래와 같이 3개이다. 1Index(['Unnamed: 0', 'Date', 'Monthly Mean Total Sunspot Number'], dtype='object') 이중에 날짜 데이터와 월별 흑점개수 평균값 데이터를 주어진 time_step, sunspots 배열에 넣는다. 생성한 배열은 numpy배열로 변환한다. 1234567891011dataframe = _sunspots[['Date', 'Monthly Mean Total Sunspot Number']]time_step = []sunspots = []for idx, sunspot in dataframe.iterrows(): time_step.append(sunspot[0]) sunspots.append(sunspot[1]) series = np.array(sunspots)time = np.array(time_step) 학습을 위해 데이터셋을 분리한다. 문제의 조건은 아래와 같다. You should split the dataset into training and validation splits at time 3000. So everything up to 3000 is training, and everything after 3000 is validation. Write the code below to achieve that. 따라서 아래와 같이 데이터셋을 분리한다. 12345split_time = 3000time_train = time[:split_time]x_train = series[:split_time]time_valid = time[split_time:]x_valid = series[split_time:] [ Window Sequence Loader ]","link":"/2020/06/30/tf-study5/"},{"title":"Tensorflow 개발자 자격증 준비하기(3)","text":"Image Classification가위바위보 손 사진을 갖고 가위/바위/보자기로 이미지를 분류하는 classification 문제를 풀어보자. 이전과 마찬가지로 이미지 분류 문제입니다. 1. 문제12345678910111213141516171819202122def solution_model(): url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip' urllib.request.urlretrieve(url, 'rps.zip') local_zip = 'rps.zip' zip_ref = zipfile.ZipFile(local_zip, 'r') zip_ref.extractall('tmp/') zip_ref.close() TRAINING_DIR = \"tmp/rps/\" training_datagen = ImageDataGenerator( # YOUR CODE HERE) train_generator = # YOUR CODE HERE model = tf.keras.models.Sequential([ # YOUR CODE HERE, BUT END WITH A 3 Neuron Dense, activated by softmax tf.keras.layers.Dense(3, activation='softmax') ]) return model 2. 기본 CNN모델 사용: 케라스 책에 있는 고양이 vs 강아지 기본 분류모델을 사용했다. [ 데이터 전처리 ]: 단계는 다음과 같다. ImageGenerator 클래스를 사용한다. 사진 파일을 읽는다 jpg컨텐츠를 rgb픽셀로 디코딩 부동소수점 타입의 텐서로 변환 0 - 255의 픽셀값을 [0, 1] 사이로 조정한다.: 신경망은 작은 입력값을 선호한다. 123456789101112131415161718training_datagen = ImageDataGenerator( rescale=1. / 255, validation_split=0.2)train_generator = training_datagen.flow_from_directory(TRAINING_DIR, target_size=(150, 150), batch_size=20, class_mode='categorical', subset='training', )validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, target_size=(150, 150), batch_size=20, class_mode='categorical', subset='validation', ) rescale=1. / 255 : 모든 이미지를 1/255로 스케일 조정 target_size=(150, 150) : 모든 이미지 크기를 150 x 150으로 바꾼다 class_mode='categorical' : 다중분류일 경우 categorical, 혹은 sparse 사용. 이진분류는 binary사용. 12345678model.fit( train_generator, steps_per_epoch=len(train_generator), epochs=30, validation_data=(validation_generator), validation_steps=len(validation_generator), callbacks=[es, mc],) fit() : 첫번째 매개변수로 python generator를 받는다(ImageGenerator로 생성). steps_per_epoch : 하나의 에포크를 정의하기위해 사용할 배치의 수. 이 값만큼 경사하강법을 실시한다. 여기서 20개의 샘플이 하나의 배치이므로 에포크 하나에서 샘플 2016개가 모두 처리되려면 101개의 배치가 필요하다. 이는 그냥 간단하게 len(train_generator)의 값이다. validation_data : python data generator, 혹은 numpy tuple을 인자로 넘길 수 있다. ![샘플개수와_배치데이터_python_generator_크기](/image/스크린샷 2020-06-22 오전 12.00.50.png) [ 사용한 모델 ]123456789101112131415model = tf.keras.models.Sequential([ Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(150, 150, 3)), MaxPooling2D(2, 2), Conv2D(64, (3, 3), activation='relu'), MaxPooling2D(2, 2), Conv2D(128, (3, 3), activation='relu'), MaxPooling2D(2, 2), Conv2D(128, (3, 3), activation='relu'), MaxPooling2D(2, 2), Flatten(), Dense(512, activation='relu'), Dense(3, activation='softmax'),])model.compile(optimizer=keras.optimizers.RMSprop(lr=1e-4), loss='categorical_crossentropy', metrics=['acc']) : 결과는 책에서 나온대로 70%대 초반정도의 정확도를 보여줬다. 이때 훈련 정확도와 검증 정확도, 훈련 손실과 검증 손실의 양상은 아래의 이미지와 비슷했다. 위의 두 그래프는 과대적합되는 모델의 양상을 보여준다. 훈련 정확도는 선형적으로 증가하여 100%까지 이르렀지만, 검증 정확도는 어느 지점에서 멈춰있다. 훈련 손실은 선형적으로 감소하여 0%까지 이르렀지만, 검증 손실은 선형적으로 증가/변화가 없다. 이러한 Overfitting문제를 컴퓨터 비전분야에서 해결하기 위해 일반적으로 사용하는 Data augumentation(데이터 증식) 방법을 사용해보도록 하자. 3. 데이터 증식 사용 데이터 증식 : 기존 훈련샘플들을 변환함으로서 더 많은 훈련데이터를 생성하여 학습을 위한 샘플의 개수를 늘리는 방법 케라스에서는 ImageDataGenerator에서 이미지를 읽어들일때 여러 랜덤변환을 적용하도록 설정할 수 있다. 1234567891011ImageDataGenerator( rescale=1. / 255, validation_split=0.2 rotation_range=40, # 랜덤하게 사진을 회전시킬 각도 범위(1-180도) width_shift_range=0.2, # 사진을 수평으로 랜덤하게 평행이동시킬 범위 height_shift_range=0.2, # 사진을 수직으로 랜덤하게 평행이동시킬 범위 shear_range=0.2, # 랜덤하게 전단변환을 적용할 각도 범위 zoom_range=0.2, # 랜덤하게 사진을 확대할 범위 horizontal_flip=True, # 랜덤하게 이미지를 수평으로 뒤집을지 여부 fill_mode='nearest', # 회전/이동 등으로 새롭게 생성되는 픽셀을 채울 방법) 회전각의 범위는 -rotation_range ~ +rotation_range이다 height/width_shift_range는 전체 너비와 높이에 대한 비율값이다. 전단변환은 rotation_range로 회전할 때 y축 방향으로 각도를 증가시켜 이미지를 변형한다. horizontal_flip은 수평대칭을 가정할 수 있는 풍경이나 인물사진의 학습에 사용한다. 도로 표지판과 같이 뒤집힌 글씨를 학습시키는건 노노. fill_mode의 기본값인 nearest는 인접한 픽셀을 사용한다. 그밖에 constant, reflect, wrap등이 있다. 또한 모델에는 Dense layer직전에 Dropout을 추가한다. 4. 사전 훈련된 컨브넷 사용완전 사기다 이건ㅋㅋ. 나쁜뜻이 아니라 성능이 너무 극적으로 좋아져서 사기라는 의미다. 실제 시험때 써도 될지 모르겠다. 방법은 그냥 간단하다. 사전 훈련된 합성곱 신경망을 가져와서 내 Dense layer classifier 앞에 넣어준다. 1234567from keras.applications.vgg16 import VGG16conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))conv_base.trainable = False # 사전학습된 가중치는 학습하지 않는다. 모델은 아래처럼 간단해진다. 12345model = models.Sequential()model.add(conv_base)model.add(layers.Flatten())model.add(layers.Dense(256, activation='relu'))model.add(layers.Dense(3, activation='softmax')) 1234Epoch 30/30101/101 [==============================] - 549s 5s/step - loss: 2.8820e-04 - acc: 1.0000 - val_loss: 1.3292e-05 - val_acc: 0.9881Epoch 00030: val_acc did not improve from 0.99603 근데 학습시간이 어ㅓㅓ어어ㅓㅓ엄청나게 오래걸린다. 실제로는 못쓸듯…","link":"/2020/06/18/tf-study3/"},{"title":"Vue.js 코딩가이드 : Strongly Recommended (Improving Readability)","text":"참고한 문서는 Vue.js Official Style Guide 이다. 모든 가이드가 그렇듯, 절대적인 지표는 아니며 개발 방향을 정해주는 정도로 참고하면 되겠습니다. Priority B Rules : Strongly Recommended (Improving Readability)Component files 빌드시스템이 파일의 병합이 가능하다면, 가급적 각 컴포넌트는 각자의 파일로 분리하도록 한다. Good123components/|- TodoList.vue|- TodoItem.vue Single-file component filename casing 싱글파일 컴포넌트 체계를 사용한다면 single-file component는 PascalCase나 kebab-case를 사용하도록 한다. PascalCase는 코드 작성시 에디터툴들과의 호환성이 좋다. 다만 case-insensitive system에서는 가끔 오류를 발생시킬 수 있다. kebab-case는 모든 경우에 잘 호환된다. Good12components/|- MyComponent.vue 12components/|- my-component.vue Base component name Base component는 Base, App, V 와 같은 special prefix로 시작해야한다. Base component는 앱에서 사용되는 consistent styling과 behavior의 기본이 된다. Base component는 다음의 항목만 포함하는 컴포넌트를 의미한다. HTML elements other base compoenents 3rd-party UI components","link":"/2020/03/20/vue-study2/"},{"title":"Tensorflow 개발자 자격증 준비하기(4)","text":"Natural Language Processing문자열 데이터를 받아 sarcastic한지 판별하는 문제를 풀어보자. 이전과는 다르게 자연어 처리 문제이다. 1. 문제123456789101112131415161718192021222324252627282930313233343536373839import jsonimport tensorflow as tfimport numpy as npimport urllibfrom tensorflow.keras.preprocessing.text import Tokenizerfrom tensorflow.keras.preprocessing.sequence import pad_sequencesdef solution_model(): url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json' urllib.request.urlretrieve(url, 'sarcasm.json') # DO NOT CHANGE THIS CODE OR THE TESTS MAY NOT WORK vocab_size = 1000 embedding_dim = 16 max_length = 120 trunc_type='post' padding_type='post' oov_tok = \"&lt;OOV&gt;\" training_size = 20000 sentences = [] labels = [] # YOUR CODE HERE model = tf.keras.Sequential([ # YOUR CODE HERE. KEEP THIS OUTPUT LAYER INTACT OR TESTS MAY FAIL tf.keras.layers.Dense(1, activation='sigmoid') ]) return model# Note that you'll need to save your model as a .h5 like this# This .h5 will be uploaded to the testing infrastructure# and a score will be returned to youif __name__ == '__main__': model = solution_model() model.save(\"mymodel.h5\") 2. 데이터 가공: sarcasm 학습데이터는 json 포맷이다. 받아온 sarcasm.json 파일을 로드해와 sentences와 labels로 나눈다. 123456789101112131415161718192021222324import json# sarcasm 데이터 다운로드urllib.request.urlretrieve('https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json', 'sarcasm.json')with open('sarcasm.json') as file: data = json.load(file)# 데이터를 sentence와 label로 나눈다.dataset = []for elem in data: sentences.append(elem['headline']) labels.append(elem['is_sarcastic']) # 훈련 데이터와 테스트 데이터로 분류training_size = int(len(data)*0.2)train_sentences = sentences[:training_size]train_labels = labels[:training_size]validation_sentences = sentences[training_size:]validation_labels = labels[training_size:]# 데이터셋은 numpy array이어야 한다.train_labels = np.array(train_labels)validation_labels = np.array(validation_labels) sarcasm 데이터셋은 자연어처리를 실습하기 위한 예제이다. 따라서 이전 포스트의 자연어 처리와 관련된 이론내용들을 실제로 적용해볼 수 있다. 자연어 처리의 전처리 자연어 처리의 실습 자연어 처리의 전처리 단계는 다음과 같다. 자연어 처리의 전처리 단계 : 토큰화, 단어집합 생성, 정수인코딩, 패딩 아 맨날 까먹는다. 붕어인가ㅠ [ 토큰화 ]123456789from tensorflow.keras.preprocessing.text import Tokenizer# 변경 불가vocab_size = 1000oov_tok = \"&lt;OOV&gt;\"max_length = 120trunc_type='post'padding_type='post'embedding_dim = 16 Tokenizer를 정의한다. 1tokenizer = Tokenizer(num_words=vocab_size, oov_token='&lt;OOV&gt;') num_words: 단어 집합 max 사이즈를 지정합니다. 가장 빈도수가 높은 단어부터 저장합니다. oov_token: 단어 집합에 없는 단어를 어떻게 표기할 것인지 지정해줍니다. 학습시킬 대상 문장을 토큰화하고(단어 단위로 분리하고), 단어집합을 만든다. 12tokenizer.fit_on_texts(sentences)word_to_idx = tokenizer.word_index 학습 대상 문장을 각각의 고유한 정수로 매핑한다. 12train_sequences = tokenizer.texts_to_sequences(train_sentences)validation_sequences = tokenizer.texts_to_sequences(validation_sentences) [ 패딩 ]: pad_sequences 함수를 사용한다. 옵션값은 아래와 같다. maxlen: 최대 문장 길이를 정의합니다. 최대 문장길이보다 길면, 잘라냅니다. truncating: 문장의 길이가 maxlen보다 길 때 앞을 자를지 뒤를 자를지 정의합니다. padding: 문장의 길이가 maxlen보다 짧을 때 채워줄 값을 앞을 채울지, 뒤를 채울지 정의합니다. 12train_padded = pad_sequences(train_sequences, truncating=trunc_type, padding=padding_type, maxlen=max_length)validation_padded = pad_sequences(validation_sequences, padding=padding_type, maxlen=max_length) 3. 모델 설계: Bidirectional LSTM 사용한 모델을 설계한다. 원래 강의노트 모델이 좀 과적합되는 것 같아서 중간에 dropout하나 추가해줌. 123456789model = tf.keras.Sequential([ tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length), tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)), tf.keras.layers.Dense(24, activation='relu'), tf.keras.layers.Dropout(0.5), tf.keras.layers.Dense(1, activation='sigmoid')])model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) 12345625/625 [==============================] - ETA: 0s - loss: 0.3208 - accuracy: 0.8569Epoch 00020: val_loss improved from 0.35426 to 0.35268, saving model to my_checkpoint3.ckpt625/625 [==============================] - 565s 904ms/step - loss: 0.3208 - accuracy: 0.8569 - val_loss: 0.3527 - val_accuracy: 0.8393Epoch 21/30 통과하는 baseline은 정확도 83퍼 중반, loss 0.36이하였다. 임베딩 차원이 너무 작아서 그런지 정확도가 잘 안오른다..ㅠㅠ 4. word2vec 적용: 이전에 배웠던 word2vec 전처리를 추가해봤다. TED 강의 중 하나의 스크립트로 16차원의 임베딩 테이블을 학습한다. 영어/한국어 Word2Vec 실습 123456789101112131415161718192021222324252627282930313233343536import refrom lxml import etreeimport urllib.requestimport zipfilefrom nltk.tokenize import word_tokenize, sent_tokenizefrom gensim.models import Word2Vecimport nltknltk.download('punkt')# 데이터 다운로드urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&amp;filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")# xml 파일로부터 &lt;content&gt;와 &lt;/content&gt; 사이의 내용만 가져온다.with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z: target_text = etree.parse(z.open('ted_en-20160408.xml', 'r')) parse_text = '\\n'.join(target_text.xpath('//content/text()'))# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.# 해당 코드는 괄호로 구성된 내용을 제거.content_text = re.sub(r'\\([^)]*\\)', '', parse_text)# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.sent_text=sent_tokenize(content_text)# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.normalized_text = []for string in sent_text: tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower()) normalized_text.append(tokens)# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.result = [word_tokenize(sentence) for sentence in normalized_text]model = Word2Vec(sentences=result, size=16, window=5, min_count=5, workers=4, sg=0)model.wv.save_word2vec_format('eng_w2v') # 워드 임베딩 저장 [Embedding Matrix 생성]1234567embedding_matrix = np.zeros((vocab_size, embedding_dim))for word, i in word_to_idx.items(): if i &gt;= vocab_size: break if word in word2vec.vocab: embedding_matrix[i] = word2vec.word_vec(word) TED 강연자료로 학습한 워드임베딩 값으로 모델 학습에 사용할 임베딩 테이블을 생성한다. 생성한 데이터셋 단어집합의 각 단어에 대해 해당 단어의 벡터값이 생성한 eng_w2v에 존재할 경우 임베딩테이블에 값을 넣어준다. 생성한 embedding matrix값은 모델의 Embedding layer에서 아래와 같이 설정함으로서 모델 학습에 활용할 수 있다. 1tf.keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=True, mask_zero=True) weights 에 생성한 embedding matrix를 넣어준다. trainable=True 로 두면 생성한 embedding matrix를 초기 임베딩 레이어 값으로 사용하되, 모델 학습에 따라서 값을 다시 학습한다. 원래대로라면 이미 만들어진 임베딩 매트릭스 값을 학습하지 않는것이 맞겠지만, 내 경우 TED로 생성한 embedding table이 당연하게도 엄청 좋지는 않아서… 그냥 모델이랑 같이 학습을 시켜주는게 더 효과가 좋았다. 결과적으로 초기값만 좀 달라진 셈인데 어쨌든 효과가 아예 없지는 않았다. 1234Epoch 8/30625/625 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.8517Epoch 00008: val_loss improved from 0.36791 to 0.36273, saving model to my_checkpoint2.ckpt625/625 [==============================] - 123s 197ms/step - loss: 0.3349 - accuracy: 0.8517 - val_loss: 0.3627 - val_accuracy: 0.8344","link":"/2020/06/22/tf-study4/"},{"title":"Tensorflow 개발자 자격증 준비하기(6)","text":"Image Classification : Tensorflow dataset3번 유형의 문제를 몇개 더 찾아보았다. 개/고양이 사진을 분류하는 문제를 풀어보았다. 1. 문제1234567891011121314151617181920212223242526# using the Cats v Dogs dataset from TFDS.# The testing infrastructre will resize all images to 224x224 # with 3 bytes of color depth. Make sure your input layer trains# images to that specification, or the tests will fail.import tensorflow_datasets as tfdsimport tensorflow as tfdataset_name = 'cats_vs_dogs'dataset, info = tfds.load(name=dataset_name, split=tfds.Split.TRAIN, with_info=True)def preprocess(features): # YOUR CODE HEREdef solution_model(): train_dataset = dataset.map(preprocess).batch(32) model = # YOUR CODE HERE, BUT MAKE SURE YOUR LAST LAYER HAS 2 NEURONS ACTIVATED BY SOFTMAX tf.keras.layers.Dense(2, activation='softmax') ]) return modelif __name__ == '__main__': model = solution_model() model.save(\"mymodel.h5\") tensorflow dataset 클래스의 개/고양이 컬러사진 데이터를 모델 학습에 사용한다. 최종 레이어는 softmax로 2개 종류로 분류하는 Dense layer label값은 0 or 1인 1차원 텐서다 label을 one hot encoding 하면 categorical cross entropy, 안하면 sparse categorical crossentropy를 사용하자. 2. 데이터 전처리아.. 일단 데이터 다운로드 받는 것 부터가 난관이었다ㅋㅋ 오랜 고군분투 끝에 알아낸 방법은 아래와 같다. 1234test_dataset, train_dataset = tfds.load(name='cats_vs_dogs' , split=('train[:35%]', 'train[20%:]') , as_supervised=True) with_info 옵션을 주면 데이터셋의 정보를 같이 반환한다. split 옵션설정을 통해 데이터를 앞에서부터 30%, 나머지 80%로 분할해서 반환하도록 했다. as_supervised 옵션을 True로 주면 데이터가 튜플로 반환된다. False일 경우 dictionary 형태로 반환된다. =&gt; default 값은 False. 받아온 데이터를 전처리한다. 별건 없고 일단은 그냥 (1)이미지 값을 0-1 사이로 조정하고, (2)이미지 사이즈를 (224, 224)로 줄인다. 간단한 전처리 함수는 아래와 같다. 123456def preprocess(img, lbl): _img = tf.cast(img, tf.float32) _img = tf.divide(_img, 255) _img = tf.image.resize(_img, (224, 224)) # 이미지 사이즈를 얜 224, 아래는 244로 해둬서 한참해멤...ㅋㅋ return _img, lbl 이제 전처리된 데이터셋으로 배치를 생성한다. 12train_databatch = train_dataset.map(preprocess).batch(BATCH_SZ).repeat() test_databatch = test_dataset.map(preprocess).batch(BATCH_SZ).repeat() map() : 데이터셋의 모든 원소에 preprocess 함수로 지정한 변환을 한다 batch(BATCH_SZ) : BATCH_SZ개씩 원소를 가져와서 데이터셋에 저장한다.데이터셋 원소 개수는 데이터셋원소개수/BATCH_SZ(나머지있으면 +1)이다. repeat() : 이걸 넣어줘야 반복적으로 데이터셋의 모든 데이터에 대해 배치가 생긴다. 3. 모델 구성12345678910111213141516171819model = Sequential([ Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(224, 224, 3)), MaxPooling2D(2, 2), Conv2D(16, (3, 3), padding='same', activation='relu'), MaxPooling2D(2, 2), Conv2D(32, (3, 3), padding='same', activation='relu'), MaxPooling2D(2, 2), Conv2D(32, (3, 3), padding='same', activation='relu'), MaxPooling2D(2, 2), Conv2D(64, (3, 3), padding='same', activation='relu'), MaxPooling2D(2, 2), Flatten(), Dropout(0.5), Dense(128, activation='relu'), Dense(2, activation='softmax'),])model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc']) 4. 모델 학습1234567891011121314checkpointPath = 'catDogBest.ckpt'mc = ModelCheckpoint(checkpointPath, monitor = 'val_loss', verbose = 1, save_weights_only=True, save_best_only = True)model.fit( train_databatch, steps_per_epoch=(train_len/BATCH_SZ), epochs=50, validation_data=(test_databatch), validation_steps=(test_len/BATCH_SZ), callbacks=[mc]) 12Epoch 00028: val_loss improved from 0.16154 to 0.14961, saving model to catDogBest.ckpt582/581 [==============================] - 25s 43ms/step - loss: 0.1320 - acc: 0.9513 - val_loss: 0.1496 - val_acc: 0.9445 + 알게된 점 train_dataset과 test_dataset의 비율을 조정하는 것 만으로도 모델의 성능을 높일 수 있다. 기존에 train_data랑 test_data를 걍 암생각없이 2 : 8로 나눴는데, 이를 3.5 : 8로 비율 조정한 것 만으로 모델 성능이 확 올라갔다. ​","link":"/2020/07/25/tf-study6/"},{"title":"Vue.js 코딩가이드 : Essential(Error Prevention)","text":"늘 Vue를 사용하지만 코딩 스타일 가이드를 정독한 적은 없는 관계로.. 조금 시간이 난 김에 한번 스타일가이드를 정리해보려 합니다. 참고한 문서는 Vue.js Official Style Guide. 모든 가이드가 그렇듯, 절대적인 지표는 아니며 개발 방향을 정해주는 정도로 참고하면 되겠습니다. Rule Categories이하의 룰들은 총 4가지 카테고리로 나뉘게 된다. 명칭 우선순위 설명 Priority A Essential - 에러를 방지한다. - 룰의 예외는 극히 드물다. Priority B Strongly Recommended - 코드의 가독성/개발 편의성을 높여준다.- 해당 룰을 지키지 않아도 코드는 실행될 수 있지만 가급적 룰을 따르는 것이 좋다. Priority C Recommended - 허용가능한/타당한 이유의 다른 방식이 있을때에는 꼭 따르지 않아도 된다. - 해당 룰에서는 가능한 다른 방법과 함께 default option을 제안한다. 개발자는 이들 중 자신의 프로젝트에 맞춰 따를 룰을 정할 수 있다.- 이러한 Community rule을 따르면 다른 코드를 이식해올 때 용이하다 Priority D Use with caution - 희귀한 edge case들을 처리하거나 legacy code의 migration을 위한 룰- 남용시 코드 가독성을 떨어뜨리고 오류를 발생시킬 수 있다. Priority A Rules : Essential(Error Prevention)Multi-word component names 컴포넌트명은 반드시 여러개의 단어로 되어있어야 한다.(Root의 App 컴포넌트나 , 같은 내장 컴포넌트 제외) 현재 존재하는, 앞으로 만들어질 수 있는 HTML 태그와의 혼선을 방지할 수 있다.(모든 HTML 태그는 single word) Bad123Vue.component('todo', { // ...}) Good123Vue.component('todo-item', { // ...}) Component Data 컴포넌트의 data는 반드시 함수형이어야 한다.(object 반환, new Vue 초기화시 제외) 컴포넌트 data를 단순한 object형으로 선언할 경우 컴포넌트의 재사용성에 큰 문제 생긴다. 해당 컴포넌트를 사용하는 모든 instance에서 같은 data object를 참조한다. 즉, 컴포넌트의 데이터가 its own data가 아닌 shared data가 되어버린다. 어떤 하나가 행하는 deletion/adding/changing은 모든 다른 컴포넌트들에 영향을 미침. 따라서 각 컴포넌트는 자신만의 고유한 데이터를 가질 수 있어야하며, 컴포넌트의 data 필드를 특정 데이터 객체를 반환하는 함수형으로 선언함으로서 문제를 해결할 수 있다. Bad12345Vue.component('some-comp', { data: { foo: 'bar' }}) Good1234567Vue.component('some-comp', { data: function () { return { foo: 'bar' } }}) Exception12345678// It's OK to use an object directly in a root// Vue instance, since only a single instance// will ever exist.new Vue({ data: { foo: 'bar' }}) Prop definition prop은 가능한 한 상세하게 필드를 정의하는 것이 좋다. 최소한 type은 명세해야 한다. Bad12// This is only OK when prototypingprops: ['status'] Good1234567891011121314151617181920// Not badprops: { status: String}// Even better!props: { status: { type: String, required: true, validator: function (value) { return [ 'syncing', 'synced', 'version-conflict', 'error' ].indexOf(value) !== -1 } }} Keyed v-for v-for 사용시에는 항상 key가 있어야 한다. v-for의 key는 내부 subtree의 제어에 사용된다. object consistancy를 유지하는 등의 예측가능한 행위를 제어/관리할 수 있도록 두는것이 좋다. 예를들어 리스트 아이템 [b,a]를 알파벳 순서로 정렬한다고 가정해보자. Vue는 가장 비용이 적게 드는 방식을 선택할 것. 가장 간단한 방법은 b를 삭제한 뒤 a 뒤에 다시 넣는 것이다. 하지만 만약 애니메이션 등을 사용해서 b를 삭제하면 안된다면? b가 텍스트필드라 정렬후에도 b에대한 focus를 잃어선 안된다면? 이때 b, a 각각에 고유한 키를 부여한다면 Vue가 보다 더 predictable 하게 행동하도록 제어할 수 있다. Bad12345&lt;ul&gt; &lt;li v-for=\"todo in todos\"&gt; {{ todo.text }} &lt;/li&gt;&lt;/ul&gt; Good12345&lt;ul&gt; &lt;li v-for=\"todo in todos\" :key=\"todo.id\"&gt; {{ todo.text }} &lt;/li&gt;&lt;/ul&gt; Avoid v-if with v-for v-for과 v-if를 같은 element 내에서 사용하면 안된다. vue가 directive를 처리할떄 v-for는 v-if보다 높은 우선순위를 갖는다. 따라서 v-for와 v-if를 같이 사용한 아래와 같은 코드는 12345&lt;ul&gt; &lt;li v-for=\"user in users\" v-if=\"user.isActive\" :key=\"user.id\"&gt; {{ user.name }} &lt;/li&gt;&lt;/ul&gt; 다음과 같이 변환된다. 12345this.users.map(function (user) { if (user.isActive) { return user.name }}) 따라서 user의 정보가 일부분만 바뀌어도 re-render를 위해 리스트 전체를 다시 iterate해야한다. 위와같은 경우 if조건을 v-for 컴포넌트의 상위 컴포넌트로 옮긴다 Computed 메서드에 user에 대한 필터링 조건을 설정하여 v-for로 iterate되는 리스트 자체를 필터링된 리스트로 사용한다. 123456789101112131415161718&lt;ul&gt; &lt;li v-for=\"user in activeUsers\" :key=\"user.id\" &gt; {{ user.name }} &lt;/li&gt;&lt;/ul&gt;...computed: { activeUsers: function () { return this.users.filter(function (user) { return user.isActive }) }} Component style scoping Root의 App컴포넌트를 제외한 모든 컴포넌트의 스타일은 scoped 되어야 한다 : 혹은 고유한 클래스명을 사용하는 것도 방법일 수 있다. Private property names private function이 외부에서 접근 불가능하도록 module scoping을 사용한다. 혹은 plugin, mixin 의 모든 custom private properties에 대해 $_ prefix를 사용한다. _ prefix는 뷰 자체 private properties를 정의하는데에 사용하므로 _update 와 같은 이름은 instance property를 overwrite할 위험이 있다. $ 는 special instance properties를 지칭하는데 사용된다. 따라서 두개의 prefix를 합친 $_yourPluginName의 사용을 권장. Bad1234567891011121314151617var myGreatMixin = { // ... methods: { update: function () { // ... }, _update: function () { // ... }, $update: function () { // ... }, $_update: function () { // ... }, }} Good12345678var myGreatMixin = { // ... methods: { $_myGreatMixin_update: function () { // ... } }} Excellent12345678910111213141516// Even better!var myGreatMixin = { // ... methods: { publicMethod() { // ... myPrivateFunction() } }}function myPrivateFunction() { // ...}export default myGreatMixin","link":"/2020/03/20/vue-study1/"},{"title":"YAMLException: can not read a block mapping entry, Hexo","text":"How to solve problem YAMLException: can not read a block mapping entry 포스팅을 하면서 다음과 같은 에러가 발생했다. 이는 아래와 같이 Hexo로 신규 게시물 작성 시 title에 [] 대괄호를 사용하면 발생하는 에러이다. (,나 :같은 기호를 사용해도 발생한다.) The error above occurs because of the [] square brackets used in a title of your post. 따라서 위의 타이틀을 “” 로 묶어주면 에러를 해결할 수 있다. Just add a title with double quotation marks to solve the problem. 1title : \"[딥러닝 스터디] 임베딩이란\"","link":"/2020/02/16/yaml-exception/"},{"title":"[Tensorflow 2.0] Subclassing 구현","text":"TensorFlow 2.0으로 베우는 딥러닝 입문 강의를 들으며 공부한 내용입니다. 복습 겸 입문 강의를 쭉 훑으면서 기초를 다시 다져보려 한다. Subclassing 코딩스타일을 익혀보자. 강의에 사용된 예제 코드는 이전에 다뤄본 MNIST 숫자분류 코드로 깃헙 주소는 아래와 같다. -&gt; 여기! 12345678910# tf.keras.Model을 이용해서 Softmax Regression 모델을 정의합니다.class SoftmaxRegression(tf.keras.Model): def __init__(self): super(SoftmaxRegression, self).__init__() self.softmax_layer = tf.keras.layers.Dense(10, activation=None, kernel_initializer='zeros', bias_initializer='zeros') def call(self, x): logits = self.softmax_layer(x) return tf.nn.softmax(logits) 케라스 서브클래싱 방식을 사용한 코드패턴이다. tf.keras.Model을 상속받는 클래스를 하나 정의해준다. 생성자 init과 호출부 call 로직을 정의해준다. 생성자에서는 super 메서드를 통해 tf.keras.model의 생성자를 상속받는 형태로 정의해준다. 클래스 변수로 원하는 모델 구조의 API를 선언해준다. 클래스 호출부 call 메서드에서는 인자값으로 input data x를 받고 생성자 부분에서 정의했던 클래스 변수들(softmax_layer)을 순차적으로 호출한다 =&gt; 전체 모델 구조의 output 반환값을 계산(logits). 12345678# 최적화를 위한 function을 정의합니다.@tf.functiondef train_step(model, x, y): with tf.GradientTape() as tape: y_pred = model(x) loss = cross_entropy_loss(y_pred, y) gradients = tape.gradient(loss, model.trainable_variables) optimizer.apply_gradients(zip(gradients, model.trainable_variables)) GradientTape에 대한 공식문서 GradientTape은 자동으로 context 내에서 실행된 모든 연산을 tape에 기록 한다. 이후, tape.gradient(z, y) 를 호출하면 GradientTape에 포함된 리소스가 해제되면서 y에 대한 도함수를 계산한다.","link":"/2020/11/29/tf-study7/"},{"title":"[DACON] 심리 성향 예측 AI 경진대회","text":"https://dacon.io/competitions/official/235647/overview/ 데이콘에서 종료한 대회의 데이터와 코드를 참고해 알고리즘 제작을 실습해보려 한다. 처음으로 풀 문제는 올해 11월 종료한 심리성향 예측 AI 경진대회 이다. Overview 테스트 참가자의 국가 선거 투표 여부를 예측한다. 사용 가능 언어 : Python, R 심사기준 : AUC 외부 데이터 사용불가, pre-trained Model 사용불가 데이터 분석학습해야할 데이터 파일의 구성은 아래와 같다. 하나의 행이 한 참가자의 정보를 담고 있다. 최종적으로 예측해야 하는 값은 해당 참가자의 voted : 지난해 국가 선거 투표여부 이다. a~t 까지의 20개의 질문에 대한 답 QnA와 답변에 걸린 시간 QnE 가 주어진다. 답변은 1=Disagree, 2=Slightly disagree, 3=Neutral, 4=Slightly agree, 5=Agree 로 주어진다. 스스로의 성격에 대한 평가 질문 7개에 대한 답이 주어진다. I see myself as (Extraverted / Critical / Dependable… ) 실존하는 단어 13개에 대한 정의를 아는지 여부에 대한 답변이 1=Yes, 2=No로 주어진다 : wr_(01~13) 허구하는 단어 3개에 대한 정의를 아는지 여부에 대한 답변이 1=Yes, 2=No로 주어진다 : wt_(01~03) 기타 해당 참가자에 대한 정보(연령, 교육수준, 모국어, 형제자매 등)가 주어진다. 데이터 전처리[ 구글 드라이브 마운트해서 파일 받아오기 ]구글 드라이브에 샘플 csv파일을 올려두고, 데이터 처리를 위해 해당 파일들을 불러온다. 1234567# 구글 드라이브에 올려둔 학습데이터 가져온다from google.colab import drivedrive.mount('/drive', force_remount=True)# 파일 받아온다train_filename = '/drive/My Drive/DACON/MindType/train.csv'test_filename = '/drive/My Drive/DACON/MindType/test_x.csv' 개인 구글 드라이브 하위에 /DACON/MindType 폴더를 만들어두고 학습 데이터들을 올려두었다. 드라이브를 마운트하고 파일을 받아온다. [ csv 파일 읽어와 학습변수로 설정하기 ] csv 파일 읽어오기 12345# csv파일 읽어들인다import pandas as pdtrain_raw = pd.read_csv(train_filename)print(train_raw.columns) 12345678910Index(['index', 'QaA', 'QaE', 'QbA', 'QbE', 'QcA', 'QcE', 'QdA', 'QdE', 'QeA', 'QeE', 'QfA', 'QfE', 'QgA', 'QgE', 'QhA', 'QhE', 'QiA', 'QiE', 'QjA', 'QjE', 'QkA', 'QkE', 'QlA', 'QlE', 'QmA', 'QmE', 'QnA', 'QnE', 'QoA', 'QoE', 'QpA', 'QpE', 'QqA', 'QqE', 'QrA', 'QrE', 'QsA', 'QsE', 'QtA', 'QtE', 'age_group', 'education', 'engnat', 'familysize', 'gender', 'hand', 'married', 'race', 'religion', 'tp01', 'tp02', 'tp03', 'tp04', 'tp05', 'tp06', 'tp07', 'tp08', 'tp09', 'tp10', 'urban', 'voted', 'wf_01', 'wf_02', 'wf_03', 'wr_01', 'wr_02', 'wr_03', 'wr_04', 'wr_05', 'wr_06', 'wr_07', 'wr_08', 'wr_09', 'wr_10', 'wr_11', 'wr_12', 'wr_13'], dtype='object') 파이썬의 pandas 라이브러리를 활용해 csv 파일을 불러온다 : pandas.read_csv() 사용 csv파일 변수의 .columns 로 추출된 컬럼을 확인할 수 있다. index column 설정하기 12345# csv파일 읽어들인다import pandas as pdtrain_raw = pd.read_csv(train_filename, index_col=0)print(train_raw.columns) 12345678910Index(['QaA', 'QaE', 'QbA', 'QbE', 'QcA', 'QcE', 'QdA', 'QdE', 'QeA', 'QeE', 'QfA', 'QfE', 'QgA', 'QgE', 'QhA', 'QhE', 'QiA', 'QiE', 'QjA', 'QjE', 'QkA', 'QkE', 'QlA', 'QlE', 'QmA', 'QmE', 'QnA', 'QnE', 'QoA', 'QoE', 'QpA', 'QpE', 'QqA', 'QqE', 'QrA', 'QrE', 'QsA', 'QsE', 'QtA', 'QtE', 'age_group', 'education', 'engnat', 'familysize', 'gender', 'hand', 'married', 'race', 'religion', 'tp01', 'tp02', 'tp03', 'tp04', 'tp05', 'tp06', 'tp07', 'tp08', 'tp09', 'tp10', 'urban', 'voted', 'wf_01', 'wf_02', 'wf_03', 'wr_01', 'wr_02', 'wr_03', 'wr_04', 'wr_05', 'wr_06', 'wr_07', 'wr_08', 'wr_09', 'wr_10', 'wr_11', 'wr_12', 'wr_13'], dtype='object') 위와 같이 csv파일을 읽어올때 index column을 설정해주면 전처리할 열에서 제외할 수 있다. “voted” 열을 train_y의 타겟으로 만들기 1234train_x = train_raw.drop('voted', axis = 1)train_y = train_raw['voted']train_x.shape 1(45532, 76) # 45532명에 대한 76가지 데이터를 의미한다. 학습 데이터에서 voted 열만 제외한 데이터를 train_x로 저장 학습 데이터의 voted 열을 따로 뽑아 train_y로 저장 [ 문자열 변수 변환 ]값이 문자열로 들어가있는 데이터에 대해 적절한 숫자값으로 변환해주었다. 12345678910111213141516gender_list = ['Male', 'Female']race_list = ['Asian', 'Arab', 'Black', 'Indigenous Australian', 'Native American', 'White', 'Other']religion_list = ['Agnostic', 'Atheist', 'Buddhist', 'Christian_Catholic', 'Christian_Mormon', 'Christian_Protestant', 'Christian_Other', 'Hindu', 'Jewish', 'Muslim', 'Sikh', 'Other']for idx, data in train_x.iterrows(): age_grp = data['age_group'] race = data['race'] religion = data['religion'] gender = data['gender'] train_x.loc[idx, 'age_group'] = age_grp.replace('s', '') train_x.loc[idx, 'race'] = race_list.index(race) + 1 train_x.loc[idx, 'religion'] = religion_list.index(religion) + 1 train_x.loc[idx, 'gender'] = gender_list.index(gender) + 1print(train_x['religion']) 12345678910111213index0 121 82 123 84 1 ..45527 945528 245529 745530 245531 1Name: religion, Length: 45532, dtype: object","link":"/2020/12/21/tf-study8/"}],"tags":[{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"딥러닝기초","slug":"딥러닝기초","link":"/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D%EA%B8%B0%EC%B4%88/"},{"name":"선형회귀","slug":"선형회귀","link":"/tags/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80/"},{"name":"linear regression","slug":"linear-regression","link":"/tags/linear-regression/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"numpy","slug":"numpy","link":"/tags/numpy/"},{"name":"그래프 시각화","slug":"그래프-시각화","link":"/tags/%EA%B7%B8%EB%9E%98%ED%94%84-%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"tensorflow 2.0","slug":"tensorflow-2-0","link":"/tags/tensorflow-2-0/"},{"name":"로지스틱 회귀","slug":"로지스틱-회귀","link":"/tags/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1-%ED%9A%8C%EA%B7%80/"},{"name":"logistic regression","slug":"logistic-regression","link":"/tags/logistic-regression/"},{"name":"자연어처리","slug":"자연어처리","link":"/tags/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/"},{"name":"딥러닝","slug":"딥러닝","link":"/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/"},{"name":"언어모델","slug":"언어모델","link":"/tags/%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8/"},{"name":"한국어 임베딩","slug":"한국어-임베딩","link":"/tags/%ED%95%9C%EA%B5%AD%EC%96%B4-%EC%9E%84%EB%B2%A0%EB%94%A9/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"순환신경망","slug":"순환신경망","link":"/tags/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D/"},{"name":"자연어 전처리","slug":"자연어-전처리","link":"/tags/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%A0%84%EC%B2%98%EB%A6%AC/"},{"name":"tensorflow","slug":"tensorflow","link":"/tags/tensorflow/"},{"name":"Keras","slug":"Keras","link":"/tags/Keras/"},{"name":"torchtext","slug":"torchtext","link":"/tags/torchtext/"},{"name":"케라스","slug":"케라스","link":"/tags/%EC%BC%80%EB%9D%BC%EC%8A%A4/"},{"name":"Attention","slug":"Attention","link":"/tags/Attention/"},{"name":"mac","slug":"mac","link":"/tags/mac/"},{"name":"change permission","slug":"change-permission","link":"/tags/change-permission/"},{"name":"folder permission","slug":"folder-permission","link":"/tags/folder-permission/"},{"name":"codility","slug":"codility","link":"/tags/codility/"},{"name":"coding test","slug":"coding-test","link":"/tags/coding-test/"},{"name":"developer","slug":"developer","link":"/tags/developer/"},{"name":"jsp","slug":"jsp","link":"/tags/jsp/"},{"name":"inflearn","slug":"inflearn","link":"/tags/inflearn/"},{"name":"nuxtjs","slug":"nuxtjs","link":"/tags/nuxtjs/"},{"name":"vuejs","slug":"vuejs","link":"/tags/vuejs/"},{"name":"vue","slug":"vue","link":"/tags/vue/"},{"name":"javascript","slug":"javascript","link":"/tags/javascript/"},{"name":"vueschool.io","slug":"vueschool-io","link":"/tags/vueschool-io/"},{"name":"githubpage","slug":"githubpage","link":"/tags/githubpage/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"인공지능","slug":"인공지능","link":"/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/"},{"name":"tensorflow developer certification","slug":"tensorflow-developer-certification","link":"/tags/tensorflow-developer-certification/"},{"name":"자격증","slug":"자격증","link":"/tags/%EC%9E%90%EA%B2%A9%EC%A6%9D/"},{"name":"ES6","slug":"ES6","link":"/tags/ES6/"},{"name":"ES2015+","slug":"ES2015","link":"/tags/ES2015/"},{"name":"nodejs","slug":"nodejs","link":"/tags/nodejs/"},{"name":"express","slug":"express","link":"/tags/express/"},{"name":"api_server","slug":"api-server","link":"/tags/api-server/"},{"name":"style guide","slug":"style-guide","link":"/tags/style-guide/"},{"name":"coding rule","slug":"coding-rule","link":"/tags/coding-rule/"},{"name":"YAMLException","slug":"YAMLException","link":"/tags/YAMLException/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"데이콘","slug":"데이콘","link":"/tags/%EB%8D%B0%EC%9D%B4%EC%BD%98/"},{"name":"dacon","slug":"dacon","link":"/tags/dacon/"}],"categories":[{"name":"개발자 공부","slug":"개발자-공부","link":"/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/"},{"name":"인공지능","slug":"개발자-공부/인공지능","link":"/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/"},{"name":"그냥 그런 일상","slug":"그냥-그런-일상","link":"/categories/%EA%B7%B8%EB%83%A5-%EA%B7%B8%EB%9F%B0-%EC%9D%BC%EC%83%81/"},{"name":"코딩테스트","slug":"개발자-공부/코딩테스트","link":"/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8/"},{"name":"JSP","slug":"개발자-공부/JSP","link":"/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/JSP/"},{"name":"Javascript","slug":"개발자-공부/Javascript","link":"/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/Javascript/"},{"name":"그렇게 바보는 아님","slug":"그냥-그런-일상/그렇게-바보는-아님","link":"/categories/%EA%B7%B8%EB%83%A5-%EA%B7%B8%EB%9F%B0-%EC%9D%BC%EC%83%81/%EA%B7%B8%EB%A0%87%EA%B2%8C-%EB%B0%94%EB%B3%B4%EB%8A%94-%EC%95%84%EB%8B%98/"},{"name":"Nuxt.js","slug":"개발자-공부/Javascript/Nuxt-js","link":"/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/Javascript/Nuxt-js/"},{"name":"끄적끄적","slug":"그냥-그런-일상/끄적끄적","link":"/categories/%EA%B7%B8%EB%83%A5-%EA%B7%B8%EB%9F%B0-%EC%9D%BC%EC%83%81/%EB%81%84%EC%A0%81%EB%81%84%EC%A0%81/"},{"name":"ES6","slug":"개발자-공부/Javascript/ES6","link":"/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/Javascript/ES6/"},{"name":"Node.js","slug":"개발자-공부/Javascript/Node-js","link":"/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/Javascript/Node-js/"},{"name":"Vue.js","slug":"개발자-공부/Javascript/Vue-js","link":"/categories/%EA%B0%9C%EB%B0%9C%EC%9E%90-%EA%B3%B5%EB%B6%80/Javascript/Vue-js/"}]}